[{"content":"Hugo文章引用完整指南 在Hugo中，文章之间的相互引用是提高用户体验和SEO的重要功能。本文将详细介绍各种文章引用方法。\n1. 基础引用方法 1.1 使用 ref shortcode（推荐） ref shortcode 是Hugo内置的引用功能，会生成绝对链接：\n1 {{\u0026lt; ref \u0026#34;/post/path/to/article.md\u0026#34; \u0026gt;}} 优点：\n自动生成正确的链接 构建时会检查链接有效性 支持多语言 支持锚点引用 示例：\n1 查看这篇文章：[WordPress使用git-it-write插件](/post/wordpress/wordpress使用git-it-write插件配合github自动发布markdown/) 1.2 使用 relref shortcode relref 生成相对链接，适合站点迁移：\n1 {{\u0026lt; relref \u0026#34;/post/path/to/article.md\u0026#34; \u0026gt;}} 1.3 直接使用 Markdown 链接 1 [文章标题](/post/article-slug/) 2. 高级引用技巧 2.1 引用特定章节 可以引用文章中的特定章节：\n1 {{\u0026lt; ref \u0026#34;/post/article.md#section-title\u0026#34; \u0026gt;}} 2.2 引用文章并显示链接文本 1 [显示的文本]({{\u0026lt; ref \u0026#34;/post/article.md\u0026#34; \u0026gt;}}) 2.3 在链接中使用变量 1 {{\u0026lt; ref \u0026#34;/post/article.md\u0026#34; \u0026gt;}} 3. 自定义引用卡片 我们还可以创建自定义的引用卡片来美化文章引用：\n3.1 创建 shortcode 创建 layouts/shortcodes/post-ref.html：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 {{- $ref := .Get 0 -}} {{- $page := .Site.GetPage $ref -}} {{- if $page -}} \u0026lt;div class=\u0026#34;post-reference-card\u0026#34;\u0026gt; \u0026lt;a href=\u0026#34;{{ $page.RelPermalink }}\u0026#34; class=\u0026#34;post-ref-link\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;post-ref-content\u0026#34;\u0026gt; \u0026lt;h3 class=\u0026#34;post-ref-title\u0026#34;\u0026gt;{{ $page.Title }}\u0026lt;/h3\u0026gt; \u0026lt;p class=\u0026#34;post-ref-summary\u0026#34;\u0026gt;{{ $page.Summary | truncate 150 }}\u0026lt;/p\u0026gt; \u0026lt;div class=\u0026#34;post-ref-meta\u0026#34;\u0026gt; \u0026lt;span class=\u0026#34;post-ref-date\u0026#34;\u0026gt;{{ $page.Date.Format \u0026#34;2006-01-02\u0026#34; }}\u0026lt;/span\u0026gt; {{- if $page.Params.categories -}} \u0026lt;span class=\u0026#34;post-ref-category\u0026#34;\u0026gt;{{ delimit $page.Params.categories \u0026#34;, \u0026#34; }}\u0026lt;/span\u0026gt; {{- end -}} \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/a\u0026gt; \u0026lt;/div\u0026gt; {{- end -}} 3.2 使用自定义引用卡片 1 {{\u0026lt; post-ref \u0026#34;/post/wordpress/WordPress使用git-it-write插件配合github自动发布markdown.md\u0026#34; \u0026gt;}} 4. 相关文章功能 Hugo Stack 主题已经内置了相关文章功能，会自动在文章末尾显示相关文章：\n4.1 配置相关文章 在 hugo.yaml 中配置：\n1 2 3 4 5 6 7 8 9 related: includeNewer: true threshold: 60 toLower: false indices: - name: tags weight: 100 - name: categories weight: 200 4.2 在文章中手动指定相关文章 在Front Matter中添加：\n1 2 3 related: - \u0026#34;/post/article-1.md\u0026#34; - \u0026#34;/post/article-2.md\u0026#34; 5. 最佳实践 5.1 文件组织 建议按分类组织文章：\n1 2 3 4 5 6 7 8 content/post/ ├── hugo/ │ ├── hugo基础教程.md │ └── hugo高级技巧.md ├── wordpress/ │ └── wordpress插件推荐.md └── tools/ └── 开发工具推荐.md 5.2 引用规范 使用绝对路径：始终使用 /post/ 开头的路径 检查链接有效性：构建时会自动检查 ref 和 relref 的有效性 统一命名规范：使用一致的文件命名规范 添加描述性文本：不要直接暴露链接，添加有意义的描述 5.3 性能优化 使用缓存：Hugo会缓存引用结果 避免循环引用：不要创建文章间的循环引用 批量引用：在一篇文章中引用多个相关文章 6. 常见问题 6.1 引用失败 错误信息：\n1 ERROR REF_NOT_FOUND: Ref \u0026#34;article.md\u0026#34;: page not found 解决方法：\n检查文件路径是否正确 确认文件是否存在 使用绝对路径 /post/... 6.2 中文文件名问题 对于中文文件名，Hugo会自动处理，但建议在链接中使用英文slug：\n1 2 3 # Front Matter title: \u0026#34;中文标题\u0026#34; slug: \u0026#34;english-slug\u0026#34; 6.3 多语言支持 如果使用多语言，引用时需要指定语言：\n1 {{\u0026lt; ref \u0026#34;/post/article.zh-cn.md\u0026#34; \u0026gt;}} 总结 Hugo提供了多种文章引用方式，选择合适的方法可以提高用户体验和维护效率：\n日常引用：使用 ref shortcode 美观展示：使用自定义引用卡片 自动推荐：配置相关文章功能 性能优化：遵循最佳实践 通过合理使用这些引用功能，可以构建一个互联互通的知识体系，提高读者的阅读体验。\n相关文章 WordPress使用git-it-write插件配合github自动发布markdown 以前发布文章都是直接在wordpress后台手动编辑，手动上传文件，确认无误后再发布，整个过程比较耗时，并且有点麻烦。最近这两天忽然有一个想法：我直接写markdown然后，然后在wordpress中找支持markdown的编辑器插件，把我的内容直接粘贴进去，这样子不就方便很多了吗？ …\n2025-04-06wordpress Typora使用picgo-core配置上传图片到easyimage图床 typora是一个非常方便的markdown编辑器，如果我们不做配置，图片仅仅只是存储在本地磁盘，如果本地磁盘出现问题，那么图片就全没了，所以今天就研究一下搭配picgo-core来把插入的图片上传到图床，我这里使用的是easyimage图床。\n2025-04-05tools ","date":"2025-07-05T00:00:00Z","permalink":"https://konghanghang.github.io/iminling-pages/p/hugo%E6%96%87%E7%AB%A0%E5%BC%95%E7%94%A8%E5%AE%8C%E6%95%B4%E6%8C%87%E5%8D%97/","title":"Hugo文章引用完整指南"},{"content":"Hugo文章SEO配置完整指南 在Hugo中，正确配置SEO元数据对提高搜索引擎收录和排名至关重要。本文将详细介绍如何配置文章的各种SEO字段。\n📋 Front Matter中的SEO字段 1. description 字段（重要） description 字段是SEO中最重要的元数据之一：\n1 2 3 4 --- title: \u0026#34;文章标题\u0026#34; description: \u0026#34;这是一段精心编写的文章描述，长度控制在150-160字符内，准确概括文章内容，包含关键词。\u0026#34; --- 最佳实践：\n长度：150-160字符（中文约75-80字） 包含主要关键词 准确描述文章内容 吸引用户点击 2. excerpt 字段 excerpt 用于文章摘要显示：\n1 excerpt: \u0026#34;文章摘要内容，用于在文章列表中显示。\u0026#34; 3. keywords 字段 1 keywords: [\u0026#34;关键词1\u0026#34;, \u0026#34;关键词2\u0026#34;, \u0026#34;关键词3\u0026#34;] 🔍 Hugo的Description生成逻辑 Hugo按以下优先级生成meta description：\nFront Matter中的 description（最高优先级） 自动生成的 .Summary（从文章内容提取） 站点默认描述 查看生成逻辑的模板代码： 1 2 3 4 5 6 7 8 \u0026lt;!-- themes/hugo-theme-stack/layouts/partials/data/description.html --\u0026gt; {{ if .Description }} \u0026lt;!-- 使用Front Matter中的description --\u0026gt; {{ $description = .Description }} {{ else if .IsPage }} \u0026lt;!-- 使用文章摘要 --\u0026gt; {{ $description = .Summary }} {{ end }} 🎯 SEO优化的正确配置 示例1：使用自定义description 1 2 3 4 5 6 7 8 9 10 11 --- title: \u0026#34;Docker安装WordPress完整教程\u0026#34; description: \u0026#34;详细介绍使用Docker快速安装WordPress的步骤，包括环境配置、容器部署、数据库设置等实用技巧。\u0026#34; keywords: [\u0026#34;Docker\u0026#34;, \u0026#34;WordPress\u0026#34;, \u0026#34;安装教程\u0026#34;, \u0026#34;容器部署\u0026#34;] categories: - 教程 tags: - docker - wordpress - 部署 --- 示例2：依赖自动摘要 1 2 3 4 5 6 7 8 --- title: \u0026#34;Hugo主题开发指南\u0026#34; # 没有description字段，Hugo会自动提取文章开头作为摘要 categories: - 开发 --- Hugo是一个强大的静态网站生成器，支持多种主题定制。本文将详细介绍如何开发自定义Hugo主题，包括模板结构、样式配置等内容。 📊 验证SEO效果 1. 查看生成的HTML 1 2 3 4 5 # 构建站点 hugo --cleanDestinationDir # 查看meta标签 grep -E \u0026#34;(meta.*description|og:description)\u0026#34; public/path/to/article/index.html 2. 使用SEO工具 Google Search Console 百度站长工具 SEO检测工具 🚀 高级SEO配置 1. 结构化数据 1 2 3 4 5 6 7 --- schema: type: \u0026#34;Article\u0026#34; author: \u0026#34;作者名称\u0026#34; datePublished: \u0026#34;2025-01-07\u0026#34; dateModified: \u0026#34;2025-01-07\u0026#34; --- 2. Open Graph配置 1 2 3 4 5 6 --- og: title: \u0026#34;自定义OG标题\u0026#34; description: \u0026#34;自定义OG描述\u0026#34; image: \u0026#34;featured-image.jpg\u0026#34; --- 3. Twitter Cards 1 2 3 4 5 6 7 --- twitter: card: \u0026#34;summary_large_image\u0026#34; title: \u0026#34;Twitter卡片标题\u0026#34; description: \u0026#34;Twitter卡片描述\u0026#34; image: \u0026#34;twitter-image.jpg\u0026#34; --- 📝 最佳实践总结 1. Description写作技巧 关键词前置：重要关键词放在前面 动作导向：使用动词，如\u0026quot;了解\u0026quot;、\u0026ldquo;学习\u0026rdquo;、\u0026ldquo;掌握\u0026rdquo; 解决问题：明确说明文章能解决什么问题 避免重复：不要与title完全重复 2. 常见错误 ❌ 错误示例：\n1 2 3 description: \u0026#34;这篇文章很好，大家快来看看。\u0026#34; # 太模糊 description: \u0026#34;aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\u0026#34; # 太长 description: \u0026#34;\u0026#34; # 空描述 ✅ 正确示例：\n1 description: \u0026#34;详细介绍Hugo静态网站生成器的安装配置方法，包括主题选择、内容管理、部署流程等实用技巧。\u0026#34; 3. 工具推荐 字符计数器：确保描述长度合适 关键词工具：Google Keyword Planner SEO检测：Screaming Frog SEO Spider 🔧 实际应用示例 让我们看看一个完整的文章配置：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 --- title: \u0026#34;Linux服务器安全配置指南\u0026#34; description: \u0026#34;Linux服务器安全配置的完整教程，包括防火墙设置、SSH加固、用户权限管理等安全防护措施，保护服务器免受攻击。\u0026#34; excerpt: \u0026#34;系统化介绍Linux服务器的安全配置方法和最佳实践。\u0026#34; keywords: [\u0026#34;Linux\u0026#34;, \u0026#34;服务器安全\u0026#34;, \u0026#34;防火墙\u0026#34;, \u0026#34;SSH配置\u0026#34;, \u0026#34;安全防护\u0026#34;] date: 2025-01-07 lastmod: 2025-01-07 categories: - 运维 - 安全 tags: - linux - 安全 - 服务器 - 运维 author: \u0026#34;技术博主\u0026#34; --- 📈 SEO效果监控 1. 搜索表现 点击率（CTR） 展现次数 平均排名 关键词覆盖 2. 优化建议 定期更新description 分析搜索查询 优化关键词 监控竞争对手 通过正确配置这些SEO字段，您的Hugo博客将在搜索引擎中获得更好的表现！\n","date":"2025-07-04T00:00:00Z","permalink":"https://konghanghang.github.io/iminling-pages/p/hugo%E6%96%87%E7%AB%A0seo%E9%85%8D%E7%BD%AE%E5%AE%8C%E6%95%B4%E6%8C%87%E5%8D%97/","title":"Hugo文章SEO配置完整指南"},{"content":"以前发布文章都是直接在wordpress后台手动编辑，手动上传文件，确认无误后再发布，整个过程比较耗时，并且有点麻烦。最近这两天忽然有一个想法：我直接写markdown然后，然后在wordpress中找支持markdown的编辑器插件，把我的内容直接粘贴进去，这样子不就方便很多了吗？于是就找到了WP-Githuber-MD这个插件，再探索的过程中无意又发现了git-it-write这个可以自动化的插件，于是就开始了折腾之旅行。\n插件安装和配置 Git-it-write插件在Wordpress的插件库是可以找到的，直接搜索安装就可以了。安装后可以在设置中找到对这个插件的配置。\n仓库配置 想要配合github进行自动发布，首先要解决的就是从仓库里拉去到.md的文件，所以需要去配置一个git仓库，我们可以先创建好这个git仓库，然后再来进行配置。\n点击左上的add a new repository to publish posts form按钮来添加一个新的仓库：\n有几个地方需要设置一下：\n配置项 说明 Github username/owner 这个自己的github用户名 Repository name 仓库名称，新建或者已存在的一个仓库名称 Branch to publish from 仓库的分支，根据自己的仓库来设置，master, main等 Folder to publish from 我整个仓库都是需要发布的，而不是只发布其中一个目录，所以这里留空。 Post type to publish to 我要发布的是文章，自己根据自己的需求来选择。 其他的选项就默认了。\n因为我这里建的是一个私有的仓库，想要拉取到仓库里的内容，我这里需要配置一下github access token,填在General settings的位置。如果是public类型的仓库，可以尝试一下不配置或者也配置一下，因为我不是这种情况，所以没有进行详细的研究。下边就来看一下如何获取github access token.\n获取github access token 来到github的settings页面：登录github后，点击右上角的头像，就会看到有settings选项。进入settings后，拉到最下边找到developer settings选项，如下图：\n点击在personal access tokens中进行添加和删除等操作：\n点击右上角的Generate new token来新建一个token，设置页面如下：\n相关的配置项说明：\n配置项 说明 Token name 自定义的一个说明名称，可以随意配置 Description 说明，可以留空 Resource owner 正常情况下，选择自己的github用户就可以了 Expiration token的过期时间，根据自己的情况设置，我这里设置永不过期 Repository access 仓库访问权，我这里选择只给他访问特定的仓库 Permissions 这里需要注意了，Repository permission一定要点开，然后对每项进行设置，我这里每项都只给access权限。 设置完成后就可以生成token了，把生成的tokent填写在General settings处了：\nGithub username就是自己的github用户名。\n至此git it write插件就配置完成了。现在要做的就是在仓库里写一篇markdown格式的文档来进行发布了。\n发布 在我们写完markdown文件后，push到上边配置的git仓库中，下边就可以来进行发布操作了。\n在wordpress插件git it write插件中添加仓库后，可以看到如上图所示的内容，我们可以点击pull posts中git仓库中拉取markdown文件进行发布。点击后有两个选项，一个是只pull更新，另一个是pull所有文件。如果是第一次拉取仓库内容，就使用pull all the files拉取左右的内容，后续就可以使用pull only changes只拉取变更的内容。\n如果拉取有问题，也可以点击上边图片中的Logs来查看插件的日志来方便排查问题。截止到上边就已经差不多完成插件配置了。那么此时就需要我们每写完一篇文章就需要到wordpress的后台来进行手动pull一下，是不是也有点麻烦呢？接下来就讲一下如果来自动化发布。\nWebbook 配置 在git it write的配置页面可以看到webhook secret的配置选项，没错，这个就是和github的webhook进行联动的，需要我们在github中进行相关的配置。\n在github仓库的设置页面，我们可以进行webbook的配置，可以添加一个webhook,具体的webhook地址可以看git it write插件页面给的提示，那里会详细说明完整的webhook地址是什么。如下图是我的完整webhook地址，当时只有地址还是不行的，我们需要配置一个密钥，这个就自己根据自己的情况来进行配置，防止被别人猜到。\ngithub中添加webhook如下，需要填写url，content type以及secret，这里的secret和git it write中的是同一个。另外需要什么时候来触发这个webhook,我这里选择Just the push event.其他的大家根据需求来进行填写。\n经过上边的配置，我们在写好markdown文件后，只需要push到git仓库中，那么github就会触发webhook通知到wordpress中的git it write插件，插件就会来仓库中拉取markdown文件，然后进行发布。做到自动化处理发布动作。\nMarkdown 文件 经过上边的步骤基本已经可以正常的发布文章了，但是这里还有一个重要的问题就是发布后的文章的分类、url以及标签这些信息是怎么处理的？我们要怎么给指定呢？下边就来给大家介绍。\n在markdown文件中，每个文件的顶部可以使用yaml来设置一些属性信息，这些属性信息就可以来设置我们发布文章的一些属性信息。设置的格式如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 --- title: \u0026#34;Wordpress使用git-it-write插件配合github自动发布markdown\u0026#34; date: 2025-04-06 post_excerpt: 以前发布文章都是直接在wordpress后台手动编辑，手动上传文件，确认无误后再发布，整个过程比较耗时，并且有点麻烦。最近这两天忽然有一个想法：我直接写markdown然后，然后在wordpress中找支持markdown的编辑器插件，把我的内容直接粘贴进去，这样子不就方便很多了吗？于是就找到了WP-Githuber-MD这个插件，再探索的过程中无意又发现了git-it-write这个可以自动化的插件，于是就开始了折腾之旅行。 post_status: publish comment_status: open taxonomy: category: - wordpress post_tag: - wordpress - github - git-it-write - markdown slug: \u0026#34;wordpress-use-git-it-write-and-github-publish-markdown-file\u0026#34; --- 是以---开始，然后设置一些特殊的属性。我这里介绍一下我上边使用到的一些信息。\n属性 说明 Titile 发布文章的标题 date 发布文章的日志 post_excerpt 帖子摘录 Post_status 发布文章的状态，可以选择：publish, draft, pending, future. Comment_status 评论的状态，这个默认值是closed.所以如果想要打开文章的评论功能，这个值要给open Taxonmy 这里设置文章的一些属性 Category Taxonmy 的下级，文章的分类，这个是实际发布文章后的分类 post_tag Taxonmy 的下级，文章的标签，也是实际发布后文章的标签 slug 暂时也没发现有什么用处，本来以为是文章的自定义url，实际上不是。 我所使用到的就是上边这些属性，其他的属性暂时还没有使用到，如果有兴趣的小伙伴可以自己去看一下官方的文章，自行研究使用方法：Getting started.\n另外文章的自定义url是读取的md文件的文件名。\n另外，如果github仓库中的文章是有目录的，那么他会发布一个以文件夹命名的文章，暂时没有很好的解决这个问题，他只会发布一次，发布后改后私有的解决问题。\n以上就是Wordpress使用git-it-write插件配合github自动发布markdown文章的折腾过程，希望可以帮助到大家。\n","date":"2025-04-06T09:20:36Z","image":"https://images.iminling.com/app/hide.php?key=SlBudmJhK1kyNkJ5NGtnVm53c1kwOUpBdFNJd1I2dHR5NXk5VjM1QkNsN1VtWm9DVWNJdi9jdEEyL0o0eTZDTXJPNUhlT3c9","permalink":"https://konghanghang.github.io/iminling-pages/2025/wordpress-use-git-it-write-and-github-publish-markdown-file/","title":"WordPress使用git-it-write插件配合github自动发布markdown"},{"content":"typora是一个非常方便的markdown编辑器，如果我们不做配置，图片仅仅只是存储在本地磁盘，如果本地磁盘出现问题，那么图片就全没了，所以今天就研究一下搭配picgo-core来把插入的图片上传到图床，我这里使用的是easyimage图床。\npicgo可以直接安装官方app，也可以使用node命令去进行配置，我这里为了简单直接使用node的方式去配置，在此之前请确定在本机已正确安装了node的环境。我使用的是mac，且也已配置好brew环境，可以直接使用brew来进行安装。\n安装node 搜索可使用的node版本并安装，这里安装18版本。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # aaa @ Mac-mini-m4 in ~ [10:35:56] $ brew search nodejs ==\u0026gt; Formulae node nodenv node@22 node@20 node@18 node@16 node@14 ==\u0026gt; Casks nodeclipse # aaa @ Mac-mini-m4 in ~ [10:36:04] $ brew install node@18 ==\u0026gt; node@18 node@18 is keg-only, which means it was not symlinked into /opt/homebrew, because this is an alternate version of another formula. If you need to have node@18 first in your PATH, run: echo \u0026#39;export PATH=\u0026#34;/opt/homebrew/opt/node@18/bin:$PATH\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.zshrc For compilers to find node@18 you may need to set: export LDFLAGS=\u0026#34;-L/opt/homebrew/opt/node@18/lib\u0026#34; export CPPFLAGS=\u0026#34;-I/opt/homebrew/opt/node@18/include\u0026#34; 安装后还需要添加环境变量，通过上面给的命令来执行echo 'export PATH=\u0026quot;/opt/homebrew/opt/node@18/bin:$PATH\u0026quot;' \u0026gt;\u0026gt; ~/.zshrc，最后再刷新环境变量\n1 2 3 4 5 6 # aaa @ Mac-mini-m4 in ~ [10:38:36] $ source .zshrc # aaa @ Mac-mini-m4 in ~ [10:38:43] $ node -v v18.20.8 最后通过npm来安装picgo:\n1 2 # aaa @ Mac-mini-m4 in ~ [10:38:48] $ npm install picgo -g 安装情况后可以使用picgo set uploader来设置上传配置，但是默认情况下不支持自定义图床，只能选定他给的几种：\n1 2 3 4 5 6 7 8 9 10 # aaa @ Mac-mini-m4 in ~ [10:39:06] $ picgo set uploader ? Choose a(n) uploader aliyun tcyun smms github qiniu imgur ❯ upyun 安装web-uploader 通过easyimage官方的文档来看，应该是有一个插件可以安装来支持自定义图床上传的：使用PicGo上传.md, 插件的名称是web-uploader，那怎么安装呢？通过picgo的命令来查看：\n1 2 3 4 5 6 7 8 9 10 11 12 # aaa @ Mac-mini-m4 in ~ [10:54:19] $ picgo -h Usage: picgo [options] [command] Options: -v, --version output the version number -d, --debug debug mode -h, --help display help for command Commands: install|add [options] \u0026lt;plugins...\u0026gt; install picgo plugin uninstall|rm \u0026lt;plugins...\u0026gt; uninstall picgo plugin 可以看到可以使用install或add命令来安装。\n1 2 3 4 5 6 7 # aaa @ Mac-mini-m4 in ~ [11:10:45] $ picgo install web-uploader added 1 package, and audited 2 packages in 2s found 0 vulnerabilities [PicGo SUCCESS]: 插件安装成功 picgo的配置文件所在位置如下：\nLinux / macOS → ~/.picgo/config.json. Windows → C:\\Users\\[your user name]\\.picgo\\config.json. 查看里边的目录情况：\n1 2 3 4 5 6 7 8 9 # aaa @ Mac-mini-m4 in ~ [11:17:34] $ tree .picgo .picgo ├── config.json ├── i18n-cli ├── node_modules ├── package-lock.json ├── package.json └── picgo.log 在package里记录了所有的插件信息：\n1 2 3 # aaa @ Mac-mini-m4 in ~ [11:11:14] C:1 $ cat .picgo/package.json {\u0026#34;name\u0026#34;:\u0026#34;picgo-plugins\u0026#34;,\u0026#34;description\u0026#34;:\u0026#34;picgo-plugins\u0026#34;,\u0026#34;repository\u0026#34;:\u0026#34;https://github.com/PicGo/PicGo-Core\u0026#34;,\u0026#34;license\u0026#34;:\u0026#34;MIT\u0026#34;,\u0026#34;dependencies\u0026#34;:{\u0026#34;picgo-plugin-web-uploader\u0026#34;:\u0026#34;^1.1.1\u0026#34;}}% 配置自定义图床 安装web-uploader后，再次执行set uploader命令查看：\n1 2 3 4 5 6 7 8 9 10 11 # aaa @ Mac-mini-m4 in ~ [11:21:32] $ picgo set uploader ? Choose a(n) uploader smms github qiniu ❯ imgur upyun web-uploader aliyun (Move up and down to reveal more choices) 可以看到多了一个web-uploader选项，下边进行来设置：\n1 2 3 4 5 6 7 8 # aaa @ Mac-mini-m4 in ~ [11:21:32] $ picgo set uploader ? Choose a(n) uploader web-uploader ? API地址 https://images.xxx.com/api/index.php ? POST参数名 image ? 图片URL JSON路径(eg: data.url) url ? 自定义请求头 标准JSON(eg: {\u0026#34;key\u0026#34;:\u0026#34;value\u0026#34;}) ? 自定义Body 标准JSON(eg: {\u0026#34;key\u0026#34;:\u0026#34;value\u0026#34;}) {\u0026#34;token\u0026#34;:\u0026#34;aaaaaa\u0026#34;} 每个参数是什么意义可以参考使用PicGo上传.md,其中api地址是自己网站的地址，post参数和图片URL JSON路径是固定，自定义请求头标准JSON可以置空，自定义body标准JSON则是在easyimage后台获取到的token替换我上边的aaaaaa;\n另外需要自己开启支持API上传：\nTypora配置 在typora的设置中，选择插入图片时的动作，这里选择上传图片。\n主要是上传服务设置，因为我这里没有安装picgo的客户段，而是使用的picgo-core来搭配node使用，所以上传服务选择自定义命令，命令的内容是：\n{node位置} {picgo位置} u.\nnode的位置在安装node的时候就已经知道了，我们还把bin添加进了PATH中，具体位置：/opt/homebrew/opt/node@18/bin/node,那么安装的picgo在什么位置呢？通过以下命令来查看：\n1 2 3 4 5 6 7 8 9 10 # aaa @ Mac-mini-m4 in ~/.npm [12:01:34] $ npm list --depath=0 /Users/hangkong/.npm └── (empty) # aaa @ Mac-mini-m4 in ~/.npm [12:02:54] $ npm list --depath=0 --global /opt/homebrew/lib └── picgo@1.5.8 可以看到位置在/opt/homebrew/lib目录下，完整的路径为：/opt/homebrew/lib/node_modules/picgo/bin/picgo。\n那么设置的完整命令就是：/opt/homebrew/opt/node@18/bin/node /opt/homebrew/lib/node_modules/picgo/bin/picgo u。\n经过上边的配置，就可以在使用typora插入图片的时候直接上传的easyimage图床了。\n","date":"2025-04-05T02:38:24Z","image":"https://images.iminling.com/app/hide.php?key=ZXNZbUNpQ1NObTUvdVJuVFlEa0xZcURTZmgzM2FISnV5MHVGQjR4OVRGSXJSWHRORmFkSTFZdkRWaEd2UFI5bDh0VWttZTQ9","permalink":"https://konghanghang.github.io/iminling-pages/2025/typora-how-to-use-picgo-upload-image-to-easyimage/","title":"Typora使用picgo-core配置上传图片到easyimage图床"},{"content":"飞牛nas系统出来也有段时间了，一个很不错的nas系统，在以前的文章中也介绍过群晖nas系统的安装，今天就来一次尝鲜，安装一下fnOS，看一下群晖的系统和飞牛的系统有什么区别。接下来就开始安装折腾之路 - 飞牛私有云fnOS nas安装。\nPVE配置 首先要先去飞牛官网把官方镜像ISO文件给下载下来，上传到pve中，这个还有不清楚的可以参考Proxmox VE(PVE)8.0安装爱快ikuai虚拟机并直通网卡中对爱快ISO文件上传的步骤。\n常规 修改为自己想要的vmid 以及 名称，我这里名称填了103，可以修改自己喜欢的，比如飞牛NAS等。其他默认。\n[][5]\n操作系统 操作系统选择在飞牛官网下载的iso文件。其他的默认\n[][6]\n系统 机型这里选择q35，其他不变。\n[][7]\n磁盘 这里没有截图到，实际是和安装群群一样，把磁盘删除了，什么都不留。如果只是想体验则可以根据实际情况来分配硬盘大小。\n我这里是要把一个硬盘直通给飞牛的，所以我这里就把硬盘都给删除了 。\n如果只是用来体验，则可以给一个30G的磁盘。\ncpu cpu核心根据自己的情况来，我的J4125只有4个核心，所以全给了。类别选host。\n[][8]\n内存配置 内存根据自己的需求来给，建议2G以上，我这里给4G.\n[][9]\n网络 网络我这里直接默认，使用pve的网桥vmbr0就可以了。\n[][10]\n确认 都设置完成后对已设置的信息进行确认，基本不会有什么问题，完成。\n[][11]\n硬盘直通 经过上边设置后，需要再给nas系统一个磁盘，可以参考我在Proxmox VE(PVE)8.0安装黑群晖NAS并直通硬盘时的直通操作，基本是一样的。\n硬盘直通后，要看一下启动顺序，需要先从我们上传的iso镜像启动，如果没有问题就可以启动了。\nFnOS安装 经过上边的步骤，已经创建好了一个虚拟机。接下来就是对系统进行配置启动了。点击控制台查看启动。默认图形安装。\n选择安装位置，本文这里是选择直通的硬盘：\n下一步选择系统分区大小,官方默认给的是64G，这里直接按官方建议来：\n接下来就是安装了，等待安装成功就可以了。\n下一步就会出现重启了，重启后控制台会显示一下内容：\n会告诉登录的ip和端口，这里是http://192.168.1.47:5666,等下来浏览器直接输入这个地址来进行访问。\n初始化FnOS 系统设置 接下来对fnos进行初始化，访问上边的地址：\n初次进入后需要设置设备名称以及管理员信息。\n存储空间创建 设置后会进入系统，因为是第一次进入系统，系统会提示创建存储空间：\n点击立即创建，选择磁盘以及数据保护默认，我这里直接使用默认basic方式。\n下一步设置存储空间可以使用的用户以及可以使用的大小，我这里只有自己使用，容量不限制：\n下一步创建确认：\n对磁盘进行格式化：\n格式化完就创建成功了：\n查看创建的存储空间：\nFnOS文件系统 上边就已经完全安装好了飞牛NSA，飞牛的磁盘存储位置和群晖还是有一点不一样的，我们可以通过ssh登录进系统进行查看他的磁盘信息。\nssh登录信息为访问网页版的用户名和密码。使用访问网页的ip和22端口+用户名和密码来进行登录。\n1 2 3 4 5 6 7 8 9 10 aa@FnOS:/$ df -h Filesystem Size Used Avail Use% Mounted on udev 1.9G 0 1.9G 0% /dev tmpfs 394M 7.7M 386M 2% /run /dev/sda2 63G 9.1G 51G 16% / tmpfs 2.0G 1.4M 2.0G 1% /dev/shm tmpfs 5.0M 0 5.0M 0% /run/lock trimafs 1.8T 1.7T 58G 97% /fs /dev/mapper/trim_f9cc7969_89e3_4c0b_9857_bcec3a1144d7-0 1.8T 1.7T 58G 97% /vol1 tmpfs 394M 0 394M 0% /run/user/1000 可以看到飞牛的系统是放在/目录下的，63G, 而我直通的硬盘有两个目录/fs和/vol1。\n在我的文件自己创建的目录在/fs目录下： ```bash aa@FnOS:/fs/1000/ftp$ ls docker download ``` 直接使用应用商店安装的qb下载目录可以在qb的设置里看到，实际是在/vol1下。 aa@FnOS:/var/apps/qBittorrent/shares$ ls -alh total 8.0K drwxr-xr-x 2 root root 4.0K Jan 7 23:05 . drwxr-xr-x 6 root root 4.0K Jan 7 23:05 .. lrwxrwxrwx 1 root root 27 Jan 7 23:05 qBittorrent -\u003e /vol1/@appshare/qBittorrent 其他的目录信息大家根据情况再去研究。 qb下载 默认qb只能访问安装后设置里配置的目录，如果想要改变qb下载的目录，则需要去系统设置-应用找到qb，添加一下允许它访问的文件目录。\n下边是完整后的桌面预览图 ![fnos complete](https://images.iminling.com/i/2025/01/08/3b89be1091025e546acd4224064abb0a.webp) ","date":"2025-02-09T03:15:47Z","image":"https://images.iminling.com/i/2025/01/08/d3c94bd7539929c05abffe55a8295ea2.webp","permalink":"https://konghanghang.github.io/iminling-pages/2025/install-fnos-nas/","title":"Proxmox VE(PVE)8.0安装飞牛私有云fnOS – NAS"},{"content":"前两篇文章先讲了如何安装alist并添加常见网盘，以及如何把alist通过rclone挂载在本地硬盘实现像本地文件一样进行浏览，本篇文章咱们继续，介绍如何安装emby并对媒体进行添加进emby.\nemby安装 要安装emby首先要面临的就是emby版本选择问题，emby本身是一个收费软件，但是也有大佬们的破解版本，我这里选择amilys/embyserver 这个版本，可以去docker hub官方地址查看。确认镜像后，下边给出我的docker-compose.yaml配置文件:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 networks: mynet: external: true services: emby: image: amilys/embyserver container_name: emby restart: unless-stopped volumes: - ./config:/config - /data/movies:/data/movies:rslave ports: - 8096:8096 extra_hosts: - host.docker.internal:host-gateway networks: - mynet network不再多说了，自己创建的一个桥接网络。\n端口暴露8096出去，\nemby的配置文件在/config目录，把它挂载到本地方便后续进行修改。\n另外一个挂载路径就是本地的/data/movies挂载到容器的/data/movies目录。本地的/data/movies其实就是上篇文章通过rclone处理的alist中所有的文件。这里建议设置为一样的路径，方便后续在302播放的时候替换，不会遇到那么多麻烦。\n整体目录如下：\n1 2 3 4 root@docker:~/emby# tree -L 2 . ├── config └── docker-compose.yaml 然后就是启动容器docker compose up -d进行emby的配置了。\nemby初始化 启动容器后，可以通过ip:8096来访问刚启动的容器。下边来进行emby的一些初始化配置，首先是进行语言配置，选择chinese simplified(简体中文)，下一步\n设置完语言后就会提示创建用户,根据自己的需求创建用户以及设置用户名和密码。然后继续下一步\n之后就会让添加一个媒体库，这里可以先不添加，直接下一步，等完全配置好了之后再去配置媒体库相关的东西\n接下来是设置媒体库的偏好语言和地区，根据自己需求英文或者中文\n下边是配置远程访问，开启就好了\n下边是使用条例，接收继续下一步\n终于完成了,点击finish跳转。\n经过上边设置，emby就算是初始化好了，接下来就可以进行媒体库添加了。\n媒体库 进入到emby后台，找到媒体库菜单，就可以在这里进行添加媒体库了。\n添加媒体库时需要整理好分类,是电影、电视节目还是其他，方便emby正确刮削。\n根据情况配置上边的选项，配置好后emby就会开始进行刮削，完整后就可以在emby首页看到添加的目录下的所有电影了。\n截止到现在emby已经可以正确的播放视频了，但是此时播放网盘的内容是会经过搭建alist那台机器，等于是那台机器把媒体内容下载下来，然后送给我们的播放器进行播放，如果alist部署在本地播放倒是什么没什么，反正都要下载下来。如果alist部署在其他vps上，流量消耗是一个比较大的问题。如果是部署在家里但是需要在家庭以外的地方播放，这时候流量也会经过家里然后才到你在外边的设备，播放速度就取决于你的家庭宽带的上行了，一般上行所以都不会太大，所以我们需要配置302重定向，让播放设备直接和网盘进行交互，而alist服务器只是负责给你列出目录树，供我们浏览使用。下边就来讲一下如何进行302播放。\nembyExternalUrl实现302播放 本文主要介绍使用embyExternalUrl工具进行302播放。有大佬做了整合，弄了一个docker镜像：MediaLinker，降低了操作的复杂度，并且支持ssl证书，可以根据需求进行配置。docker compose文件内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 services: medialinker: container_name: medialinker image: thsrite/medialinker:latest restart: unless-stopped volumes: - ./data/:/opt/ environment: - AUTO_UPDATE=true - SERVER=emby - NGINX_PORT=8091 network_mode: host 具体环境信息可以看大佬的介绍，我这里使用emby且也不需要SSL，如上是最简单的配置了。启动后，在data目录下会有一个constant.js文件，我们需要改变其中emby、alist的一些配置，需要配置的地方如下图：\n根据上图可以看到有7项信息需要填写，主要分为两个大项，一个是emby的配置，一个是alist的配置。下边来详细说一下每个参数的配置。\nemby配置 emby需要三个参数，embyhost这个简单，就是我们打开emby的地址，安装的机器ip和docker-compose文件中的端口就可以了。\nembyApiKey需要在emby的后台去获取，路径如下，新建一个api密钥，然后填进去就可以了。\nmediaMountPath文件中介绍的也比较清楚：\n// 挂载工具 rclone/CD2 多出来的挂载目录, 例如将 od,gd 挂载到 /mnt 目录下: /mnt/onedrive /mnt/gd ,那么这里就填写 /mnt // 通常配置一个远程挂载根路径就够了,默认非此路径开头文件将转给原始 emby 处理 // 如果没有挂载,全部使用 strm 文件,此项填[\u0026quot;\u0026quot;],必须要是数组\n我们在上边安装alis和emby的时候，两个内部路径都是/data/movies，那么这个数组中就填/data/movies.\nemby的配置就完成了。\nalist配置 host也比较简单，我们怎么访问alist的就怎么写，一般是ip:5244.\nalist-token的获取路径如下：\n然后是否启用了sign，这个在往alist配置每个网盘的时候，我这边都是有开启的，所以这个参数我需要设置为true.\n签名有效期，按照他提供的路径也很容易找到，默认是0，我这里也把他改成12，两边同步。\n然后保存constant.js文件，此时需要再对medialinker容器进行一次重启，如果不重启，mediaMountPath不生效。\n如何判断是否成功了呢？可以查看medialinker的日志，docker compose logs -tf 来查看。如下我在第一次没有重启的情况去播放视频，看到有以下日志，找的还是默认的/mnt路径，并且可以看到我的服务器流量在疯狂的跑下行流量，说明是通过服务器下载后转给我的。\n经过对容器进行重启后，再次去播放视频，可以看到以下日志，读取到了我配置的/data/movies.\n经过以上就可以愉快的302直接播放云盘中的视频了。希望可以帮到大家。\n","date":"2025-01-04T09:48:58Z","image":"https://images.iminling.com/app/hide.php?key=QStIZ0I0Y3k4RmJmL1lZY3lLbjZDS0hqVkcxQjRVU21iZnlwaTJqRk83cm9VTE1EZzg2bmp6b2ErcmM4RkpsVUJDa3h4TEk9","permalink":"https://konghanghang.github.io/iminling-pages/2025/emby-install-and-configuration/","title":"私人影院之emby安装配置以及通过embyExternalUrl实现302播放"},{"content":"最近购买了两个服务器，其中一个带了一个1T的磁盘，另一个带了一个3T的磁盘，默认这两个磁盘都是没有挂载状态的，需要自己手动进行挂载，于是就开始了研究如何在linux中进行磁盘分区以及磁盘挂载，接下来记录一下折腾过程。\n3T盘挂载 磁盘查看 先使用fdisk查看磁盘\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 root@host:~# fdisk -l Disk /dev/sda: 20 GiB, 21474836480 bytes, 41943040 sectors Disk model: QEMU HARDDISK Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disklabel type: gpt Disk identifier: 0DA7595A-DE2A-1042-8C4F-3C883C4D7BA6 Device Start End Sectors Size Type /dev/sda1 262144 41943006 41680863 19.9G Linux filesystem /dev/sda14 2048 8191 6144 3M BIOS boot /dev/sda15 8192 262143 253952 124M EFI System Partition table entries are not in disk order. Disk /dev/sdb: 2.93 TiB, 3221225472000 bytes, 6291456000 sectors Disk model: QEMU HARDDISK Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes 可以看到/dev/sdb有一个2.93TB的硬盘，下边来对这个磁盘进行分区并添加。\n磁盘分区 传统的MBR（主引导记录）分区表只能支持最多2TB的磁盘，而我这个盘是3T的，需要使用GPT，这个格式支持超过2TB的磁盘，Linux支持GPT（GUID分区表）格式。对于大于2T的硬盘使用parted命令来进行处理。\n首先要确认是否已安装parted,如果没有安装使用一下命令进行安装：\n1 2 3 4 root@host:~# apt install parted Reading package lists... Done Building dependency tree... Done Reading state information... Done 然后执行parted /dev/sdb对/dev/sdb这个盘进行处理，输入命令后会进入命令模式，需要经过几个步骤\nmklabel gpt ，创建GPT分区表 mkpart primary ext4 0% 100% ，创建一个新分区，使用100%的磁盘空间 print ，显示设置的分区(可选操作) quit ，退出 完整的操作命令如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 root@host:~# parted /dev/sdb GNU Parted 3.5 Using /dev/sdb Welcome to GNU Parted! Type \u0026#39;help\u0026#39; to view a list of commands. (parted) mklabel gpt (parted) mkpart primary ext4 0% 100% (parted) print Model: QEMU QEMU HARDDISK (scsi) Disk /dev/sdb: 3221GB Sector size (logical/physical): 512B/512B Partition Table: gpt Disk Flags: Number Start End Size File system Name Flags 1 1049kB 3221GB 3221GB ext4 primary (parted) quit Information: You may need to update /etc/fstab. 分区完成。\n磁盘格式化 创建分区后，需要格式化为文件系统。我这里使用ext4格式，因为我只分了一个盘，所以这里是sdb1,如果有多个盘，需要分别对每个进行格式化：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 root@host:~# mkfs.ext4 /dev/sdb1 mke2fs 1.47.0 (5-Feb-2023) Discarding device blocks: done Creating filesystem with 786431488 4k blocks and 196608000 inodes Filesystem UUID: f2275364-6fa6-4ae0-a214-5bd98552f5b1 Superblock backups stored on blocks: 32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632, 2654208, 4096000, 7962624, 11239424, 20480000, 23887872, 71663616, 78675968, 102400000, 214990848, 512000000, 550731776, 644972544 Allocating group tables: done Writing inode tables: done Creating journal (262144 blocks): done Writing superblocks and filesystem accounting information: done 经过上边就已经对刚分的那个盘进行了格式化。\n磁盘挂载 接下来就是对这个盘进行挂载，我这里挂载到/data目录下，需要先创建/data这个目录，然后通过mount /dev/sdb1 /data命令，把/dev/sdb1挂载到/data目录：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 root@host:~# mkdir /data root@host:~# df -h Filesystem Size Used Avail Use% Mounted on udev 979M 0 979M 0% /dev tmpfs 198M 732K 198M 1% /run /dev/sda1 20G 2.1G 17G 12% / tmpfs 990M 0 990M 0% /dev/shm tmpfs 5.0M 0 5.0M 0% /run/lock /dev/sda15 124M 12M 113M 10% /boot/efi tmpfs 198M 0 198M 0% /run/user/0 root@host:~# mount /dev/sdb1 /data root@host:~# df -h Filesystem Size Used Avail Use% Mounted on udev 979M 0 979M 0% /dev tmpfs 198M 732K 198M 1% /run /dev/sda1 20G 2.1G 17G 12% / tmpfs 990M 0 990M 0% /dev/shm tmpfs 5.0M 0 5.0M 0% /run/lock /dev/sda15 124M 12M 113M 10% /boot/efi tmpfs 198M 0 198M 0% /run/user/0 /dev/sdb1 2.9T 28K 2.8T 1% /data 可以通过命令df -h查看磁盘挂载情况，如上是已经成功挂载了。\n磁盘开机自动挂载 经过上面的挂载后，如果系统重启，那么挂载就会失效，所以如果你希望磁盘在系统重启时自动挂载，可以编辑/etc/fstab文件：\n1 2 root@host-c:~# vim /etc/fstab /dev/sdb1 /data ext4 defaults 0 2 如上添加一行/dev/sdb1 /data ext4 defaults 0 2就可以重启后自动实现挂载。\n1T盘挂载 在3t盘挂载的教程中可以看出整个挂载过程分为：磁盘查看-磁盘分区-磁盘格式化-磁盘挂载-磁盘开机自动挂载共5个步骤，处理1T盘过程基本一致，只是在磁盘分区的时候有两种选择，第一种就还是使用到parted命令，另一种是使用fdisk命令。\n先来查看磁盘的分布\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 root@host:~# fdisk -l Disk /dev/sdb: 1000 GiB, 1073741824000 bytes, 2097152000 sectors Disk model: QEMU HARDDISK Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk /dev/sda: 20 GiB, 21474836480 bytes, 41943040 sectors Disk model: QEMU HARDDISK Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disklabel type: gpt Disk identifier: 0DA7595A-DE2A-1042-8C4F-3C883C4D7BA6 Device Start End Sectors Size Type /dev/sda1 262144 41943006 41680863 19.9G Linux filesystem /dev/sda14 2048 8191 6144 3M BIOS boot /dev/sda15 8192 262143 253952 124M EFI System Partition table entries are not in disk order. 可以看到有一个/dev/sdb: 1000 GiB的磁盘。\nfdisk命令 先来介绍一下fdisk命令，输入/dev/sdb开始进行分区，默认是创建MBR分区，下边每个Command (m for help)都是需要进行输入的地方。首先是输入o,创建一个MBR分区，然后是输入n来创建分区，partition type选择主分区p，分区号码我这里只需要一个分区，所以输入1，然后就是first sector和last sector默认直接回车就是整个盘。最后输入w来写入修改，就完成了分区。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 root@host:~# fdisk /dev/sdb Welcome to fdisk (util-linux 2.38.1). Changes will remain in memory only, until you decide to write them. Be careful before using the write command. Device does not contain a recognized partition table. Created a new DOS (MBR) disklabel with disk identifier 0x17afed0e. Command (m for help): o Created a new DOS (MBR) disklabel with disk identifier 0xa7272020. Command (m for help): n Partition type p primary (0 primary, 0 extended, 4 free) e extended (container for logical partitions) Select (default p): p Partition number (1-4, default 1): 1 First sector (2048-2097151999, default 2048): Last sector, +/-sectors or +/-size{K,M,G,T,P} (2048-2097151999, default 2097151999): Created a new partition 1 of type \u0026#39;Linux\u0026#39; and of size 1000 GiB. Command (m for help): w The partition table has been altered. Calling ioctl() to re-read partition table. Syncing disks. 然后就是对新建的分区进行格式化和挂载了。和3T盘操作一样。\nparted命令 parted不仅可以处理大于2T的，小于2T的也是可以处理的，下边就来看看具体怎么处理。\n1 2 3 4 5 6 7 8 root@host:~# parted /dev/sdb GNU Parted 3.5 Using /dev/sdb Welcome to GNU Parted! Type \u0026#39;help\u0026#39; to view a list of commands. (parted) mklabel msdos (parted) mkpart primary ext4 0% 100% (parted) quit Information: You may need to update /etc/fstab. 唯一的区别就是mklable命令，原来是gpt（GPT分区），现在改成msdos（MBR分区），其他命令都一样。分区完成后进行格式化，挂载等一系列操作。\n以上就是针对小于2T以及大于2T的盘的挂载教程，希望可以帮到大家。\n","date":"2024-12-04T15:04:19Z","image":"https://images.iminling.com/app/hide.php?key=STRHaU84cVVtSm1LSEZrWHVLdDhqbzZPUURSR0EzWDB5a3RJL2RIdWgwZUVHWTFNQjV6WEtndkhQQUcxb3VlQjNGNzg5eWc9","permalink":"https://konghanghang.github.io/iminling-pages/2024/linux-mount-new-disk/","title":"Linux管理磁盘分区-挂载新的磁盘到系统"},{"content":"上一篇文章介绍了对alist的安装，本篇文章则来介绍一下rclone把alist里挂载的网盘再套娃挂载到本地磁盘，为后续emby直接读取本地的挂载文件做准备。那么接下来就开始折腾rclone.\n配置文件 本文使用docker compose来进行安装，可以docker-hub找到rclone的官方镜像地址，安装可以参考rclone的官方安装教程。\n先要把rclone的配置文件给配置好，我这里只配置alist，所以直接给出配置文件内容方便大家快速使用:\n1 2 3 4 5 6 [alist] type = webdav url = http://alist:5244/dav vendor = other user = admin pass = x9WN7skj6o7_fqjd4F 如上配置，\n[]中的名称自己定义一个，\ntype固定为webdav，\nurl为alist的webdav的url，url地址在alist的文档中也有说明，就是自己alist的ip+端口然后拼上/dav就可以了。\nvendor值为other\nuser为自己的alist的用户名\npass为自己的alist的用户名密码，但是密码需要进行加密才行，所以可以使用下边的命令来生成自己密码的密文，\n生成加密密码：\n1 2 3 docker run --rm -it \\ rclone/rclone \\ obscure [替换为具体的密码] 执行命令后就会生成一个你密码的密文，然后替换在配置文件中就可以了。\n经过上边处理配置文件就处理好了，可以命名为rclone.conf，rclone的默认配置文件名就是这个，如果名字改动了，则需要在下边docker-compose配置文件的挂载时特殊配置。方便下边docker-compose文件使用。\ndocker compose 老规矩，所有的应用程序都使用docker compose安装，下边是docker-compose.yaml的完整配置：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 networks: mynet: external: true services: rclone: image: rclone/rclone:latest container_name: rclone restart: always cap_add: - SYS_ADMIN devices: - /dev/fuse security_opt: - apparmor:unconfined volumes: - ./config:/config/rclone - /data/movies:/data:shared - /tmp:/tmp command: [ \u0026#34;mount alist:/ /data --cache-dir /tmp --allow-other --vfs-cache-mode writes --allow-non-empty\u0026#34; ] networks: - mynet network网络配置我这里就不讲了，是我自己创建的一个桥接网络。\n这里主要说一下volumes和command, 其中cap_add，devices和security_opt有兴趣的同学可以自己去研究他的含义，这里直接按照我给的配置文件就行了。\nvolumes中/tmp，临时文件存放在目录，在command中指出了cache-dir的位置，然后挂载到宿住机的/tmp.\nrclone的配置在容器的/config/rclone目录下，我挂载到本地的config目录，把上边咱们生成的配置文件放在里边。\n/data/movies:/data则是目录的配置，先是在command中把咱们的远程alist中的/目录(alist:/)和rclone容器中的/data目录关联在一起，然后再通过volumes把容器中的/data挂载在宿主机的/data/movies下。通过这个目录挂载，咱们就可以在宿主机下/data/movies中浏览alist中所有挂载的文件信息，为后边emby添加影视库做准备。\n容器启动 上边的配置信息完成后，文件放到对应的目录下，我这边的目录结构如下：\n1 2 3 4 5 root@docker:~/rclone# tree . ├── config │ └── rclone.conf └── docker-compose.yaml 然后在rclone目录下执行docker compose up -d启动容器就可以了。\n如果配置没问题应该就可以在宿主机/data/movies目录下看到alist中的网盘和所有文件了。\n以上就是折腾rclone和alist的过程，把alist挂载到本地，想本地目录文件一样来进行浏览，方便后续emby进行影视库的添加。\n","date":"2024-10-13T02:04:10Z","image":"https://images.iminling.com/app/hide.php?key=bEt3WUtUZk13dFI3Z0FyckVUZGdnQS94cHhoaHlzMVdsNGp1c0tHVG0vVjhLRHZYbzE2Unl1VlVPdWpFUjdqMllSZE5jVGc9","permalink":"https://konghanghang.github.io/iminling-pages/2024/install-rclone-and-configuration/","title":"私人影院之rclone安装以及通过WebDav配置alist"},{"content":"前段时间写了一篇如何搭建小雅alist的文章，使用小雅的媒体库来进行观影，但是这种有一个问题就是小雅的库更新的不是很快，而且如果我想在电视上观看比较麻烦，就算搭配emby,也无法避免资源更新慢的问题。所以就想着使用自己的网盘配合自己搭建的alist服务端，来进行资源快速入库，方便自己快速观看。那么接下来就详细说明一下自己的搭建过程。\nalist服务端 我这里使用docker compose来搭建alist server,alist提供了两个版本的镜像，一个是普通的版本，一个是带aria2下载的版本，根据自己的需求进行安装，安装文档参考官方文档。\n我的docker-compose.yaml如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 networks: mynet: external: true services: alist: image: xhofe/alist-aria2:latest container_name: alist restart: unless-stopped volumes: - ./data:/opt/alist/data networks: - mynet ports: - 15244:5244 extra_hosts: - host.docker.internal:host-gateway environment: - PUID=0 - PGID=0 - UMASK=022 - TZ=Asia/Shanghai 我的目录分配如下：\n1 2 3 . ├── data └── docker-compose.yaml 整体配置是比较简单的，我使用了自己的网络mynet，而不是让docker自建一个网络，方便后续容器之间的项目访问。\n按照上边配置好后直接docker compose up -d运行起来容器。之后通过访问ip:15244(我这里映射到主机的15244端口了)，默认admin用户和密码，进行登录并修改密码。容器启动成功，alist的服务端搭建就算完成了。\n网盘添加 我这里主要添加三种类型，天翼云盘，115网盘，本地smb，下边就看一下每种网盘是需要怎么来添加。\n天翼云盘 我家里使用的是电信的宽带，送了天翼网盘的会员，个人和家庭分别是4TB，整体也不算少。\n进入到alist的管理界面\n点击存储-添加,然后选择天翼云盘客户端(官方建议的类型)。然后就可以看到很多选项需要填写，具体的填写操作步骤参考官方文档。\n挂载路径是最终显示在alist主页的名称，需要唯一。\n缓存过期时间根据自己的需求来定义，比如我添加了一个文件想要快一点能刷新出来，那么我就定义短一点(比如1分钟)，这个根据自己需求来定。\nWebDAV策略建议都使用302重定向，这样子在通过WebDAV访问alist服务端的内容的时候，实际上会重定向到网盘内真实的路径，等于直接访问网盘。\n启用签名选项如果后续是需要配合emby实现302播放，一定要打开，一定要打开，一定要打开。\n用户名就是天翼云盘登录的手机号。\n密码是天翼云盘登录的密码。\n根文件的id根据自己需求，如果只是想把网盘内的某一个目录添加到alist中，那就按照官方文档里的方法找到对应的文件夹id。\n类型有家庭云和个人云，family id在是选择家庭云的时候需要填写，官网里都有介绍。我这里就是家庭云。\n基本上述搞定就可以添加成功了。\n115网盘 基本和天翼云盘添加流程差不多，驱动类型选择115网盘,挂载路径、缓存过期时间、WebDAV策略、启用签名四个选项和天翼云盘意向逻辑，进行处理就行了。有不明白的可以参考官方文档。\ncookie和Qrcode二选一，官方文档也有详细的介绍，包括根文件夹ID，都有详细的介绍，参考文档就可以了。感觉Qrcode会简单一点。我是直接使用的抓包软件抓的应用的cookie。这里有一个事项需要注意一下，如果使用了手机端软件，后续在网页登录的时候最好选择用手机扫码登录，要不然可能会把手机应用端挤掉导致cookie失效。\nSMB添加 有些文件没有放在网盘，而是放在自己本地或者放在本地nas中，比如我上篇文档也介绍了Proxmox VE(PVE)8.0安装黑群晖NAS并直通硬盘，这样子想要在alist中把nas中的资源添加进去，就需要使用到SMB一些了，nas中是有开启这个功能的。\n添加驱动类型选择SMB\nsmb是本地文件，启用签名就可以不用开了。地址、用户名、密码和分享名称(smb中的目录)根据自己的需求填写就可以了。\n总结 我这里介绍了三种网盘的添加方式，其他的网盘也都大同小异，比如添加阿里云盘等。那么搭建alist服务端并添加网盘，就介绍到这里。希望可以帮到大家。\n接下来还会介绍利用rclone挂载alist，然后让emby来使用并实现302播放。\n","date":"2024-09-21T09:56:03Z","image":"https://images.iminling.com/app/hide.php?key=ZVpuQ3crbnpMRHc2N2lQQktsMm93TkVobGtsOXZrV2ZsUUYyajMxd1FuSlFXSW5iK0wxRUxPcEYvcEhDU0NkSnJJQzdnT289","permalink":"https://konghanghang.github.io/iminling-pages/2024/build-alist-server/","title":"私人影院之搭建自己的alist服务端并添加常见网盘"},{"content":"申请ae信用卡有段时间了，中间也想过要去申请ae的checking账户，网上搜到原来是有开户奖励的，但是我想申请的时候是没有开户奖励的，所以就一直拖着。最近收到了ae checking账户的开户奖励邀请，是发邮件过来邀请说开户后3个月内存1000刀或更多，就可以拿到200刀奖励，于是就开启了申请之路。\n收到的邮件信息如下：\n还没有申请ae信用卡的同学可以参考我的另一个文章：使用ITIN申请American Express(美国运通)信用卡进行申请。\n申请 按上边邮件里的提示，直接点击Explore Now进行跳转浏览器进行申请，点击后跳转到介绍页：\n可以看到Apply Now下边有一行小字介绍:现在接受至少35天的会员申请。直接点击申请跳转下一步：\n如上，其中邮箱，手机号和家庭住址是已经默认填入且不可更改，我们只需要选择职业和填写SSN或者ITIN就可以了，下边还有一个W-9税收预扣状态证明，问美国国税局是否已通知您需要缴纳备用预扣税,选择NO，选则NO后会有下边的一些选项让确认，大概内容如下：\nIRS 税收预扣证明 通过选择此选项，我根据伪证处罚规定证明：\n随此申请提交的纳税人识别号 (TIN) 是我的正确 TIN，并且 我无需缴纳备用预扣税，因为：(a) 我免于缴纳备用预扣税，或 (b) 我尚未收到美国国税局 (IRS) 的通知，告知我由于未报告所有利息或股息而需要缴纳备用预扣税，或 (c) IRS 已通知我，我不再需要缴纳备用预扣税，并且 我是美国公民或其他美国人，并且 此表格中输入的表明我免于缴纳 FATCA（海外账户税收合规法案）代码（如果有）是正确的。 继续往下填写，Electronic Delivery电子交付，同意，后续银行会使用电子方式(邮件)来通知一些账户等信息。\n申请过程要填写的内容不是很多，经过上边的填写，需要我们处理的内容已经结束了。接下来就是Agree \u0026amp; Submit.\n申请结果 当我们提交后，基本上会立马得到结果，\n此时邮件也会收到一封通过的邮件：\n可以看到5-7个工作日会收到debit card,并且如果60个日历日没有往里边存款，这个账户就会被关闭。至此申请基本就完成了。接下来就是等待房东通知收到邮件了。\n收到邮件 说的是5-7个工作日，实际上速度很快，第二天就发邮件通知说已经发出。\n又等待了一天房东通知收到了邮件,然后就是让房东进行转寄，目前已经转寄出了，按DHL的速度，应该很快就可以收到邮件了。等到收到邮件后再看后续如何进行存款操作。\n","date":"2024-09-21T08:02:37Z","image":"https://images.iminling.com/app/hide.php?key=SkV2Smk4MEFjeVZ4K1NKZTlPS24vZG1XbVZ3eXUxYm1HVEVZdnIrbGI0TjJZVWhsNnN6VEFtZWtvTHBwYmtoOXUxMzZlRlU9","permalink":"https://konghanghang.github.io/iminling-pages/2024/apply-american-express-checking/","title":"American express checking账户申请"},{"content":"前段时间通过pve安装ikuai,openwrt以及使用lxc安装了docker,之后就一直稳定使用，J4125上有一个2T的硬盘，于是就想着折腾一下在上边安装一下黑群晖，体验一下nas系统。于是就又开始了折腾之路，又学习了很多知识。下边就记录一下我折腾的过程。\n准备 其实在开始装nas之前我看了很多教程，里边只是提供安装过程，并提供对应的安装包。说实在的，虽然很贴心，但是每个人的主机不尽相同，适合他的nas包不一定适合我，那么自己应该选择什么nas包呢？他们基本都没有说明，但是基本都是安装DS918+。于是在b站找到了一个版本选择教程，腾讯文档地址：RR型号列表。然后又看了rr安装，使用rr安装很方便：RR地址。\n直接下载一个最新RR的镜像就可以了。至于nas的版本，两个选择，DS918+和SA6400，两个版本都是视频中推荐的版本，如果cpu是10代以后选择SA6400，如果10代以前则两个都可以。\n安装 新建虚拟机 下载好镜像后就需要在pve中进行新建虚拟机了。步骤和openwrt差不多。\n常规选项：只需要填写一个名称就可以了。\n操作系统：选择不使用任何介质。\n系统：只需要将机型设置为q35，其他默认。\n磁盘：直接把磁盘删除。\nCPU：核心数根据自己的cpu设置，我这里给4.另外类别下拉到最后，选择host模式。\n内存：内存给2-4GB都可以，我这里给4G.\n网络：默认。模型为:VirtIo(半虚拟化)。\n然后就是确认刚才填的信息，确认就可以了。\n经过上边已经创建好了一个虚拟机，下边还需要上传刚才下载的rr镜像。\n镜像上传 如图的位置进行上传。\n接下来在shell中使用命令将黑群晖的引导文件rr导入到创建好的DSM虚拟机，进入到pve系统的shell中执行。\n命令如下：qm importdisk 编号 /var/lib/vz/template/iso/rr.img local-lvm , 其中编号为刚创建的虚拟机编号，rr.img的镜像上传路径基本不会有不同，基本都是在/var/lib/vz/template/iso目录下 再加上镜像名称，我这里就是rr.img。\n我的完整命令如下：qm importdisk 104 /var/lib/vz/template/iso/rr.img local-lvm。执行成功后可以在nas虚拟机的硬件里看到一个未使用的磁盘，双击可添加磁盘：\n总线设备选sata，磁盘映像默认就是刚看到的那个未使用的磁盘。其他的默认就可以了。\n硬盘直通 经过上边的设置基本就可以了，此时还需要给nas添加一个磁盘。在pve的shell中通过命令找到我的固态盘ls -l /dev/disk/by-id/：\n可以看到ata开头的ZHITAI就是我的固态盘了。复制完整的名称：ata-ZHITAI_SC001_XT_2000GB_ZTB502TAB2404507RX。\n然后通过命令直通给nas，set后边就是虚拟机的编号，我这里是103，后边\u0026ndash;satax 根据自己的定义，刚添加的引导盘占了sata0,所以我这里就使用sata1 后边就是完整的磁盘路径 /dev/disk/by-id/拼上的判断完整名。\n1 2 root@pve:~# qm set 103 --sata1 /dev/disk/by-id/ata-ZHITAI_SC001_XT_2000GB_ZTB502TAB2404507RX update VM 103: -sata1 /dev/disk/by-id/ata-ZHITAI_SC001_XT_2000GB_ZTB502TAB2404507RX 执行完成后就可以看到新添加的磁盘了： 然后修改启动顺序后就可以启动了。\n把sata0设置为第一位：\n启动成功后，在控制台中可以看到提示，会让访问一个ip:7681的网址去进行初次设置。\n引导编译 访问7681端口的那个网址\n先进行语言设置，选择Choose a language，找到zh-CN,切换语言为中文。\n型号选择：我这里选择SA6400\n版本选择：我这里选择DSM7.2\n弹出的版本页面，点击URL会自动下载当前引导的系统文件（建议使用此方式下载，避免在群晖官网下载错系统），下载好的系统文件后缀为pat，然后点击确认。下边初始化会用到。\n然后选择编译引导。\n只需要等待。\n编译好引导后会自动跳转到主菜单的启动选项，直接点击启动即可。\n正常开机后，可以再次在控制台看到让访问ip:5000的端口，此时说明安装已经ok了。\nNAS初始化 接下来就是访问ip:5000来进行NAS的初始化,我这里的ip是192.1681.42:5000\n安装。\n选择引导编译阶段下载的pat文件。\n提示会删除硬盘数据，继续进行确认。\n等待安装。安装后就是重启，提示大概需要10分钟，实际上我等了3分钟就可以了。\n重启完成后就会提示安装组件：\n套件安装完成后进入安装引导：\n进入用户名和密码设置：\n接下来的更新就不需要了自动安装了：\n账号创建跳过：\n用户体验不勾选，提交：\n经过上边的一系列设置，终于来到了nas的桌面中。\n桌面设置 群晖套件：不用了，谢谢。\n双重2FA不开启：\n下一步账户保护不开启。\n终于都设置完了。。。\n磁盘设置 经过上边的设置，终于提示要设置磁盘了。\n点击开始进行设置：\nraid类别根据自己的需要选择，我这里 就一个硬盘，直接选择basic类型。继续下一步,选择硬盘，我这里需要一个硬盘： 继续下一步，跳过硬盘检查：\n继续下一步配置磁盘容量：\n直接最大化，整个都分配给nas，继续下一步文件系统：\n这里我就选择他推荐的，继续下一步配置加密：\n我这里不加密，默认，继续下一步，对刚才的配置在进行概览：\n配置无问题应用就可以了。终于整个nas都配置后了。\n最后再上一个桌面显示的图片：\n以上就是pve安装黑群晖的折腾记录。\n","date":"2024-09-16T10:00:29Z","image":"https://images.iminling.com/app/hide.php?key=NFRXQWhja0FLK28xVDVKMjg3V1dLL0xOYi9sYmloRVIra2YveWJQNVNTY1NVempCcDZMUjNrKzI1NkZmL3o0WlJJTzI2TGc9","permalink":"https://konghanghang.github.io/iminling-pages/2024/pve-install-nas/","title":"Proxmox VE(PVE)8.0安装黑群晖NAS并直通硬盘"},{"content":"在公司有两台电脑，其中一台正常使用的工作电脑(A)，另一台(B)想要部署一些服务，当做一台服务器来使用，于是就是在B机器上启用了WSL服务，并安装了Ubuntu 22。但是这里遇到一个问题，我总不能一直远程桌面从A中来通过SSH操作B电脑，于是就开始折腾在B电脑开启Ubuntu的远程访问，下边记录一下折腾过程。\n准备 A电脑需要有SSH远程访问工具，使用自带的powershell或者其他第三方的工具都是可以的。\nB电脑需要开启WSL并安装好Ubuntu子程序。\n开启远程访问 首先需要在B电脑安装ssh-server服务:\n1 2 3 4 ai@DESKTOP-KKMQ55S:/etc/apt$ sudo apt install openssh-server -y Reading package lists... Done Building dependency tree... Done Reading state information... Done 等待安装成功后就可以对ssh服务进行启用：\n1 2 3 4 ai@DESKTOP-KKMQ55S:~$ sudo service ssh restart * Restarting OpenBSD Secure Shell server sshd [ OK ] ai@DESKTOP-KKMQ55S:~$ service ssh status * sshd is running SSH服务启动后还需要获取当前ubuntu的ip才能进行访问，WSL安装的ubuntu默认无法使用ifconfig命令，需要安装net-tools才可以使用，下边进行安装net-tools以及查看ip地址：\n1 2 3 4 5 6 7 ai@DESKTOP-KKMQ55S:~$ sudo apt install net-tools Reading package lists... Done Setting up net-tools (1.60+git20181103.0eebece-1ubuntu5) ... Processing triggers for man-db (2.10.2-1) ... ai@DESKTOP-KKMQ55S:~$ ifconfig eth0: flags=4163\u0026lt;UP,BROADCAST,RUNNING,MULTICAST\u0026gt; mtu 1500 inet 172.17.33.211 netmask 255.255.240.0 broadcast 172.17.47.255 如上，通过ifconfig命令查看到ubuntu机器的ip是172.17.33.211，那么可以在B机器中进行远程ubuntu机器，看一下是否可以正常远程：\n1 2 3 4 5 6 C:\\Users\\ai001\u0026gt;ssh ai@172.17.33.211 ai@172.17.33.211\u0026#39;s password: Welcome to Ubuntu 22.04.3 LTS (GNU/Linux 5.10.16.3-microsoft-standard-WSL2 x86_64) Last login: Fri Aug 16 16:15:43 2024 from 127.0.0.1 ai@DESKTOP-KKMQ55S:~$ 可以看到才已经正常开启了ssh并可以连接。\n其他机器访问 上边已经对WSL的Ubuntu开启了SSH访问，接下来还需要通过其他的机器来连接这个机器，连接示意图如下：\n需要从电脑A访问电脑B，然后电脑B再访问WSL子系统的ubuntu.使用电脑B的ip是无法直接访问到Ubuntu系统的，\n这时候就需要在电脑B中进行代理设置，需要以管理员运行Powershell工具，然后执行以下命令，listenport和listenaddress是指电脑B监听的地址和端口，connectport和connectaddress是指需要代理到的地址和端口，我这里是从电脑B的22端口到Ubuntu的22端口，所以端口都是22，ubuntu的ip这里写成了localhost，在上边咱们获取到的ip是172.17.33.211，写成这localhost和172开头的ip应该都是可以的，我这里只是测试了localhost,是可以正常联通的，有兴趣的同学可以自行测试一下。\n添加protproxy的语法可以参考微软官方文档：Netsh interface portproxy commands\n1 2 3 4 5 6 7 8 9 PS C:\\Users\\ai001\u0026gt; netsh interface portproxy add v4tov4 listenport=22 listenaddress=0.0.0.0 connectport=22 connectaddress=localhost PS C:\\Users\\ai001\u0026gt; netsh interface portproxy show v4tov4 侦听 ipv4: 连接到 ipv4: 地址 端口 地址 端口 --------------- ---------- --------------- ---------- 0.0.0.0 22 localhost 22 经过上边的步骤后，我们还需要对电脑B进行防火墙放行22端口的入站流量，命令如下，name可以自定义，我这里是对ssh放行的，所以取名字就叫ssh，官方文档\n1 PS C:\\Users\\ai001\u0026gt; netsh advfirewall firewall add rule name=ssh dir=in action=allow protocol=TCP localport=22 然后就可以在电脑A通过电脑B的22端口访问到电脑B的WSL Ubuntu子系统了。\n1 2 3 4 k@admin:~$ ssh ai@192.168.6.39 Welcome to Ubuntu 22.04.3 LTS (GNU/Linux 5.10.16.3-microsoft-standard-WSL2 x86_64) Last login: Sat Aug 17 14:36:06 2024 from 172.17.32.1 ai@DESKTOP-KKMQ55S:~$ 以上就可以完成直接从A电脑访问B电脑的linux服务器，可以直接在上边愉快的部署服务了。\n其他服务访问 在WSL的Ubuntu中部署其他的服务，然后根据服务占用的端口，需要再去配置电脑B的端口转发，转发到Ubuntu的对应端口去，这里我尝试了部署一个Java的tomcat服务，占用了18080端口，我通过上边的配置代理命令，connectaddress还是localhost,此时是无法访问的，然后对代理进行删除，改成了具体的172.17.33.211后，再通过192.168.6.39:18080就可以正常访问了。\n1 2 3 4 5 6 7 8 9 10 PS C:\\Users\\ai001\u0026gt; netsh interface portproxy add v4tov4 listenport=18080 listenaddress=0.0.0.0 connectport=18080 connectaddress=172.17.33.211 PS C:\\Users\\ai001\u0026gt; netsh interface portproxy show all 侦听 ipv4: 连接到 ipv4: 地址 端口 地址 端口 --------------- ---------- --------------- ---------- 0.0.0.0 22 localhost 22 0.0.0.0 18080 172.17.33.211 18080 如果对代理规则或者防火墙配置错误可以通过以下命令来进行删除，代理规则根据监听的端口和ip来进行删除，防火墙则通过name来进行删除。\n1 2 3 4 5 PS C:\\Users\\ai001\u0026gt; netsh interface portproxy delete v4tov4 listenport=18080 listenaddress=0.0.0.0 PS C:\\Users\\ai001\u0026gt; netsh advfirewall firewall delete rule name=tomcat 已删除 1 规则。 确定。 以上就是WSL配置SSH远程访问的过程，并对特定服务的特定端口进行代理转发，实现访问。\n","date":"2024-08-17T07:12:52Z","image":"https://images.iminling.com/app/hide.php?key=ektqWVRFVFhvR1dxYVh3L2tER0pPa0dsR00zZUxYZGJHbnNaY1lZankzNEpyMzgyT0ZoclN3bG5CQkVhajB6cjh0bVl3R0U9","permalink":"https://konghanghang.github.io/iminling-pages/2024/wsl2-ubuntu-open-ssh-remote-login/","title":"WSL2 Ubuntu开启SSH并配置远程登录"},{"content":"在前边的文章中介绍了如何快速的搭建小雅alist来满足大家的观影需求，但是有一些剧小雅更新没那么及时，这时候就需要大家八仙过海了。如何及时找到自己要观看的剧，并成功观看呢？下边就带着大家一起使用aliyunpan-sync工具来同步阿里云盘的数据。\n网盘选择 这里为什么要选择阿里云盘呢？因为阿里网盘资源比较多，更新也比较快，然后网上也找了同步阿里云盘的同步工具：aliyunpan-sync，理论上115，百度云，夸克这些网盘也都是ok的，主要是把文件同步到本地，具体的网盘的同步工具就需要大家自己去找了。我这里只带着大家实现阿里云盘的同步。另外推荐给大家一个电报的阿里云盘的资源通知群，资源更新还是挺及时的：https://t.me/yunpanpan。\n安装aliyunpan-sync 我这里使用的是docker compose进行的安装，如果还没有安装docker的同学可以参考的我的文章把docker 给安装一下：docker安装。\n获取阿里云盘token 要想从阿里云盘里下载文件，肯定是需要先登录阿里云盘才能进行数据同步，如何登录阿里云盘aliyunpan-sync工具里也有具体的说明：登录阿里云盘，需要先在release页面下载一个对应系统的release，我的操作系统是mac m1芯片我就下载arm那个\n然后对文件进行解压，使用终端进入到对应的目录里，看到有一个aliyunpan的文件，执行这个文件获取登录链接，然后在网页端进行扫码登录就可以了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # k @ Mac-mini in ~/Downloads/aliyunpan-v0.3.2-darwin-macos-arm64 [10:03:26] $ ls README.md manual.md sync.sh webdav.sh aliyunpan plugin sync_drive aliyunpan_config.json sync.bat webdav.bat # k @ Mac-mini in ~/Downloads/aliyunpan-v0.3.2-darwin-macos-arm64 [10:03:28] $ aliyunpan login zsh: command not found: aliyunpan # k @ Mac-mini in ~/Downloads/aliyunpan-v0.3.2-darwin-macos-arm64 [10:03:42] C:127 $ ./aliyunpan login 请在浏览器打开以下链接进行登录，链接有效时间为5分钟。 注意：你需要进行一次授权一次扫码的两次登录。 https://openapi.alipan.com/oauth/authorize?client_id=cf9f70e8fc6143031375\u0026amp;redirect_uri=https%3A%2F%2Fapi.tickstep.com%2Fauth%2Ftickstep%2Faliyunpan%2Ftoken%2Fopenapi%2F0bd327267c41f7b2fcadf927%2Fauth2\u0026amp;scope=user:base,file:all:read,file:all:write 请在浏览器里面完成扫码登录，然后再按Enter键继续... 打开url就需要使用手机端的阿里云盘进行扫码登录，提示进行授权：\n根据需要选择授权范围，我这里把备份盘和资源库都进行授权，其实就是整个阿里云盘这个工具都可以访问。然后就是回到终端看到具体的token。保存好这个token.\ndocker镜像启动 我这里使用的是docker compose来进行安装的，我的文件目录如下：\n1 2 3 4 5 6 7 8 9 10 11 12 $ tree . ├── config ├── docker-compose.yaml ├── js │ ├── download_handler.js.sample │ ├── sync_handler.js │ ├── sync_handler.js.sample │ ├── token_handler.js │ ├── token_handler.js.sample │ └── upload_handler.js.sample └── sync_drive config目录是用来挂在配置文件的，等下token是要填在这个目录下的aliyunpan_config.json文件里的。\njs目录是用来做一些脚本处理，用来控制什么文件可以上传，什么文件可以下载，以及进行一些通知操作的。\nsync_drive是保存数据库的信息，用来记录同步的一些信息，即使容器销毁，同步数据库还可以用于以后使用。\n具体的docker-compose.yaml文件内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 version: \u0026#39;3\u0026#39; services: sync: image: tickstep/aliyunpan-sync:v0.3.2 container_name: aliyunpan-sync restart: unless-stopped volumes: # （必须）映射的本地目录 - /data/webdav/data:/home/app/data:rw # （可选）可以指定JS插件sync_handler.js用于过滤文件，详见插件说明 #- ./config/sync_handler.js:/home/app/config/plugin/js/sync_handler.js - ./js:/home/app/config/plugin/js/ # （推荐）挂载sync_drive同步数据库到本地，这样即使容器销毁，同步数据库还可以用于以后使用 - ./sync_drive:/home/app/config/sync_drive # （必须）映射token凭据文件 - ./config/aliyunpan_config.json:/home/app/config/aliyunpan_config.json extra_hosts: - host.docker.internal:host-gateway environment: # 时区，东8区 - TZ=Asia/Shanghai # 下载文件并发数 - ALIYUNPAN_DOWNLOAD_PARALLEL=2 # 上传文件并发数 - ALIYUNPAN_UPLOAD_PARALLEL=2 # 下载数据块大小，单位为KB，默认为10240KB，建议范围1024KB~10240KB - ALIYUNPAN_DOWNLOAD_BLOCK_SIZE=1024 # 上传数据块大小，单位为KB，默认为10240KB，建议范围1024KB~10240KB - ALIYUNPAN_UPLOAD_BLOCK_SIZE=10240 # 指定网盘文件夹作为备份目标目录，不要指定根目录 - ALIYUNPAN_PAN_DIR=/来自分享 # 备份模式：upload(备份本地文件到云盘), download(备份云盘文件到本地) - ALIYUNPAN_SYNC_MODE=download # 备份策略: exclusive(排他备份文件，目标目录多余的文件会被删除),increment(增量备份文件，目标目录多余的文件不会被删除) #- ALIYUNPAN_SYNC_POLICY=increment # 备份周期, 支持两种: infinity(永久循环备份),onetime(只运行一次备份) #- ALIYUNPAN_SYNC_CYCLE=infinity # 网盘：backup(备份盘), resource(资源盘) - ALIYUNPAN_SYNC_DRIVE=resource # 是否显示文件备份过程日志，true-显示，false-不显示 - ALIYUNPAN_SYNC_LOG=true # 本地文件修改检测延迟间隔，单位秒。如果本地文件会被频繁修改，例如录制视频文件，配置好该时间可以避免上传未录制好的文件 - ALIYUNPAN_LOCAL_DELAY_TIME=60 重点说一下上边的四个配置：\n第一个是挂载配置下的映射的本地目录，这个是把阿里云盘的数据下载下来的目录，需要把他挂载在一个比较大的存储路径。\n第二个是备份模式：ALIYUNPAN_SYNC_MOD，我这里是把云盘文件下载到本地，所以模式是download。\n第三个是网盘：ALIYUNPAN_SYNC_DRIVE，阿里云盘分为备份盘和资源盘，我这里大部分转存的文件都是放在资源盘，所以这里配置resource。\n第四个是备份目标目录：ALIYUNPAN_PAN_DIR，这个配置就是当前容器需要下载的目录，上边指定了需要下载资源盘的文件，但是肯定不能整个资源盘都下载，只需要指定特定的目录下载就行了，比如我转存的文件都是放在来自分享目录下，我这里就配置来自分享。\njs的通知后边在讲，这个目录里边暂时可以先不放任何js文件。\n然后就可以启动docker compose文件了。\n1 docker compose up -d 此时虽然启动了容器，但是因为没有配置token，容器会一直重启，但是此时目录config目录下就会多出一个aliyun_config.json的文件，编辑文件找到accessToken属性，把第一步生成好的token替换进去就可以了。保存文件后等待容器下一次重启或者手动重启容器就可以了。此时就可以了。\n验证 接下来就是找一个文件保存到云盘的指定要下载的目录，我是来自分享，然后去看一下目录有没有进行下载。也可以通过查看容器的日志：\n1 2 3 4 5 6 7 8 9 root@docker:~/images/aliyunpancli# docker compose logs -tf --tail 10 WARN[0000] /root/images/aliyunpancli/docker-compose.yaml: `version` is obsolete aliyunpan-sync | 2024-07-06T02:52:51.522742265Z 扫描到云盘文件：/来自分享/Cover the sky.S01E61.2023.2160p.WEB.DL.H265.DDP2.0-BestWEB.mkv aliyunpan-sync | 2024-07-06T02:52:56.282356345Z 完成全部文件的同步下载，等待下一次扫描 aliyunpan-sync | 2024-07-06T02:53:51.550419129Z 开始进行文件扫描... aliyunpan-sync | 2024-07-06T02:53:51.756156867Z 扫描到云盘文件：/来自分享/Jade Dynasty.S02E43.2022.2160p.WEB-DL.H265.DDP2.0-BestWEB.mkv aliyunpan-sync | 2024-07-06T02:53:51.756982180Z 扫描到云盘文件：/来自分享/Cover the sky.S01E61.2023.2160p.WEB.DL.H265.DDP2.0-BestWEB.mkv aliyunpan-sync | 2024-07-06T02:53:56.554962070Z 下载文件：/来自分享/Jade Dynasty.S02E43.2022.2160p.WEB-DL.H265.DDP2.0-BestWEB.mkv 下载到本地:/home/app/data/Jade Dynasty.S02E43.2022.2160p.WEB-DL.H265.DDP2.0-BestWEB.mkv ↓ 773.00MB/779.46MB(99.17%) 9.64MB/s............下载完毕：/home/app/data/Jade Dynasty.S02E43.2022.2160p.WEB-DL.H265.DDP2.0-BestWEB.mkv 通过日志可以看出它在不停的扫描，检测到新文件就开始进行下载。\nJS通知 在docker compose文件中，指定了js文件的目录，那么要怎么使用呢？官方也有一些具体的例子：JavaScript插件，我这里需要提供一个下载完成通知的功能，保存文件后什么时候下载完成是大家比较关心的，总不能总是查看日志。\n这里要使用到的js文件是sync_handler.js文件。文件具体的内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 // ------------------------------------------------------------------------------------------ // 函数说明：同步备份-同步文件后的回调函数 // // 参数说明 // context - 当前调用的上下文信息 // { // \u0026#34;appName\u0026#34;: \u0026#34;aliyunpan\u0026#34;, // \u0026#34;version\u0026#34;: \u0026#34;v0.1.3\u0026#34;, // \u0026#34;userId\u0026#34;: \u0026#34;11001d48564f43b3bc5662874f04bb11\u0026#34;, // \u0026#34;nickname\u0026#34;: \u0026#34;tickstep\u0026#34;, // \u0026#34;fileDriveId\u0026#34;: \u0026#34;19519111\u0026#34;, // \u0026#34;albumDriveId\u0026#34;: \u0026#34;29519122\u0026#34; // } // appName - 应用名称，当前固定为aliyunpan // version - 版本号 // userId - 当前登录用户的ID // nickname - 用户昵称 // fileDriveId - 用户文件网盘ID // albumDriveId - 用户相册网盘ID // // params - 同步文件后的参数 // { // \u0026#34;action\u0026#34;: \u0026#34;upload\u0026#34;, // \u0026#34;actionResult\u0026#34;: \u0026#34;success\u0026#34;, // \u0026#34;driveId\u0026#34;: \u0026#34;19519221\u0026#34;, // \u0026#34;fileName\u0026#34;: \u0026#34;1.txt\u0026#34;, // \u0026#34;filePath\u0026#34;: \u0026#34;D:/goprojects/dev/upload/1.txt\u0026#34;, // \u0026#34;fileSha1\u0026#34;: \u0026#34;294C8F24C56042710813E95C55A0B018299BA9A7\u0026#34;, // \u0026#34;fileSize\u0026#34;: \u0026#34;28077\u0026#34;, // \u0026#34;fileType\u0026#34;: \u0026#34;file\u0026#34;, // \u0026#34;fileUpdatedAt\u0026#34;: \u0026#34;2022-03-04 15:19:47\u0026#34; // } // action - 同步动作， // download-下载文件， // upload-上传文件， // delete_local-删除本地文件， // delete_pan-删除云盘文件， // create_local_folder-创建本地文件夹， // create_pan_folder-创建云盘文件夹 // actionResult - 同步结果，success-成功，fail-失败 // driveId - 网盘ID // fileName - 文件名称 // filePath - 文件完整路径 // fileSha1 - 文件SHA1 // fileSize - 文件大小，单位B // fileType - 文件类型，file-文件，folder-文件夹 // fileUpdatedAt - 文件修改时间 // // 返回值说明 // （无） // ------------------------------------------------------------------------------------------ function syncFileFinishCallback(context, params) { console.log(params) var header = { \u0026#34;User-Agent\u0026#34;: \u0026#34;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.88 Safari/537.36\u0026#34;, \u0026#34;Content-Type\u0026#34;: \u0026#34;application/json\u0026#34;, \u0026#34;Accept\u0026#34;: \u0026#34;application/json\u0026#34; }; try { var text = \u0026#34;文件名：\u0026#34; + params[\u0026#34;fileName\u0026#34;] + \u0026#34; 同步完成, 同步结果: \u0026#34; + params[\u0026#34;actionResult\u0026#34;]; if (params[\u0026#34;actionResult\u0026#34;] === \u0026#34;fail\u0026#34;) { var reqData = { \u0026#34;chat_id\u0026#34;: \u0026#34;这里是自己的id\u0026#34;, \u0026#34;text\u0026#34;: text }; var r = PluginUtil.Http.post(header, \u0026#34;https://api.telegram.org/{这里替换具体的电报机器人token}/sendMessage\u0026#34;, JSON.stringify(reqData)); } } catch (e) { if (e !== \u0026#34;Error\u0026#34;) { throw e; } } } 怎么创建电报机器人以及获取自己的id这里就不再说了，大家可以网上搜索一下，如果后续时间充裕，我也会详细教大家如何创建机器人和查看自己的id。\ntext就是通知的内容，来看一下最终的通知效果：\n","date":"2024-07-06T03:11:29Z","image":"https://images.iminling.com/app/hide.php?key=dTRuQi9oWFFCZ2JmUDF2bDRUUFVERFNJZnc2Sm43RTU4dXlnVzViM3pMYzdEenBDM0t4MDBwbkM2eTY5QlZ1MSt2UjhuRjQ9","permalink":"https://konghanghang.github.io/iminling-pages/2024/docker-deploy-aliyunpan-sync/","title":"docker搭建aliyunpan-sync时实增量同步阿里云盘文件"},{"content":"工作中提供给外部调用的api需要进行请求的内容进行加密，加密使用的AES/ECB/PKCS5Padding这种加密方式，公司开发使用的是Java，但是对接企业有使用Java，Go或者php进行开发的，客户会要求提供一下demo，Java语言还好搞，本身就是Java开发的，直接提供就好了，但是php和Go由于公司没有使用者，在客户来询问的时候就没有demo可以提供到，于是自己就研究了一下PHP的AES加密，并提供了一个demo。下边介绍一下具体的实现。\n本文主要讲由Java转到PHP的实现，具体AES算法是怎么实现的不在本文的讨论范围，如果还不知道AES是什么自行搜索。\nJava实现 在这里有必要先说明一下Java的实现，因为只有知道Java是怎么实现的，才能在其他语言里去实现。先上代码吧：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 public class AesUtils { private static final String TRANSFORMATION = \u0026#34;AES/ECB/PKCS5Padding\u0026#34;; private static final String ALGORITHM = \u0026#34;AES\u0026#34;; public static String encrypt(String content, String key){ try { Key secretKeySpec = secretKeySpec(key); Cipher cipher = Cipher.getInstance(TRANSFORMATION);// 创建密码器 cipher.init(Cipher.ENCRYPT_MODE, secretKeySpec);// 初始化 byte[] result = cipher.doFinal(content.getBytes(StandardCharsets.UTF_8)); return Base64.getEncoder().encodeToString(result); } catch (Exception e) { } } public static String decrypt(String content, String key) { try { Key keySpec = secretKeySpec(key); Cipher cipher = Cipher.getInstance(TRANSFORMATION); cipher.init(Cipher.DECRYPT_MODE, keySpec); byte[] result = cipher.doFinal(Base64.getDecoder().decode(content)); return new String(result, StandardCharsets.UTF_8); } catch (Exception e) { } } private static Key secretKeySpec(String key) throws EncryptException { KeyGenerator generator = KeyGenerator.getInstance(ALGORITHM); SecureRandom secureRandom = SecureRandom.getInstance(\u0026#34;SHA1PRNG\u0026#34;); secureRandom.setSeed(key.getBytes(StandardCharsets.UTF_8)); generator.init(128, secureRandom); SecretKey secretKey = generator.generateKey(); byte[] enCodeFormat = secretKey.getEncoded(); return new SecretKeySpec(enCodeFormat, ALGORITHM); } } 完整代码如上，整个代码也比较清晰，获取key然后对内容进行加解密。\n但是问题就出现在key获取上，根据用户提供的key再使用RNG(Random Number Generator)算法：SHA1PRNG获取128位的key：generator.init(128, secureRandom);，由次可知完整的AES加密算法应该是AES-128-ECB并使用PKCS5Padding方式进行填充。\nPHP实现 通过阅读Java的代码发现完整算法是AES-128-ECB并使用PKCS5Padding方式进行填充，获取key的时候使用SHA1PRNG，但是PHP并没有这种方式，于是就去询问GPT，查看网上各种资料，最终找到了解决办法，PHP的完整代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 \u0026lt;?php $plainText = isset($_GET[\u0026#39;text\u0026#39;]) ? $_GET[\u0026#39;text\u0026#39;] : \u0026#39;Hello, World!\u0026#39;; $key = isset($_GET[\u0026#39;key\u0026#39;]) ? $_GET[\u0026#39;key\u0026#39;] : \u0026#39;this_is_a_very_long_key_that_needs_to_be_shortened_or_hashed\u0026#39;; function encrypt($plainText, $key) { $key = substr(openssl_digest(openssl_digest($key, \u0026#39;sha1\u0026#39;, true), \u0026#39;sha1\u0026#39;, true), 0, 16); // openssl_encrypt 加密不同Mcrypt，对秘钥长度要求，超出16加密结果不变 $data = openssl_encrypt($plainText, \u0026#39;AES-128-ECB\u0026#39;, $key, OPENSSL_RAW_DATA); //$data = strtolower(bin2hex($data)); return base64_encode($data); } function decrypt($cipherText, $key) { $key = substr(openssl_digest(openssl_digest($key, \u0026#39;sha1\u0026#39;, true), \u0026#39;sha1\u0026#39;, true), 0, 16); $decrypted = openssl_decrypt(base64_decode($cipherText), \u0026#39;AES-128-ECB\u0026#39;, $key, OPENSSL_RAW_DATA); return $decrypted; } // 示例用法 $encrypted = encrypt($plainText, $key); echo \u0026#34;加密结果: \u0026#34; . $encrypted . \u0026#34;\\n\u0026#34;; $decrypted = decrypt($encrypted, $key); echo \u0026#34;解密结果: \u0026#34; . $decrypted . \u0026#34;\\n\u0026#34;; ?\u0026gt; 如上，在php中是对Key进行两次sha1并对结果进行截取16位。\n在PHP中，openssl_encrypt和openssl_decrypt函数会自动处理PKCS#5/PKCS#7填充（padding），不需要手动实现填充。参数中指明OPENSSL_RAW_DATA就可以了。\n以上就是在PHP中实现Java中SHA1PRNG生成key并以AES-128-ECB加密且以PKCS#5方式进行填充的实现。记录一下。\n","date":"2024-06-29T03:36:33Z","image":"https://images.iminling.com/app/hide.php?key=VDg3MjhNTkpJUzVSWUEyNGY0UHZCQkRvbXEwYXlpWVB5Q2ZuS3ZnTGUwTkxDVW1yTGd2L1N4cU5kVmZzQjIrcFQycG5UZXM9","permalink":"https://konghanghang.github.io/iminling-pages/2024/php-aes-128-ecb-pkcs5padding/","title":"PHP实现AES-128-ECB并以PKCS5Padding填充方式加解密"},{"content":"网站从成功部署后，就入了google adsense，算下来也有一年多的时间了，这一年多自己发布文章的频率也比较低，所以流量不高，广告收入非常少，没想到这么快就收到了adsense的地址验证要求。今天就介绍一下我验证地址的详细过程。\n验证邮件 在6月初，我收到了google的邮件，提示验证我的身份，只有这样子才能接收到来自google adsense的付款，并且邮件中直接给出了地址可以直接点击按钮跳转验证地址进行验证。\n资料上传 点击链接会跳转到验证界面，最开始是需要上传一份身份证明：身份ID或者护照(passport)。我这边因为个人信息写的美国，所以这里就上传了护照上去，并填写了自己在anyboxmail上申请的美国地址，在输入完地址点击下一步的时候，又弹出需要验证地址。\n地址验证这里对我倒是没有什么难处，我申请了美国运通信用卡(申请教程：使用ITIN申请American Express(美国运通)信用卡)的月度账单，上边有我的地址信息，以此来作为我的地址证明进行了上传。如果地址写的是国内的小伙伴，直接申请国内信用卡的电子账单，进行上传应该也是可以的。\n整体上其实就是上传了两份文件，一份护照，一份地址证明文件，提交后就是等待处理，google那边需要点时间对上传的资料进行审查。\n身份验证通过 过了有3天，收到了google的邮件通知，提示身份验证通过。\n同一天google又给我发了一份邮件，提示验证地址的pin码已经发出，等具体收到信件后再进行pin码验证。\n验证pin码 这中间又是一段时间的等待，因为邮件是发到我租的美国地址的，中间刚好又遇到双休，处理的没那么快，等待几天后收到了pin码邮件\n然后让房东进行了扫描，扫描后的内容如下\n此时登录google adsense的后台，直接看到有一个卡片就是提示要验证pin码\n点击验证就跳转到了pin码验证页面\n正确输入后就ok了，最终身份验证和地址验证都显示已通过，至此完成google adsense的全部验证\n以上就是整个验证流程。\n","date":"2024-06-18T13:10:26Z","image":"https://images.iminling.com/app/hide.php?key=NE1yYVdkUjdQS3Q1UTBUODVkbW5zZ2NWcFVjY083SWV0RnI4Vnh2SVF3THJmY3REUE5UbGVIcHRTVCtPRmZEOEtqK0JEZTA9","permalink":"https://konghanghang.github.io/iminling-pages/2024/google-adsense-address-verify/","title":"Google Adsense地址验证流程"},{"content":"上篇文章记录了如何使用maven来发布自己的个人项目到中央仓库，后边项目改使用gradle来管理依赖了，为了能及时的把jar发布到maven仓库，所以就又折腾了一遍如何使用gradle来发布自己的jar到中央仓库，在这里记录一下折腾和踩坑经历，并分享给大家。\n前提准备 如果你是第一次发布jar到仓库，则需要参考我的另一篇文章：发布个人项目的jar包文件到maven中央仓库 来创建好sonatype账号并生成gpg key。这些就不在另外说明了。\n本篇文章就是在我已经使用了maven发布过jar到中央仓库，然后在此基础上把项目迁移到gradle，然后使用gradle来继续发布项目到中央仓库。\ngradle配置 设置发布plugins 想要把jar发布的maven仓库需要先将项目的代码打包成jar，然后对jar进行签名，最后发布到maven仓库，三步对应三个插件：\n1 2 3 4 5 plugins { `java-library` `maven-publish` signing } 上边就添加了三个插件，将用于后续的发布使用。\n配置jar打包 下边设置对项目进行打包成jar的设置\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 tasks.jar { dependsOn(tasks.withType(GenerateMavenPom::class)) manifest { attributes(\u0026#34;Created-By\u0026#34; to \u0026#34;Gradle ${project.ext[\u0026#34;gradleVersion\u0026#34;]}\u0026#34;) } into(\u0026#34;META-INF\u0026#34;) { from(\u0026#34;$buildDir/publications/mavenJava\u0026#34;) exclude(\u0026#34;*.asc\u0026#34;) rename { it.replace(\u0026#34;pom-default.xml\u0026#34;, \u0026#34;pom.xml\u0026#34;) } } } tasks.withType\u0026lt;JavaCompile\u0026gt; { options.encoding = \u0026#34;UTF-8\u0026#34; } java { sourceCompatibility = JavaVersion.VERSION_17 targetCompatibility = JavaVersion.VERSION_17 withJavadocJar() withSourcesJar() } 上边指定了jdk的版本，并且生成javadoc和java source文件，指定打包的编码以及对manifest文件属性添加等一系列的操作。\n配置发布 主要是配置仓库，pom文件以及签名等信息，先贴一下整个配置，下面单独讲。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 publishing { publications { create\u0026lt;MavenPublication\u0026gt;(\u0026#34;mavenJava\u0026#34;) { artifactId = project.name from(components[\u0026#34;java\u0026#34;]) /*versionMapping { usage(\u0026#34;java-api\u0026#34;) { fromResolutionOf(\u0026#34;runtimeClasspath\u0026#34;) } usage(\u0026#34;java-runtime\u0026#34;) { fromResolutionResult() } }*/ pom { name.set(project.name) description.set(\u0026#34;A concise description of my library\u0026#34;) url.set(\u0026#34;https://www.example.com/library\u0026#34;) /*properties.set(mapOf( \u0026#34;myProp\u0026#34; to \u0026#34;value\u0026#34;, \u0026#34;prop.with.dots\u0026#34; to \u0026#34;anotherValue\u0026#34; ))*/ licenses { license { name.set(\u0026#34;The Apache License, Version 2.0\u0026#34;) url.set(\u0026#34;https://www.apache.org/licenses/LICENSE-2.0.txt\u0026#34;) } } developers { developer { id.set(\u0026#34;yslao\u0026#34;) name.set(\u0026#34;yslao\u0026#34;) email.set(\u0026#34;yslao@outlook.com\u0026#34;) } } scm { connection.set(\u0026#34;scm:git:git://github.com/konghanghang/base-iminling-core.git\u0026#34;) developerConnection.set(\u0026#34;scm:git:ssh://github.com/konghanghang/base-iminling-core.git\u0026#34;) url.set(\u0026#34;https://github.com/konghanghang/base-iminling-core\u0026#34;) } } } } repositories { maven { name = \u0026#34;mavenCentral\u0026#34; // change URLs to point to your repos, e.g. http://my.org/repo // val releasesRepoUrl = uri(layout.buildDirectory.dir(\u0026#34;repos/releases\u0026#34;)) val releasesRepoUrl = uri(\u0026#34;https://oss.sonatype.org/service/local/staging/deploy/maven2/\u0026#34;) val snapshotsRepoUrl = uri(\u0026#34;https://oss.sonatype.org/content/repositories/snapshots\u0026#34;) url = if (version.toString().endsWith(\u0026#34;SNAPSHOT\u0026#34;)) snapshotsRepoUrl else releasesRepoUrl credentials { // System.getenv放在.bash_profile中 // System.getProperty可以放在命令行也可以放在gradle.properties中 username = System.getProperty(\u0026#34;SONATYPE_NEXUS_USERNAME\u0026#34;) password = System.getProperty(\u0026#34;SONATYPE_NEXUS_PASSWORD\u0026#34;) } } } signing { sign(publishing.publications[\u0026#34;mavenJava\u0026#34;]) } tasks.javadoc { if (JavaVersion.current().isJava9Compatible) { (options as StandardJavadocDocletOptions).addBooleanOption(\u0026#34;html5\u0026#34;, true) } (options as StandardJavadocDocletOptions).encoding(\u0026#34;UTF-8\u0026#34;) } } 整个publishing共分为四部分：\npublications 指定jar的version，groupId和artifactId。另外还有pom的信息，这个在使用maven发布的时候也设置过\nrepositories 指定仓库地址，以及配置sonetype的账号和密码，可以放在用户目录的gradle.properties中：\n1 2 3 4 5 6 7 8 9 10 11 12 # k @ MacBook-Pro in ~/.gradle [9:30:05] $ pwd /Users/k/.gradle # k @ MacBook-Pro in ~/.gradle [9:30:06] $ ls caches gradle.properties kotlin-profile notifications wrapper daemon jdks native workers # k @ MacBook-Pro in ~/.gradle [9:30:09] $ cat gradle.properties systemProp.SONATYPE_NEXUS_USERNAME=aaa systemProp.SONATYPE_NEXUS_PASSWORD=aaa 如上在gradle.properties中以key-value的形式进行配置。另外同时配置了快照版本的发布地址和release版本的发布地址，通过项目的版本好结尾是不是SNAPSHOT来确定到底是发布到哪里。\nsigning 指定签名哪个publications，名字要和上边publications中配置的名称一致。另外有一点还需要特别进行配置，我maven发布的时候使用gpg生成了key，在使用gradle的时候还需要导出私钥，同样是导出到用户家目录下的.gnupg目录下，进入到此目录执行gpg --export-secret-keys -o secring.gpg ：\n1 2 3 4 5 6 7 8 9 10 # k @ MacBook-Pro in ~ [9:39:08] C:1 $ cd .gnupg # k @ MacBook-Pro in ~/.gnupg [9:39:13] $ ls common.conf openpgp-revocs.d public-keys.d trustdb.gpg crls.d private-keys-v1.d secring.gpg # k @ MacBook-Pro in ~/.gnupg [9:39:14] $ gpg --export-secret-keys -o secring.gpg 会生成一个secring.gpg的文件，这时候需要在/Users/k/.gradle/gradle.properties进行配置\n1 2 3 4 5 6 7 # k @ MacBook-Pro in ~/.gradle [9:41:37] $ cat gradle.properties signing.keyId=44405DA7 signing.password=12345 signing.secretKeyRingFile=/Users/k/.gnupg/secring.gpg systemProp.SONATYPE_NEXUS_USERNAME=aa systemProp.SONATYPE_NEXUS_PASSWORD=aa 上边有三个参数，keyId使用gpg \u0026ndash;list-keys中展示出来的pub下C87B0403E54CD05D431E5C1A7204BFB944405DA7 中的后8位。\n1 2 3 4 5 6 7 8 9 10 11 $ gpg --list-keys gpg: checking the trustdb gpg: marginals needed: 3 completes needed: 1 trust model: pgp gpg: depth: 0 valid: 1 signed: 0 trust: 0-, 0q, 0n, 0m, 0f, 1u gpg: next trustdb check due at 2023-02-20 /c/Users/aaa/.gnupg/pubring.kbx --------------------------------- pub rsa2048 2021-02-20 [SC] [expires: 2023-02-20] C87B0403E54CD05D431E5C1A7204BFB944405DA7 uid [ultimate] ysl \u0026lt;ysl@test.com\u0026gt; sub rsa2048 2021-02-20 [E] [expires: 2023-02-20] password则是生成gpg key的时候输入的密码，这个在maven发布的那篇文章中讲过，有不清楚的可以再去看一下那篇文章。\nsecretKeyRingFile则是刚才使用gpg导出的文件。\n签名相关的配置就已经配置完成了。\njavadoc 这个配置相对简单，指定编码。\n经过上边的配置基本就已经完成了，可以去发布了。\n发布 publishing下有几个选项，主要用的还是publishToMavenLocal，这个是发布到本地的maven仓库，可以在本地测试使用。另外就是publish直接往maven仓库中发布。\n双击上边的任务进行运行，或者直接在终端使用gradle + 具体的参数来运行，比如：gradle publishToMavenLocal 。\n遇到的问题 在经过上边配置后发现发布到maven仓库里的只有.moudle的文件，并没有我们的jar和doc相关的文件，经过网上查询添加以下配置就可以了：\n1 2 3 4 // 解决打包后生成.module文件，导致发布到中央仓库时只上传了.module文件没有上传jar文件 tasks.withType\u0026lt;GenerateModuleMetadata\u0026gt; { enabled = false } 以上就是使用gradle发布jar到中央仓库的折腾过程。\n参考：\nPublishing a project as module\n","date":"2024-05-19T02:02:03Z","image":"https://images.iminling.com/app/hide.php?key=YmduQTFleVVSNGloQzkvRXJvK2dtcjNiZEtrUjRMSEdYRFVzeitxNXUrNzVPeFpRQ2pBVzBlU2I4dGtPRWUxeWFZNWJQdzg9","permalink":"https://konghanghang.github.io/iminling-pages/2024/gradle-kts-push-jar-to-maven-central/","title":"使用gradle kts脚本发布个人项目的jar包文件到maven中央仓库"},{"content":"自己有一个项目想要在任何机器上都能引用到，最简单的办法就是在所要使用的机器上把项目下载下来，然后install到本地仓库，但是如何直接通过引用坐标就能引用到呢？答案就是发布到maven的中央仓库，这样子无论你在什么机器上，只要能上网输入gav三个坐标就可以引入了。这篇文章就介绍一下自己项目打成jar包并发布到maven中央仓库的完整过程。mac安装maven可以参考我的另一篇文章：Mac使用Homebrew安装maven环境。\n账号注册 首先我们要先注册sonatype账号，访问地址sonatype输入必须的内容就可以成功注册一个账号,不过对密码就有一些特殊的安全要求，正确注册就可以了。\nsonatype工单 新建工单 点击新建按钮，项目选择open的那个，问题类型选择new project，概要，描述随便写就ok了\n摘要根据自己需要填写，我这里填写的是项目的名称。\ngroup id就是maven坐标的名称，一般是域名反转过来。例如我的域名是iminling.com,则这里填写com.imining.\nproject URL则是github的仓库地址，或者其他代码仓库的地址。\nSCM url就是在project URL后边加上.git\n其他的默认就可以了，创建。新建完成后如下图：\n添加TXT记录 如上边的图所示，它为了验证你是域名的所有者，会让你去解析一条txt记录。两种方案选一种就可以了，我这里选择的是添加一条txt的记录，如下图所示，我这里是不清楚规则，提交了两个工单，所以添加了两条记录，最后其中一个工单被认为是重复提交，已关闭。其中记录值填写你的工单地址，下图中框住的部分，主机记录就是jira tiket.\n这里txt解析的值来源就是你的问题url，如下：\n解析完后就可以再等待审核了，我的大概是凌晨3点进行的审核，通过以后会有邮件通知，工单下边也有评论,此时我们就可以准备发布我们的jar包了。\n1 2 3 4 5 6 7 8 com.iminling has been prepared, now user(s) yslaoo can: Publish snapshot and release artifacts to https://oss.sonatype.org Have a look at this section of our official guide for deployment instructions: https://central.sonatype.org/pages/ossrh-guide.html#deployment Please comment on this ticket when you\u0026#39;ve released your first component(s), so we can activate the sync to Maven Central. Depending on your build configuration, this might happen automatically. If not, you can follow the steps in this section of our guide: https://central.sonatype.org/pages/releasing-the-deployment.html 发布准备 gpg安装 mac可以使用用brew进行安装 brew install gpg就可以了。\nwindows安装了git客户端就自带了这个功能。\n检查自己的gpg的版本，有些是gpg，有些则需要输入gpg2.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # 或者使用gpg2 --version 就看自己的电脑上哪个命令可以运行 $ gpg --version gpg (GnuPG) 2.2.13-unknown libgcrypt 1.8.4 Copyright (C) 2019 Free Software Foundation, Inc. License GPLv3+: GNU GPL version 3 or later \u0026lt;https://gnu.org/licenses/gpl.html\u0026gt; This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. Home: /c/Users Supported algorithms: Pubkey: RSA, ELG, DSA, ECDH, ECDSA, EDDSA Cipher: IDEA, 3DES, CAST5, BLOWFISH, AES, AES192, AES256, TWOFISH, CAMELLIA128, CAMELLIA192, CAMELLIA256 Hash: SHA1, RIPEMD160, SHA256, SHA384, SHA512, SHA224 Compression: Uncompressed, ZIP, ZLIB, BZIP2 生成key 不论是mac还是windows都是使用命令gpg --gen-key来生成。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 $ gpg --gen-key gpg (GnuPG) 2.2.27; Copyright (C) 2021 Free Software Foundation, Inc. This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. 注意：使用 “gpg --full-generate-key” 以获得一个功能完整的密钥产生对话框。 GnuPG 需要构建用户标识以辨认您的密钥。 真实姓名： yslaoo 电子邮件地址： ysl@test.com 您选定了此用户标识： “ysl \u0026lt;ysl@test.com\u0026gt;” 更改姓名（N）、注释（C）、电子邮件地址（E）或确定（O）/退出（Q）？ O 我们需要生成大量的随机字节。在质数生成期间做些其他操作（敲打键盘 、移动鼠标、读写硬盘之类的）将会是一个不错的主意；这会让随机数 发生器有更好的机会获得足够的熵。 我们需要生成大量的随机字节。在质数生成期间做些其他操作（敲打键盘 、移动鼠标、读写硬盘之类的）将会是一个不错的主意；这会让随机数 发生器有更好的机会获得足够的熵。 gpg: /Users/aaa/.gnupg/trustdb.gpg：建立了信任度数据库 gpg: 密钥 84040E735F931A32 被标记为绝对信任 gpg: 目录‘/Users/aaa/.gnupg/openpgp-revocs.d’已创建 gpg: 吊销证书已被存储为‘/Users/aaa/.gnupg/openpgp-revocs.d/DD1E1B8213D07DA46FC3F2B684040E735F931A32.rev’ 公钥和私钥已经生成并被签名。 pub rsa3072 2021-02-20 [SC] [有效至：2023-02-20] DD1E1B8213A07DA46FC3F2B684040E735F931A32 uid yslao \u0026lt;yslao@outlook.com\u0026gt; sub rsa3072 2021-02-20 [E] [有效至：2023-02-20] 期间会让输入密码，牢记密码，后边会使用。\nkey操作 生成key后需要发布key到公有服务器。\n先查看key：\n1 2 3 4 5 6 7 8 9 10 11 $ gpg --list-keys gpg: checking the trustdb gpg: marginals needed: 3 completes needed: 1 trust model: pgp gpg: depth: 0 valid: 1 signed: 0 trust: 0-, 0q, 0n, 0m, 0f, 1u gpg: next trustdb check due at 2023-02-20 /c/Users/aaa/.gnupg/pubring.kbx --------------------------------- pub rsa2048 2021-02-20 [SC] [expires: 2023-02-20] C87B0403E54CD05D431E5C1A7204BFB944405DA7 uid [ultimate] ysl \u0026lt;ysl@test.com\u0026gt; sub rsa2048 2021-02-20 [E] [expires: 2023-02-20] 然后发布：\n1 2 3 # 命令格式：gpg --keyserver [key的服务器](这个有很多，随便找一个就行了) --send-keys [key] key就是查看key操作中pub对应的那串字符串 $ gpg --keyserver hkp://keyserver.ubuntu.com:11371 --send-keys C87B0403E54CD05D431E5C1A7204BFB944405DA7 gpg: sending key 7204BFB944405DA7 to hkp://keyserver.ubuntu.com:11371 Distribution 管理 修改pom.xml, 添加以下代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 \u0026lt;!--父级是project--\u0026gt; \u0026lt;distributionManagement\u0026gt; \u0026lt;snapshotRepository\u0026gt; \u0026lt;id\u0026gt;ossrh\u0026lt;/id\u0026gt; \u0026lt;url\u0026gt;https://oss.sonatype.org/content/repositories/snapshots\u0026lt;/url\u0026gt; \u0026lt;/snapshotRepository\u0026gt; \u0026lt;repository\u0026gt; \u0026lt;id\u0026gt;ossrh\u0026lt;/id\u0026gt; \u0026lt;url\u0026gt;https://oss.sonatype.org/service/local/staging/deploy/maven2/\u0026lt;/url\u0026gt; \u0026lt;/repository\u0026gt; \u0026lt;/distributionManagement\u0026gt; \u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.sonatype.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;nexus-staging-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.6.7\u0026lt;/version\u0026gt; \u0026lt;extensions\u0026gt;true\u0026lt;/extensions\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;serverId\u0026gt;ossrh\u0026lt;/serverId\u0026gt; \u0026lt;nexusUrl\u0026gt;https://oss.sonatype.org/\u0026lt;/nexusUrl\u0026gt; \u0026lt;autoReleaseAfterClose\u0026gt;true\u0026lt;/autoReleaseAfterClose\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; 认证配置 在setting.xml中添加认证信息,此处的id要和pom文件中的distributionManagement下snapshotRepository和repository的id保持一致.\n1 2 3 4 5 6 7 8 9 10 11 \u0026lt;settings\u0026gt; \u0026lt;servers\u0026gt; \u0026lt;server\u0026gt; \u0026lt;id\u0026gt;ossrh\u0026lt;/id\u0026gt; \u0026lt;!-- username就是注册sonatype时的username --\u0026gt; \u0026lt;username\u0026gt;your-jira-id\u0026lt;/username\u0026gt; \u0026lt;!-- password就是注册sonatype时的password --\u0026gt; \u0026lt;password\u0026gt;your-jira-pwd\u0026lt;/password\u0026gt; \u0026lt;/server\u0026gt; \u0026lt;/servers\u0026gt; \u0026lt;/settings\u0026gt; javadoc和源代码配置 在pom.xml中添加配置如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 \u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-source-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.2.1\u0026lt;/version\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;id\u0026gt;attach-sources\u0026lt;/id\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;jar-no-fork\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-javadoc-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.9.1\u0026lt;/version\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;id\u0026gt;attach-javadocs\u0026lt;/id\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;jar\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; gpg签名配置 在pom中添加gpg插件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-gpg-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.5\u0026lt;/version\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;id\u0026gt;sign-artifacts\u0026lt;/id\u0026gt; \u0026lt;phase\u0026gt;verify\u0026lt;/phase\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;sign\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; 在setting.xml中添加gpg profile配置,gpg.executable属性要根据自己的电脑环境进行添加.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 \u0026lt;settings\u0026gt; \u0026lt;profiles\u0026gt; \u0026lt;profile\u0026gt; \u0026lt;id\u0026gt;ossrh\u0026lt;/id\u0026gt; \u0026lt;activation\u0026gt; \u0026lt;activeByDefault\u0026gt;true\u0026lt;/activeByDefault\u0026gt; \u0026lt;/activation\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;!--这里根据实际情况填写gpg或gpg2,看自己的环境能使用哪个命令--\u0026gt; \u0026lt;gpg.executable\u0026gt;gpg2\u0026lt;/gpg.executable\u0026gt; \u0026lt;!--passphrase就是我们在gpg安装生成key的时候设置的--\u0026gt; \u0026lt;gpg.passphrase\u0026gt;the_pass_phrase\u0026lt;/gpg.passphrase\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;/profile\u0026gt; \u0026lt;/profiles\u0026gt; \u0026lt;/settings\u0026gt; Nexus Staging Maven插件，用于部署和发布 在pom.xml中添加以下内容\n1 2 3 4 5 6 7 8 9 10 11 \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.sonatype.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;nexus-staging-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.6.7\u0026lt;/version\u0026gt; \u0026lt;extensions\u0026gt;true\u0026lt;/extensions\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;serverId\u0026gt;ossrh\u0026lt;/serverId\u0026gt; \u0026lt;nexusUrl\u0026gt;https://oss.sonatype.org/\u0026lt;/nexusUrl\u0026gt; \u0026lt;autoReleaseAfterClose\u0026gt;true\u0026lt;/autoReleaseAfterClose\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; 经过上边操作，准备工作已完毕，下边就可以开始发布jar包了。\n发布 所有的发布操作确保gpg命令是可以用的,在windows下进行发布一定要注意是在git bash客户端中进行,以确保gpg可以使用.以及发布过程中可能会让你再次输入gpg的密码，这里需要注意一下。\n快照版本 项目的版本如果是以-SNAPSHOT结尾的,就会发布到快照仓库,如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 D:\\project\\idea\\base-iminling-parent\u0026gt;mvn clean deploy INFO] Scanning for projects... [WARNING] [WARNING] Some problems were encountered while building the effective model for com.iminling:base-iminling-parent:pom:1.0.0-SNAPSHOT [WARNING] \u0026#39;build.pluginManagement.plugins.plugin.(groupId:artifactId)\u0026#39; must be unique but found duplicate declaration of plugin org.sonatype.plugins:nexus-staging- maven-plugin @ line 326, column 25 [WARNING] [WARNING] It is highly recommended to fix these problems because they threaten the stability of your build. [WARNING] [WARNING] For this reason, future Maven versions might no longer support building such malformed projects. [WARNING] [INFO] [INFO] -----------------\u0026lt; com.iminling:base-iminling-parent \u0026gt;------------------ [INFO] Building base-iminling-parent 1.0.0-SNAPSHOT [INFO] --------------------------------[ pom ]--------------------------------- [INFO] [INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ base-iminling-parent --- [INFO] [INFO] --- maven-install-plugin:2.4:install (default-install) @ base-iminling-parent --- [INFO] Installing D:\\project\\idea\\base-iminling-parent\\pom.xml to D:\\maven-repository\\com\\iminling\\base-iminling-parent\\1.0.0-SNAPSHOT\\base-iminling-parent-1.0.0-S NAPSHOT.pom [INFO] [INFO] --- maven-deploy-plugin:2.7:deploy (default-deploy) @ base-iminling-parent --- Downloading from ossrh: https://oss.sonatype.org/content/repositories/snapshots/com/iminling/base-iminling-parent/1.0.0-SNAPSHOT/maven-metadata.xml Uploading to ossrh: https://oss.sonatype.org/content/repositories/snapshots/com/iminling/base-iminling-parent/1.0.0-SNAPSHOT/base-iminling-parent-1.0.0-20210220.03 4207-1.pom Uploaded to ossrh: https://oss.sonatype.org/content/repositories/snapshots/com/iminling/base-iminling-parent/1.0.0-SNAPSHOT/base-iminling-parent-1.0.0-20210220.034 207-1.pom (14 kB at 4.8 kB/s) Downloading from ossrh: https://oss.sonatype.org/content/repositories/snapshots/com/iminling/base-iminling-parent/maven-metadata.xml Uploading to ossrh: https://oss.sonatype.org/content/repositories/snapshots/com/iminling/base-iminling-parent/1.0.0-SNAPSHOT/maven-metadata.xml Uploaded to ossrh: https://oss.sonatype.org/content/repositories/snapshots/com/iminling/base-iminling-parent/1.0.0-SNAPSHOT/maven-metadata.xml (609 B at 263 B/s) Uploading to ossrh: https://oss.sonatype.org/content/repositories/snapshots/com/iminling/base-iminling-parent/maven-metadata.xml Uploaded to ossrh: https://oss.sonatype.org/content/repositories/snapshots/com/iminling/base-iminling-parent/maven-metadata.xml (292 B at 54 B/s) [INFO] ------------------------------------------------------------------------ [INFO] BUILD SUCCESS [INFO] ------------------------------------------------------------------------ [INFO] Total time: 15.105 s [INFO] Finished at: 2021-05-20T11:42:18+08:00 [INFO] ------------------------------------------------------------------------ release版本 项目的版本不是以-SNAPSHOT结尾的,就会发布到release仓库,如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 D:\\project\\idea\\base-iminling-parent\u0026gt;mvn clean deploy [INFO] Scanning for projects... [WARNING] [WARNING] Some problems were encountered while building the effective model for com.iminling:base-iminling-parent:pom:1.0.0 [WARNING] \u0026#39;build.pluginManagement.plugins.plugin.(groupId:artifactId)\u0026#39; must be unique but found duplicate declaration of plugin org.sonatype.plugins:nexus-staging- maven-plugin @ line 326, column 25 [WARNING] [WARNING] It is highly recommended to fix these problems because they threaten the stability of your build. [WARNING] [WARNING] For this reason, future Maven versions might no longer support building such malformed projects. [WARNING] [INFO] [INFO] -----------------\u0026lt; com.iminling:base-iminling-parent \u0026gt;------------------ [INFO] Building base-iminling-parent 1.0.0 [INFO] --------------------------------[ pom ]--------------------------------- [INFO] [INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ base-iminling-parent --- [INFO] [INFO] --- maven-install-plugin:2.4:install (default-install) @ base-iminling-parent --- [INFO] Installing D:\\project\\idea\\base-iminling-parent\\pom.xml to D:\\maven-repository\\com\\iminling\\base-iminling-parent\\1.0.0\\base-iminling-parent-1.0.0.pom [INFO] [INFO] --- maven-deploy-plugin:2.7:deploy (default-deploy) @ base-iminling-parent --- Uploading to ossrh: https://oss.sonatype.org/service/local/staging/deploy/maven2/com/iminling/base-iminling-parent/1.0.0/base-iminling-parent-1.0.0.pom Uploaded to ossrh: https://oss.sonatype.org/service/local/staging/deploy/maven2/com/iminling/base-iminling-parent/1.0.0/base-iminling-parent-1.0.0.pom (14 kB at 59 7 B/s) Downloading from ossrh: https://oss.sonatype.org/service/local/staging/deploy/maven2/com/iminling/base-iminling-parent/maven-metadata.xml Uploading to ossrh: https://oss.sonatype.org/service/local/staging/deploy/maven2/com/iminling/base-iminling-parent/maven-metadata.xml Uploaded to ossrh: https://oss.sonatype.org/service/local/staging/deploy/maven2/com/iminling/base-iminling-parent/maven-metadata.xml (312 B at 51 B/s) [INFO] ------------------------------------------------------------------------ [INFO] BUILD SUCCESS [INFO] ------------------------------------------------------------------------ [INFO] Total time: 32.049 s [INFO] Finished at: 2021-02-20T14:11:23+08:00 [INFO] ------------------------------------------------------------------------ 遇到的问题 在mac上进行发布的时候遇到下边问题：\n1 2 3 4 5 6 7 8 9 [INFO] --- maven-gpg-plugin:1.5:sign (sign-artifacts) @ base-iminling-parent --- gpg: 签名时失败： Inappropriate ioctl for device gpg: signing failed: Inappropriate ioctl for device [INFO] ------------------------------------------------------------------------ [INFO] BUILD FAILURE [INFO] ------------------------------------------------------------------------ [INFO] Total time: 17.069 s [INFO] Finished at: 2021-02-21T09:36:03+08:00 [INFO] ------------------------------------------------------------------------ 上网查询后，原因是 gpg 在当前终端无法弹出密码输入页面。\n解决办法很简单在终端执行export GPG_TTY=$(tty) 。重新执行，发现会弹出一个密码输入界面。\n同步中央仓库 发布后我们还需要在sonatype中问题下方进行评论,来激活同步到maven中心仓库.\n后续的release就可以同步到maven仓库了。\n版本引用 release 正常使用gav三个坐标来引入就可以了。可能刚发布的并没有同步到所有的仓库，需要等待同步，例如可以去阿里仓库里搜索几遍，让它去同步。\n快照版本 快照版本需要引入仓库地址：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 \u0026lt;!--定义snapshots库的地址--\u0026gt; \u0026lt;repositories\u0026gt; \u0026lt;repository\u0026gt; \u0026lt;id\u0026gt;sonatype-snapshots\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;sonatype-snapshots\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;https://oss.sonatype.org/content/repositories/snapshots/\u0026lt;/url\u0026gt; \u0026lt;snapshots\u0026gt; \u0026lt;enabled\u0026gt;true\u0026lt;/enabled\u0026gt; \u0026lt;/snapshots\u0026gt; \u0026lt;/repository\u0026gt; \u0026lt;/repositories\u0026gt; \u0026lt;!--经测试,不要下边的应该也是可以的,留着做不时之需--\u0026gt; \u0026lt;pluginRepositories\u0026gt; \u0026lt;pluginRepository\u0026gt; \u0026lt;id\u0026gt;sonatype-snapshots\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;sonatype-snapshots\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;https://oss.sonatype.org/content/repositories/snapshots/\u0026lt;/url\u0026gt; \u0026lt;snapshots\u0026gt; \u0026lt;enabled\u0026gt;true\u0026lt;/enabled\u0026gt; \u0026lt;/snapshots\u0026gt; \u0026lt;/pluginRepository\u0026gt; \u0026lt;/pluginRepositories\u0026gt; 上边就是通过maven发布jar包到maven中央仓库的的过程，希望可以帮助到大家。\n","date":"2024-05-08T14:33:57Z","image":"https://images.iminling.com/app/hide.php?key=VmhUVjAvWExidzB3U04rbmdWZjJwRG54MDgvZkZYZjZjdFYxNXNXbHlXVlU1MmRGVVJmeFpEV0FFeXBQbkdHbXpVMDA5TW89","permalink":"https://konghanghang.github.io/iminling-pages/2024/push-jar-to-maven-central/","title":"发布个人项目的jar包文件到maven中央仓库"},{"content":"网络测速相信很多人都使用过，想要看看自己家里的宽带网速怎么样，最简单的方式就是搜索测速网，然后等结果出来就可以了，比较简单。今天要介绍的主角是：iperf3,由于经常要和vps打交到，想要测试本地到服务器的速度，使用iperf3会更准确一点，接下来就介绍一下iperf3，以及如何使用iperf3来进行测试速度。\niperf3是什么 iPerf3 是一种主动测量 IP 网络上可实现的最大带宽的工具。 它支持调整与计时、缓冲区和协议（TCP、UDP、SCTP 与 IPv4 和 IPv6）相关的各种参数。 对于每次测试，它都会报告带宽、损耗和其他参数。它是一个 C/S 类型的测速工具，在服务器上开放某个端口，然后在客户机上连接该服务器对应的端口，就可以开始进行 tcp 或 udp 的下载速度了\niperf3安装 iperf3的官网也详细介绍了几种操作平台的安装，具体的地址：安装iperf3。下边说明一下几种操作系统的安装。\nWindows 直接去官方下载地址：budman.pw或者github去下载安装文件,下载最新的就可以了。\nMac OS mac可以使用homebrew来进行安装，如果还没有安装homebrew可以参考我的另一篇文章来进行安装：Mac更换源更快速的安装Homebrew.然后通过命令brew install iperf3。\nUbuntu/Debian 使用命令：sudo apt-get install iperf3进行安装。如果当前用户是root用户，则可以省略sudo.\nCentos/Red hat 使用命令：yum install iperf3进行安装。\niperf3使用 iperf3分为客户端和服务端，服务端开放端口，客户端则连上对应的端口进行发包，达到测速。下边来使用命令来快速的进行一轮测速：\n服务端 服务端执行命令iperf3 -s -p 1111就启动了：\n1 2 3 4 root@docker:~# iperf3 -s -p 1111 ----------------------------------------------------------- Server listening on 1111 (test #1) ----------------------------------------------------------- 服务端开启1111端口后就等待客户端连上来。\n客户端 客户端执行命令iperf3 -c 192.168.1.222 -p 1111 -i 1 -t 10 ,其中192.168.1.222是你服务端所在服务器的ip，执行后客户端输出如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 $ iperf3 -c 192.168.1.222 -p 1111 -i 1 -t 10 Connecting to host 192.168.1.222, port 1111 Reverse mode, remote host 192.168.1.222 is sending [ 5] local 192.168.1.10 port 56431 connected to 192.168.1.222 port 1111 [ ID] Interval Transfer Bitrate [ 5] 0.00-1.00 sec 52.1 MBytes 435 Mbits/sec [ 5] 1.00-2.00 sec 67.4 MBytes 567 Mbits/sec [ 5] 2.00-3.00 sec 58.6 MBytes 492 Mbits/sec [ 5] 3.00-4.00 sec 71.4 MBytes 600 Mbits/sec [ 5] 4.00-5.00 sec 69.2 MBytes 579 Mbits/sec [ 5] 5.00-6.00 sec 69.8 MBytes 586 Mbits/sec [ 5] 6.00-7.00 sec 67.5 MBytes 568 Mbits/sec [ 5] 7.00-8.00 sec 70.9 MBytes 593 Mbits/sec [ 5] 8.00-9.00 sec 73.1 MBytes 613 Mbits/sec [ 5] 9.00-10.00 sec 73.1 MBytes 613 Mbits/sec - - - - - - - - - - - - - - - - - - - - - - - - - [ ID] Interval Transfer Bitrate Retr [ 5] 0.00-10.03 sec 676 MBytes 565 Mbits/sec 2 sender [ 5] 0.00-10.00 sec 673 MBytes 564 Mbits/sec receiver iperf Done. 一次测速就完成了。服务端也会有同样的日志输出。可见速度大概是500Mb/s。\n参数详解 具体的参数详细解释可以参考官网的文档;这里我也简单的介绍一下。\n通用参数 通用参数就是客户端和服务端都可以使用的参数。\n命令行选项 说明 -p, \u0026ndash;port n 服务器侦听和客户端连接的服务器端口。这在客户端和服务器中应该是相同的。默认值为 5201。 \u0026ndash;cport n 指定客户端端端口的选项。(iPerf 3.13 新特性) -f, \u0026ndash;format [kmKM] 指定打印带宽数字的格式的命令字。支持的格式有\n\u0026lsquo;k\u0026rsquo; = Kbits/sec \u0026lsquo;K\u0026rsquo; = KBytes/sec\n\u0026rsquo;m\u0026rsquo; = Mbits/sec \u0026lsquo;M\u0026rsquo; = MBytes/sec\n自适应格式根据需要在千级和兆级之间进行选择。 -i, \u0026ndash;interval n 设置周期性带宽、抖动和丢失报告之间的间隔时间（以秒为单位）。如果非零，则自上次报告以来每隔 n 秒带宽参数会生成一份报告。如果为零，则只打印定期报告。默认认为零。 -F, \u0026ndash;file name 客户端：从文件中读取并写入网络，而不是使用随机数据；\n服务器端：从网络读取并写入文件，而不是丢弃数据。 -A, \u0026ndash;affinity n/n,m/m-f 如果可能的话，设置 CPU 关联性（仅限 Linux 和 FreeBSD）。在客户端和服务器上，您可以使用此参数以 n 的形式（其中 n 是 CPU 编号）来设置本地关联性。\n在客户端，您可以使用 n,m 形式的参数覆盖服务器的关联性，仅用于测试。\n请注意，使用此功能时，进程将仅绑定到单个 CPU（而不是包含潜在多个 CPU 的集合）。 -B, \u0026ndash;bind host 绑定到特定网卡，即该计算机的地址之一。对于客户端，这设置输出的网卡接口。对于服务器端，这设置传入网卡接口。这仅在具有多个网卡接口的多宿主主机上有用。 -V, \u0026ndash;verbose 给出更详细的输出 -J, \u0026ndash;json 以 JSON 格式输出 \u0026ndash;logfile file 将输出发送到日志文件。(iPerf 3.13 新特性) -d, \u0026ndash;debug 发出调试输出。主要供开发人员使用。 -v, \u0026ndash;version 显示版本信息并退出。 -h, \u0026ndash;help 显示帮助概要并退出。 以上是通用的参数说明，可以根据需求在执行命令的时候添加。\n服务端参数 下边对服务端特有参数进行说明：\n命令行选项 说明 -s, \u0026ndash;server 在服务器模式下运行 iPerf。（这一次只允许一个 iperf 连接） -D, \u0026ndash;daemon 服务器作为守护进程在后台运行。 -I, \u0026ndash;pidfile file 写入一个包含进程 ID 的文件，这在作为守护进程运行时最有用。（iPerf 3.1 新特性） 服务端的命令选项相对来说少一些。\n客户端参数 下边对客户端特有参数进行说明：\n命令行选项 说明 -c, \u0026ndash;client host 在客户端模式下运行 iPerf，连接到主机上运行的 iPerf 服务器。 \u0026ndash;sctp 使用 SCTP 而不是 TCP（Linux、FreeBSD 和 Solaris）。 (iPerf 3.1新特性) -u, \u0026ndash;udp 使用 UDP 而不是 TCP。 另请参阅 -b 选项。 -b, \u0026ndash;bandwidth n[KM] 将目标带宽设置为 n 位/秒（UDP 默认为 1 Mbit/秒，TCP 无限制）。如有多个流（-P 标志），带宽限制单独应用于每个流。可向带宽说明符添加“/”和数字，称为“突发模式”，将发送给定数量的数据包而不暂停，即使暂时超出指定带宽限制。 -t, \u0026ndash;time n 传输时间（以秒为单位）。iPerf 通常通过在 time 秒内重复发送 len 个字节的数组来工作。默认值为 10 秒。另请参见 -l、-k 和 -n 选项。 -n, \u0026ndash;num n[KM] 要传输的缓冲区数量。通常 iPerf 发送 10 秒。-n 选项会覆盖此设置并发送 len 个字节的数组 num 次，无论需要多长时间。另请参见 -l、-k 和 -t 选项。 -k, \u0026ndash;blockcount n[KM] 要传输的块（数据包）数量。（而不是 -t 或 -n）另请参阅 -t、-l 和 -n 选项。 -l, \u0026ndash;length n[KM] 要读取或写入的缓冲区的长度。iPerf 的工作原理是多次写入 len 个字节的数组。TCP 默认为 128 KB，UDP 默认为 8 KB。另请参见 -n、-k 和 -t 选项。 -P, \u0026ndash;parallel n 与服务器建立的同时连接数。默认值为 1。 -R, \u0026ndash;reverse 以反向模式运行（服务器发送，客户端接收）。 -w, \u0026ndash;window n[KM] 将套接字缓冲区大小设置为指定值。对于 TCP，这设置 TCP 窗口大小。（这会被发送到服务器并在该端使用） -M, \u0026ndash;set-mss n 尝试设置 TCP 最大分段大小 (MSS)。MSS 通常为 MTU - 40 字节。例如以太网，MSS 为 1460 字节（1500 字节 MTU）。 -N, \u0026ndash;no-delay 设置 TCP 无延迟选项，禁用 Nagle 算法。通常仅交互式应用（如 telnet）禁用此功能。 -4, \u0026ndash;version4 仅使用 IPv4。 -6, \u0026ndash;version6 仅使用 IPv6。 -S, \u0026ndash;tos n 传出数据包的服务类型。可用“0x”前缀的十六进制、0 前缀的八进制或十进制。\n常用值：\nIPTOS_LOWDELAY 0x10\nIPTOS_THROUGHPUT 0x08\nIPTOS_RELIABILITY 0x04\nIPTOS_LOWCOST 0x02 -L, \u0026ndash;flowlabel n 设置 IPv6 流标签（目前仅在 Linux 上支持）。 -Z, \u0026ndash;zerocopy 使用“零复制”方法发送数据（如 sendfile(2)），而非通常的 write(2)。减少 CPU 使用率。 -O, \u0026ndash;omit n 省略测试的前 n 秒，以跳过 TCP 慢启动期。 -T, \u0026ndash;title str 使用此字符串作为每个输出行的前缀。 -C, \u0026ndash;linux-congestion algo 设置拥塞控制算法（仅 iPerf 3.0 Linux，iPerf 3.1 支持 Linux 和 FreeBSD）。 以上就是服务端和客户端的所有参数说明。\n","date":"2024-05-03T05:52:37Z","image":"https://images.iminling.com/app/hide.php?key=b0w0Mnh3eThuS0JueUNaajQrNU1LZmIrL2ZIOEpGSUM5aVl0ZWs5bTFCUjhtMWdNN0dmc3FLakhyWExPR2ExRTJqcitLdVU9","permalink":"https://konghanghang.github.io/iminling-pages/2024/how-to-use-iperf3/","title":"服务器带宽测速iperf3工具使用"},{"content":"之前一直在使用其他的影视站去看一些电影，这些影视站基本网速都比较慢，画质也都一般，观看体验也不怎么好，这里顺便也分享一下我一直使用的影视站：影视森林，该站整理了一些比较不错的影视站。偶然的机会下了解到了小雅(xiaoya)Alist，搭配阿里云盘简直不要太爽，作者也在一直更新资源，非常推荐自己搭建，下边就简单介绍一下我的搭建过程以及一些使用。\n准备工作 在进行安装前需要先获取三个东西：token,open token以及folder id,下边介绍一下如何获取这几个信息。另外需要在机器上安装docker，因为小雅Alist是使用docker镜像来安装的，如果本机还没有安装docker,可以参考我的文章：docker安装 来安装docker。\ntoken 打开网站：https://aliyuntoken.vercel.app/，会出现二维码，使用手机端的阿里云盘扫描就可以获取到token。先记录下。\nopen token 打开网站：Get Aliyundrive Refresh Token，首先点击Scan QrCode获取二维码，然后使用手机端阿里云盘扫描，扫描完成后再点击I have scan 来获取refresh token。同时记录下这个token。\nfolder id 打开小雅的分享地址：https://www.alipan.com/s/rP9gP3h9asE，将里边的内容转存到自己的网盘下，选择资源库。\n然后进入到自己的阿里云盘，打开刚才转存的目录，看地址栏，最后那一串字符串就是需要的folder id.记录改folder id.\n经过上边几步，已经准备好了所需要的三个必须信息，下边就开始安装小雅Alist。\n小雅Alist安装 安装有几种方式，小雅也有提供一键安装脚本，比较方便，下边我介绍一下几种安装方式。\n一键脚本 这种方式最简单，在获取了上边的信息后，就可以直接在vps或者自己的电脑上进行安装，打开命令窗口(终端)执行一键安装脚本：bash -c \u0026ldquo;$(curl http://docker.xiaoya.pro/update_new.sh)\"，执行后会提示输入token（32位）、open Token也就是刚才的refresh Token(335位)以及folder id(40位)，输入完成后就开始了安装，等待结束就可以了。通过docker 命令docker ps来查看安装情况,看是否有一个容器名称为xiaoya,存在就说明安装成功。\n一键脚本安装的小雅默认配置文件是在/etc/xiaoya目录下，后续的配置文件都需要往这个文件下配置。\ndocker命令 上边介绍了一键脚本，本质上也是使用docker命令来安装的，如果我们想要自己控制配置放在什么地址，可以把脚本下载下来自行修改，或者来进行docker的配置安装。\n比如我想把配置文件放在/data/xiaoya下，那么我需要在data/xiaoya目录下先新建三个文件:\nmytoken.txt：把信息准备中的token字符串放在这个文件里。 myopentoken.txt：把信息准备中的refresh Token字符串放在这个文件里 temp_transfer_folder_id.txt：把folder id字符串放在这个文件里。 此时准备工作就完成了，可以来使用命令来安装小雅了： docker run -d --network=host -v /data/xiaoya:/data --restart=always --name=xiaoya xiaoyaliu/alist:hostmode,等待安装完成，同样通过docker ps来查看是否启动成功，后续所有的配置文件都放在/data/xiaoya目录下。\ndocker compose安装 这种是我最常用的方式，容器的配置都放在compose文件中，方便管理。和docker安装差不多，也是先需要将三个文件创建出来，目录结构如下：\n1 2 3 4 5 6 7 8 root@docker:~/xiaoya# tree -l . ├── data │ ├── docker_address.txt │ ├── myopentoken.txt │ ├── mytoken.txt │ └── temp_transfer_folder_id.txt └── docker-compose.yaml docker-compose.yaml文件内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 root@docker:~/xiaoya# cat docker-compose.yaml version: \u0026#39;3.9\u0026#39; services: xiaoya: image: xiaoyaliu/alist:latest container_name: xiaoya env_file: - .env restart: unless-stopped ports: - 5678:80 - 2345:2345 - 2346:2346 volumes: - ./data:/data environment: - TZ=Asia/Shanghai 然后在~/xiaoya目录下执行 docker compose up -d启动就可以了。\n经过上边的安装已经可以通过你的机器ip:5678来访问了。\n播放 经过上边安装默认情况下已经可以正常使用了，在网页端找到自己想观看的电影，直接在网页端观看，或者在视频播放器下边的按钮里选择自己本地已安装的程序打开进行播放,例如下边有iina,VLC等播放器，自己在本地安装就可以了。\n也可以在小雅Alist中找到对应的安装包，也提供了很多播放器的安装包：\n安卓手机 想要在安卓手机上使用alist,我是使用tvbox来观看的，在小雅Alist提供的安装包里也是有tvbox的，需要在配置文件目录新建一个docker_address.txt文件，里边填写http://xxxxx:5678，网址最后不需要/, xxx替换为自己的vps的ip，或者搭建机器的内网ip。\n安卓手机正常安装后进行配置：http://xxxxx:5678/tvbox/my.json。\n如果同时有内网以及外网地址，那么想要在公网访问，则需要再多建一个docker_address_ext.txt,里边需要填写公网的ip:端口,然后在tvbox中进行配置:http://xxxxx:5678/tvbox/my_ext.json就可以了。\n电视端 其实和安卓端是一样的，安装tvbox(安装包也是在小雅Alist中获取)，按照安卓的配置方式，进行配置后就可以观看了。\n配置 登录配置 如果你搭建的机器是公网的，又不想别人随便使用，可以通过配置，需要使用账号和密码来登录，需要在配置文件目录添加两个文件:guestlogin.txt,和guestpass.txt两个文件，guestlogin.txt控制Alist网页端需要登录，只是一个空文件就可以了，guestpass.txt里边内容是登录密码，这样子访问你的Alist就需要账号和密码了，账号是：dav，密码是guestpass.txt中的内容。\n其他配置暂时也没有使用到，后续有使用到再进行更新，祝大家都能顺利安装成功。\n","date":"2024-04-20T06:39:56Z","image":"https://images.iminling.com/app/hide.php?key=VTJuMzZadnFMdGQzWkp6ZFlHWk44dm1scFJnV0xZVXp4aGVnbHBCNmszQ2tqSU9sRkxTSmJNZlljSWtSb3pkWVdMdXVkQlk9","permalink":"https://konghanghang.github.io/iminling-pages/2024/how-to-build-xiaoya-alist-and-use/","title":"搭建属于自己的影视小站：小雅Alist安装及使用"},{"content":"前边已经分享了PVE的安装，pve下安装爱快(ikuai)以及pve下安装openwrt实现旁路由，还想要弄一个docker来跑一些其他的服务，docker的安装有两种方式，一种是装一个linux的虚拟机，然后在里边来跑docker,另一种就是今天要介绍的使用CT模板来创建LXC容器跑docker。\nCT模板下载 我这里使用的是debain12来当作模板，可以在pve里下载该模板。\n创建CT 常规 点击创建CT,这里的主机名随便给一个，因为我这里是要专门来运行docker,所以我这里填：docker, 密码是这个容器的登录密码，一定要牢记。另外要把无特权的容器取消勾选。\n模板 模板选择下载的debian模板\n磁盘 磁盘大小根据自己的实际需要给\nCPU cpu把j4125的4核都给过去\n内存 我这里先给2GB，后续根据需求再添加\n网络 我这里手动指定了ip，可以使用dhcp自动分配ip\nDNS dns默认\n确认 刚才设置的一些信息的预览\n创建完成后先不要开机，还需要一些其他的一些配置。\n功能 在功能里勾选NFS等选项\nLXC配置文件 还需要进入pve的shell,对刚创建的LXC容器的配置文件进行修改，位置：/etc/pve/lxc,此时里边应该只有1个配置文件，文件名对应创建的lxc容器在pve里的id。我的是102.conf\n需要在后边再添加几行：\n1 2 3 4 5 6 lxc.apparmor.profile: unconfined # 表示容器内的进程将不受任何 AppArmor 限制 lxc.mount.auto: cgroup:rw lxc.mount.auto: proc:rw lxc.mount.auto: sys:rw lxc.cap.drop: # 用于指定容器内进程的能力限制，允许进程执行一些特定的操作，例如修改系统时间、挂载文件系统等 lxc.cgroup.devices.allow: a 完整的配置如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 root@pve:/etc/pve/lxc# cat 102.conf arch: amd64 cores: 4 features: fuse=1,mount=nfs;cifs,nesting=1 hostname: docker memory: 4096 net0: name=eth0,bridge=vmbr0,firewall=1,gw=192.168.1.253,hwaddr=BA:64:EF:29:04:A6,ip=192.168.1.22/24,type=veth ostype: debian rootfs: local-lvm:vm-102-disk-0,size=30G swap: 512 lxc.apparmor.profile: unconfined lxc.mount.auto: cgroup:rw lxc.mount.auto: proc:rw lxc.mount.auto: sys:rw lxc.cap.drop: lxc.cgroup.devices.allow: a 配置完成后就可以正常启动该容器了。\n更换源 源文件路径：/etc/apt/sources.list,替换为下边的内容。\n1 2 3 4 root@docker:/etc/apt# cat sources.list deb https://mirrors.ustc.edu.cn/debian bookworm main contrib deb https://mirrors.ustc.edu.cn/debian bookworm-updates main contrib deb https://mirrors.ustc.edu.cn/debian-security bookworm-security main contrib 查看是否替换成功，执行命令apt update:\n1 2 3 4 5 6 7 8 9 10 11 root@docker:/etc/apt# apt update Hit:1 https://mirrors.ustc.edu.cn/debian bookworm InRelease Get:2 https://mirrors.ustc.edu.cn/debian bookworm-updates InRelease [55.4 kB] Get:3 https://mirrors.ustc.edu.cn/debian-security bookworm-security InRelease [48.0 kB] Get:4 https://mirrors.ustc.edu.cn/debian-security bookworm-security/main amd64 Packages [148 kB] Hit:5 https://download.docker.com/linux/debian bookworm InRelease Fetched 251 kB in 1s (228 kB/s) Reading package lists... Done Building dependency tree... Done Reading state information... Done 51 packages can be upgraded. Run \u0026#39;apt list --upgradable\u0026#39; to see them. 可见已经替换成功。\nSSH登录 默认情况下只能通过pve的控制台进行登录，无法在其他地方进行登录。\n修改sshd的配置文件，文件路径：/etc/ssh/sshd_config,添加下边的内容：允许root登录，开启key登录：\n1 2 3 PermitRootLogin yes PubkeyAuthentication yes AuthorizedKeysFile .ssh/authorized_keys 如果只想使用key登录，禁止密码登录可以再添加一行：PasswordAuthentication no 。根据自己需求添加。\n时区设置 默认情况下是0时区：\n1 2 3 4 root@docker:~# date Sun Mar 24 07:04:09 UTC 2024 root@docker:~# date -R Sun, 24 Mar 2024 07:04:11 +0000 修改为北京时间：\n1 2 3 4 5 6 7 8 9 root@docker:~# timedatectl set-timezone Asia/Shanghai root@docker:~# timedatectl Local time: Sun 2024-03-24 15:06:22 CST Universal time: Sun 2024-03-24 07:06:22 UTC RTC time: n/a Time zone: Asia/Shanghai (CST, +0800) System clock synchronized: yes NTP service: inactive RTC in local TZ: no 可以看到已成功设置为北京时间了。\n整个LXC容器已设置完成。\n","date":"2024-03-27T15:28:11Z","image":"https://images.iminling.com/app/hide.php?key=aXJqeW9LcUVTSmRtV2N0TXhRc05EZEpDQXpLTU5oWEtLcW5CejJNa0R0SW0zalI2ZDN1MDVrcUp4Znd3RWtHK1V0em9KeFU9","permalink":"https://konghanghang.github.io/iminling-pages/2024/pve-use-ct-template-install-lxc-docker/","title":"Proxmox VE(PVE)8.0使用CT模板创建LXC版docker服务"},{"content":"前边介绍了PVE的安装，Proxmox VE(PVE)8.0的底层使用的是debian12，默认的源在国外下载速度非常慢，甚至可能连接失败，所以需要更换一下默认源为中科大的源来加快下载以及更新软件的速度。\nAPT源 需要修改三个文件\nsources.list 位置在/etc/apt/sources.list,这个文件里默认有三行：\n1 2 3 4 5 6 7 root@pve:~# cat /etc/apt/sources.list deb http://ftp.debian.org/debian bookworm main contrib deb http://ftp.debian.org/debian bookworm-updates main contrib # security updates deb http://security.debian.org bookworm-security main contrib 替换为一下三条：\n1 2 3 4 5 6 7 8 9 10 root@pve:~# cat /etc/apt/sources.list #deb http://ftp.debian.org/debian bookworm main contrib deb https://mirrors.ustc.edu.cn/debian bookworm main contrib #deb http://ftp.debian.org/debian bookworm-updates main contrib deb https://mirrors.ustc.edu.cn/debian bookworm-updates main contrib # security updates #deb http://security.debian.org bookworm-security main contrib deb https://mirrors.ustc.edu.cn/debian-security bookworm-security main contrib 或使用一键命令进行替换：\n1 2 sed -i \u0026#39;s|^deb http://ftp.debian.org|deb https://mirrors.ustc.edu.cn|g\u0026#39; /etc/apt/sources.list sed -i \u0026#39;s|^deb http://security.debian.org|deb https://mirrors.ustc.edu.cn/debian-security|g\u0026#39; /etc/apt/sources.list 最主要的就是 http://ftp.debain.org 替换为 https://mirrors.ustc.edu.cn , http://security.debian.org 替换为 https://mirrors.ustc.edu.cn/debian-security 。\nceph.list 位置：/etc/apt/sources.list.d/ceph.list,原始内容如下：\n1 2 root@pve:~# cat /etc/apt/sources.list.d/ceph.list deb https://enterprise.proxmox.com/debian/ceph-quincy bookworm enterprise 替换为：\n1 2 3 root@pve:~# cat /etc/apt/sources.list.d/ceph.list #deb https://enterprise.proxmox.com/debian/ceph-quincy bookworm enterprise deb https://mirrors.ustc.edu.cn/proxmox/debian/ceph-quincy bookworm no-subscription 替换完成。\npve-enterprise.list 位置是：/etc/apt/sources.list.d/pve-enterprise.list,这个是pve企业的源，没有订阅pve也就没什么用，直接把这个文件里的内容注释了。\n1 2 root@pve:~# cat /etc/apt/sources.list.d/pve-enterprise.list #deb https://enterprise.proxmox.com/debian/pve bookworm pve-enterprise 到这里apt的源就替换完成了，可以执行apt udpate来看一下是否更换成功。\n1 2 3 4 5 6 7 8 9 10 11 root@pve:~# apt update Hit:1 https://mirrors.ustc.edu.cn/debian bookworm InRelease Get:2 https://mirrors.ustc.edu.cn/debian bookworm-updates InRelease [55.4 kB] Get:3 https://mirrors.ustc.edu.cn/debian-security bookworm-security InRelease [48.0 kB] Hit:4 https://mirrors.ustc.edu.cn/proxmox/debian/ceph-quincy bookworm InRelease Get:5 https://mirrors.ustc.edu.cn/debian-security bookworm-security/main amd64 Packages [148 kB] Fetched 251 kB in 1s (300 kB/s) Reading package lists... Done Building dependency tree... Done Reading state information... Done 94 packages can be upgraded. Run \u0026#39;apt list --upgradable\u0026#39; to see them. 已经使用了中科大的源了，替换成功。\nCT模板源 文件位置：/usr/share/perl5/PVE/APLInfo.pm，需要替换 http://download.proxmox.com 为 https://mirrors.ustc.edu.cn/proxmox,可以执行命令：\n1 sed -i \u0026#39;s|http://download.proxmox.com|https://mirrors.ustc.edu.cn/proxmox|g\u0026#39; /usr/share/perl5/PVE/APLInfo.pm 或者通过直接修改APLInfo.pm的内容进行修改，替换后的内容如下：\n1 2 3 4 5 6 my $sources = [ { host =\u0026gt; \u0026#34;download.proxmox.com\u0026#34;, url =\u0026gt; \u0026#34;https://mirrors.ustc.edu.cn/proxmox/images\u0026#34;, file =\u0026gt; \u0026#39;aplinfo-pve-8.dat\u0026#39;, } 保存后进行重启pvedaemon：systemctl restart pvedaemon.service 。\n整个pve的源就替换完成了。\n","date":"2024-03-26T23:45:43Z","image":"https://images.iminling.com/app/hide.php?key=Z1BQTnU0azJ3OUdjSkc0Sm9FS0Jscjhkb1drV2pXbDlWR3NBcmRoSElPWmVkN1ZCY1BOQnZ2SkRjNUxzcFdDd0dnQmRpQjQ9","permalink":"https://konghanghang.github.io/iminling-pages/2024/pve-change-ustc-source/","title":"Proxmox VE(PVE)8.0换中科大源"},{"content":"前边介绍了roxmox VE(PVE)的安装，一直也没有在pve中进行过联网动作，直到今天想要在pve中运行LXC容器，需要下载CT模板的时候才发现原来pve是无法联网的，于是又开始了折腾pve的网络了。\n情况说明 在我下载CT模板的时候模板列表是能出来的，但是当点击下载后，等待一段时间后就提示无法下载，但是那个地址我直接在浏览器中访问是可以的。在pve的shell中ping一些地址提示：Destination Host Unreachable，如下：\n1 2 3 4 5 6 7 8 9 10 root@pve:~# ping 1.1.1.1 PING 1.1.1.1 (1.1.1.1) 56(84) bytes of data. From 192.168.1.251 icmp_seq=1 Destination Host Unreachable From 192.168.1.251 icmp_seq=2 Destination Host Unreachable From 192.168.1.251 icmp_seq=3 Destination Host Unreachable From 192.168.1.251 icmp_seq=4 Destination Host Unreachable ^C --- 1.1.1.1 ping statistics --- 5 packets transmitted, 0 received, +4 errors, 100% packet loss, time 4065ms pipe 4 但是ping内网的网段是完全ok的，可见是内网通，只是无法连接到互联网。\n问题分析 在遇到上边问题后，我也上网找了一些解决办法，大部分都是说DNS服务器设置的不对，第一个为lan，第二个为阿里的dns服务器，第三个为爱快(ikuai)的地址，这样子设置后发现还是同样的问题。\n后来在网络配置中发现了问题，这里的网关我配置的是192.168.1.1。\n当时安装pve的时候在规划网络时填的是192.168.1.1，但是当安装完pve，进行ikuai配置的时候我改变了注意，把ikuai的地址分配为192.168.1.253，所以导致192.168.1.1其实并没有设备使用，导致pve无法访问网络。\n问题解决 既然找到了问题，那就修改一下试一试，于是对pve的网关配置进行修改，把网关地址设置为爱快(ikuai)的地址：\n再去pve中进行ping检测，发现已经可以通了。\n1 2 3 4 5 6 7 8 9 10 root@pve:~# ping 1.1.1.1 PING 1.1.1.1 (1.1.1.1) 56(84) bytes of data. 64 bytes from 1.1.1.1: icmp_seq=1 ttl=54 time=152 ms 64 bytes from 1.1.1.1: icmp_seq=2 ttl=54 time=164 ms 64 bytes from 1.1.1.1: icmp_seq=3 ttl=54 time=166 ms ^C --- 1.1.1.1 ping statistics --- 3 packets transmitted, 3 received, 0% packet loss, time 2002ms rtt min/avg/max/mdev = 151.887/160.656/165.863/6.236 ms root@pve:~# 成功的解决了pve无法联网的问题。\n","date":"2024-03-26T05:34:09Z","image":"https://images.iminling.com/app/hide.php?key=Z1BQTnU0azJ3OUdjSkc0Sm9FS0Jscjhkb1drV2pXbDlWR3NBcmRoSElPWmVkN1ZCY1BOQnZ2SkRjNUxzcFdDd0dnQmRpQjQ9","permalink":"https://konghanghang.github.io/iminling-pages/2024/pve-network-troubleshooting/","title":"Proxmox VE(PVE)8.0无法访问网络排查"},{"content":"很久以前就拿到了ITIN，在这期间使用ITIN也成功的申请到了Capital One(C1)的信用卡 和 American Express(AE)的信用卡，今天就来分享一下使用ITIN申请美区的Stripe的经历。\n注册 stripe的注册很简单，只需要邮箱就可以注册成功，地址：stripe官网。\n验证完毕登录到stripe后就被要求需要激活支付账户。\n账户激活 如下图，要求激活账户。\n点击激活支付功能\n商家类型 地区美国，类型个人。\n个人详情 法定名称就是自己的姓名，第一行名，第二行姓。\n家庭地址我这里填写的申请ITIN时的地址。\n电话号码填写的是GV号\n社会保障码后四位：填写ITIN后四位\n商家详情 纳税人识别码：填ITIN\n商家地址：和上边个人详情的一样\n网站：自己的网站\n产品描述：介绍一下为何收款，我这里填的是英文的。\n公开详情 添加一些描述以及客服地址等信息\n银行详情 我这里使用的是revolut的美元账户。\n路径号码：ACH号码\n账户：银行账号\n两步验证 出于安全，添加2FA\n税款计算 默认\n捐款 拒绝白嫖\n摘要 摘要信息\n提交等代审核就可以了。\n设置账户 进入stripe的首页，提示账户已激活。\n但是当我们去创建收款的时候，发现还是不能使用。\n点击添加信息，发现还需要再次输入ITIN，提交。\n手机号验证 账户详情处进行手机号验证\n经过这些处理后基本已经可以正常使用了。\n可以在账户状态看是否还需要补充什么信息，如下图就说明完全不需要补充资料了。\n账号注册完毕，可以开心收款了。\n","date":"2024-03-25T05:35:52Z","image":"https://images.iminling.com/app/hide.php?key=UC9DejIvQjdPSGFkV2JMSGptSlBBOVhWS2dYR0Vpd0c5aHN1RSs4dE1BWko2bWNUcklXMDROejVFQXJCSkRQTklpcE0wVjA9","permalink":"https://konghanghang.github.io/iminling-pages/2024/itin-register-stripe/","title":"使用ITIN注册美区stripe进行收款"},{"content":"在前两篇文章中分别介绍了pve的安装以及pve安装ikuai做为主路由来拨号上网，此时的网络环境基本已经稳定，但出于特殊需求，我需要使用Openwrt来进行科学上网，所以今天就来折腾一下pve安装Openwrt并实现旁路由模式。\nopenwrt镜像 我使用的是骷髅头的openwrt镜像，下载的是beggar版本，可根据自己的需求找不同的openwrt版本。下载完成后需要对文件进行解压，下载下来的是.gz结尾的文件，需要解压成.img结尾的文件，解压后上传到pve中\n创建 常规 vm ID默认自增到101(ikuai是100)，名称自己填，我这里填openwrt\n操作系统 选择不使用任何介质\n系统 全部默认就可以了\n磁盘 这里保持默认，后边会进行删除。\nCPU 同样把j4125的四个核心都给到它\n内存 运行openwrt,1GB的RAM就够用了。\n网络 全部默认\n确认 确认所有选项是否正确。\n没有问题就点完成。\n硬件配置 创建过程中选择的硬盘是需要删除的，所以需要对硬件进行一些配置。\n移除CD 在硬件配置中将已存在的CD/DVD驱动器移除\n分离并移除硬盘 选中硬盘，先进行分离，然后进行移除。\n移除\n添加磁盘 需要通过进入pve的shell执行命令来导入磁盘,执行命令qm importdisk 虚拟主机编号 /var/lib/vz/template/iso/openwrt镜像名 local-lvm ，虚拟主机编号是在经过上边创建虚拟机后pve生成的一个编号，例如我的是101，openwrt镜像名是在刚开始的时候上传到pve中的名称，我的名称是：openwrt.img. 替换后的命令如下：qm importdisk 101 /var/lib/vz/template/iso/openwrt.img local-lvm。\n执行成功后会在硬件中看到一个未使用的磁盘，进行添加。\n引导顺序 磁盘添加后需要修改引导为当前的磁盘\n经过上边的设置就已经完全ok了，可以来启动openwrt了。\nopenwrt设置 启动openwrt虚拟机，如下会卡住，敲回车就可以进行下去\n回车后如下图，表示启动成功\n设置ip 一般固件都有自己的管理ip，可能和我们自己的网络不是在同一个网段，比如我下载这个默认的管理网段是192.168.6.1，我需要改成和我的网络在同一个网段，192.168.1.xxx。\n编辑 /etc/config/network，修改如下：\n我这里改成192.168.1.254，修改保存后重启openwrt,重启后就可以通过访问192.168.1.254在浏览器中进行相关配置了。\nLAN口设置 进入openwrt系统后，首先是对网络接口LAN口进行设置，设置网关为爱快(ikuai)的管理地址，并关闭LAN口的DHCP功能\n修改网关\n这里需要注意一点，我在刚开始设置的时候并没有设置使用自定义DNS服务器，后边发现openwrt无法上网，最终是填写了一个DNS服务器后才解决的，这里可以使用223.5.5.5或者其他的DNS服务器。\n关闭防火墙 接下来关闭openwrt的防火墙\nUPNP 开启UPNP\n经过上边的设置，openwrt基本已设置完毕，可以开始使用了。\n旁路由模式 openwrt做为旁路由，该怎么工作呢，在ikuai设置的时候我设置了31-250的一个DHCP网络段，他们只会经过ikuai来处理流量，那什么设备可以经过这个openwrt旁路由呢？这里就需要在ikuai中进行一些设置了，同样是DHCP服务,我设置了10-30这个ip段的ip的网关为192.168.1.254也就是openwrt的ip，那么这个ip段里的设置的网络就会经过openwrt来处理，满足特定需求了。\n因为我是先设置的31-250这个ip段，所以连接上来的设置被优先往这个ip段分配，自己的其他设置如果想要使用openwrt来处理流量，则对特定设置固定ip就可以了，设置他们的ip在10-30之间。\n大功告成，使用pve安装ikuai并使用openwrt做为旁路由。\n","date":"2024-03-24T05:43:31Z","image":"https://images.iminling.com/app/hide.php?key=UHVPZkRvYkllMlN2SzRMa09qTXcxSDNHaVd1czRGUGtjbmtNM2RoWnpCWEtWb0FYUmF5OHRtZWhxT3JQb2RUd2RDZkQvS3M9","permalink":"https://konghanghang.github.io/iminling-pages/2024/pve-install-openwrt/","title":"Proxmox VE(PVE)8.0安装Openwrt实现旁路由模式"},{"content":"上一篇介绍了在J4125机器上安装pve环境，安装好pve后整个机器还是无法上网的状态，所以接下来就来介绍一下在pve中安装爱快，使用爱快(ikuai)来进行拨号上网，当然也可以直接安装openwrt,出于综合考虑我这里还是安装爱快(ikuai)，会稳定一些，后续再折腾其他的也不影响家人上网。\n爱快(ikuai)固件 爱快(ikuai)的固件也不大，直接官网下载就可以了，下载ISO 64位的镜像。把下载的镜像上传到pve中\n创建ikuai虚拟机 鼠标右键点击pve选择创建虚拟机：\n常规 名称命名为ikuai，其他默认\n操作系统 ISO镜像选择上传的爱快镜像：\n系统 保持默认继续下一步\n磁盘 ikuai我不做其他用处，所以这里给5GB硬盘\nCPU cpu把j4125的四个核心都给它\n内存 我这里给2GB的内存\n网络 默认\n确认 显示ikuai虚拟机的一些信息，确认和我们选择的是否一致\n一些基本信息就已经完成了。\n添加直通网口 在畅网J4125安装pve 8.0一 篇中已经规划了ETH3归为pve的管理口，那么剩下的三个网口都直通给ikuai,让ikuai来管理,选择硬件，然后点击添加，PCI设备，就会弹出下图：\n可以看到总共有4个I226-V的网口，04已经被pve管理口使用了，那么可以把01，02，03分别添加到硬件中。\n设置引导项 默认优先是从添加的硬盘启动，因为是第一次启动硬盘里还没有数据，所以需要先从上传的ISO文件引导启动，修改启动项为ISO文件\n安装 经过上边的设置，下边就可以来真正的安装，点击启动\n选择1安装到硬盘，安装成功后就会自动重启。重启后先关闭虚拟机，因为启动项问题 还是从镜像启动的，所以先关机 然后去调整启动项为硬盘\n调整完成后就可以再次启动ikuai虚拟机了。\n设置LAN 看到下图说明ikuai已经安装并启动成功了\n可以看到上图里有四个网口，eth0-eth3,其中eth0是pve一个虚拟网口，是ikuai的管理网口，其他三个网口是直通的三个PIC网口设备，后边进入ikuai设置界面后会把eth1设置为wan口，用来连接光猫拨号使用。\n选择2设置LAN,我规划的ikuai的管理地址是192.168.1.253\n设置成功后就可以不用再理pve了，此时可以通过网页进入ikuai的管理页面，浏览器直接访问192.168.1.253(这个根据自己设置的lan地址来进入)，密码都是admin/admin。初次登录会让改密码，修改为自己常用的密码。\n配置WAN 进入管理页面后会看到WAN口有异常，先配置WAN口\n绑定wan并设置pppoe拨号上网：\n设置好WAN后，此时还没有把WAN口和光猫连在一起，网络还是不行，我们先完成一些其他的配置项。\n配置LAN 将直通给爱快的其他两个口分配给lan\nDHCP配置 对连接上来的设备进行ip地址自动分配\n添加一条新的dhcp配置,我这里预留一些ip给自己使用，所以分配的ip是从31到250。\n网关：设置为ikuai自己的ip\nDNS：设置了一个阿里的和一个114的。\n其他默认就好。\n然后重启dhcp服务。\nUPNP 开启ikuai的UPNP服务\nikuai的设置基本已经设置完毕了。剩下的就是要接入互联网了。\n把光猫连在j4125机器的eth1上，路由器接到机器的eth3上来开启wifi，整个家庭的网络就已经通了。\n","date":"2024-03-24T04:02:02Z","image":"https://images.iminling.com/app/hide.php?key=MGt0VDNLdUNhUDI2MXVlRkUvSXZvVS9KSE14UzlOazF4Z3JqRjhmVnhFbmV0UzdXNE1NUXUyNUxXNkVQNjN6VlVtL1JpN009","permalink":"https://konghanghang.github.io/iminling-pages/2024/pve-install-ikuai/","title":"Proxmox VE(PVE)8.0安装爱快ikuai虚拟机并直通网卡"},{"content":"年前综合考虑买了一台畅网的J4125，低功耗，也能满足一些搞机需求。由于一直忙于工作，一直没有时间研究它，最近终于抽空给机器装上了PVE8.0系统，记录一下折腾的过程。\n机器配置 畅网J4125\n英特尔®第十代Gemini Lake低功耗四核处理器 4个Intel i226-V 2.5G网卡 2条SO-DIMM DDR4 2400MHz（兼容2666/3200MHz） 1个mSATA接口、1个SATA3.0硬盘接口 1个HDMI 1.4接口支持4K（4096x2160@30Hz） 1个DP 1.2接口支持4K（4096x2160@60Hz） 4个USB 3.0 全长miniPCle插槽支持USB信号的4G/WiFi通讯模块 直流DC-12V 55*25输入或凤凰端子供电 支持看门狗、GPIO、PXE无盘启动、网络唤醒 我这边是买了一个梵想的256G mSATA硬盘，另外买了两个三星8GB,3200HZ的内存条，整机的硬件算是完成。\n准备工作 U盘 安装PVE需要从U盘进行启动，这里使用ventory来制作启动盘。电脑上插上需要制作启动盘的U盘，然后下载ventory解压后运行ventory2Disk.exe，设备选择自己的U盘，安装就可以了。\nPVE下载 直接PVE官网进行下载，根据自己的情况下载，我这里下载的是8.0的版本。\n把下载好的pve镜像放到上边制作好的U盘中。\n准备工作已完成。\n安装PVE 安装的所有截图都来源于网络，因为安装的过程没办法截图，具体的ip地址请以文字中说明的为准。\n网段是：192.168.1.xxx\n网关：192.168.1.253\npve管理ip：192.168.1.251\n网口规划 机器有4个网口，ETH0、ETH1，ETH2，ETH3，我打算是让ETH3来作为管理端口，所以在后边安装的时候选择最后一个网口。\n安装 下边就可以开始安装pve了，机器通过HDMI连接到显示器，并连接键盘和鼠标。然后进行开机，我这台机器是按delete键进入bios设置,在Boot选项中选择Boot option #1中选择上边制作的启动盘，然后F10保存重启。\n模式选择 开机后就进入了安装，选择第一个模式进行安装： 协议 接下来就是同意协议：\n硬盘选择 选择硬盘，选择自己的J4125机器中安装的硬盘，不要选择成了U盘。 地区设置 地区和时区以及键盘设置： 密码设置 管理密码和邮箱设置,密码在后边登录pve的时候要用到，请牢记。 网络设置 接下来的就是重点了，需要指定pve的管理网口以及ip的一些信息 假如我想让我家的所有设置的ip是192.168.1.xxx开头,其中第三位的1可以替换为自己想要的网段，比如：192.168.31.xxx(小米路由器就是用这个网段)\n详细说明一下这5个选项：\n管理接口：这里在上边也说了，我打算把管理接口放在ETH3，所以我这里选了最后一个：enp4s0.\n主机名称：这里可以不用处理，默认就行了。\nip地址：这里的ip是等下在网页登录的地址，根据自己需求来指定，我自己的设置为192.168.1.251,\n网关：这里是主路由的地址，比如我在安装pve后想要再装ikuai来拨号上网，并且ikuai的管理ip为：192.168.1.253，那么我这里的网关地址就填这个了。如果你后边的ikuai是其他的ip，替换为自己的。\nDNS服务器：填写和网关一样的地址就可以了。\n这里的网关如果填错了也没关系，后边在pve里也可以进行修改，如果填错最直接的表现就是pve没办法上网。这个我在折腾的过程中也遇到了。\n剩下的就是核对信息，然后进行安装了。等安装完成后会提示让重启。进行重启就可以了，在重启的时候拔掉U盘，防止又从启动盘中进行了启动。\nPVE设置 上边安装pve后会进行重启，重启后会进入一个命令界面，需要输入账号和密码才能进入\n这时候可以把机器连接到电脑，使用电脑通过网页端来设置pve了。正确的连接方式是：在安装过程中的管理端口连上网线，网线的另一端插入到电脑的网线口，并设置电脑端和pve在同一个网段（这个在上边安装的时候已经说明过），比如我的安装网段是192.168.1.xxx，pve管理ip是：192.168.1.251，那么设置电脑的网络为192.168.1.200就可以了。\n设置好后就可以通过网页端访问ip：192.168.1.251:8006来访问了,如果提示不安全则点击高级继续访问：\n然后输入用户名和密码进行登录，用户名：root，密码是在安装的时候输入的密码。就进入了pve的管理界面：\n网口直通 进入后首先需要设置的就是网口直通，进入pve的shell界面，修改/etc/default/grub文件，修改GRUB_CMDLINE_LINUX_DEFAULT=\u0026ldquo;quiet\u0026quot;为GRUB_CMDLINE_LINUX_DEFAULT=\u0026ldquo;quiet intel_iommu=on\u0026rdquo;\n然后执行update-grub更新并重启：\n1 2 3 4 5 6 7 8 9 root@pve:~# vim /etc/default/grub root@pve:~# update-grub Generating grub configuration file ... Found linux image: /boot/vmlinuz-6.2.16-3-pve Found initrd image: /boot/initrd.img-6.2.16-3-pve Found memtest86+ 64bit EFI image: /boot/memtest86+x64.efi Adding boot menu entry for UEFI Firmware Settings ... done root@pve:~# reboot 进行到这里pve安装基本已经完成了，截止到现在pve还不可以上网，这个需要在进行爱快(ikuai)安装后，进行拨号上网让整个环境都有网络。后续在进行介绍。\n","date":"2024-03-23T09:15:47Z","image":"https://images.iminling.com/app/hide.php?key=ZG5zSWhxS29UVDdDc25iUEVOTmRiREVtRjdYOHNNMmNnbHVyRXd2QUJZRnVacll6TW8vZ3EzQ0g2ZnFhYXN5TEozU3hQOUU9","permalink":"https://konghanghang.github.io/iminling-pages/2024/j4125-install-pve/","title":"畅网J4125安装Proxmox VE(PVE)8.0"},{"content":"最近上车的office365到期了，搜索后发现在苹果土耳其商店使用onedrive可以以23.99里拉每个月的价格来开通office365，算下来一个月6块都不到(土耳其钱包FUPS注册可以参考另一篇文章：土耳其虚拟银行FUPS注册教程)，非常划算，所以就开始折腾。手上的iphone se2的版本是15.5，在商店下载onedrive的时候提示当前版本只支持ios16以及更新的ios版本，我又不想升级手上这个手机的版本，于是就想着通过fiddler抓包来获取ios15支持的版本来进行安装。\n旧版本iTunes安装 我这里下载的是12.6.5.3的版本，iTunes的历史版本可以去到wiki百科进行下载：iTunes。这里边包含所有的版本的下载链接，如果打不开wiki百科，可以使用下边这个url进行下载，也是直链苹果官网：iTunes 12.6.5.3。下载正常安装，成功后登录自己的土耳其apple id就可以了。\nfiddler安装配置 fiddler直接去官网下载就可以，官网地址：fiddler。安装成功后首先要开启解密https流量，位置：Tools -\u0026gt; Options -\u0026gt; decrypt https traffic，勾选后就会让添加证书到当前电脑，根据弹窗提示进行安装。\n添加成功后，把ignore server certificate errors(unsafe)也勾选一下。到这里fiddler就设置好了。\n获取oneDrive版本 直接在iTunes中进行搜索，找到oneDrive：\n点击查看详情，可以看到一个show all versions的链接，点击查看所有的版本说明：\n版本说明如下，可以看到官方的说明，14.21.7是最后一个支持ios15的版本，后续的版本只支持16和17.这个版本就是我需要的版本了。\n现在只是知道了版本是哪个，在下载历史版本的时候需要获取一个9位数的id才能正确的下载到对应的版本。所以需要先获取历史版本的id。\n获取历史版本id 此时需要使用到fiddler来进行抓包，如果已经启动了fiddler可以先清理一下已经抓取的历史记录,如下图，remove all或者使用快捷键：ctrl+x清除：\n清除后在iTunes里进行一次onedrive的下载，此时在fiddler里会有一个pxx-buy开头的url，这个url就是我们需要找的url，在这里边可以获取到onedrive所有的历史版本id，先双击这个url，在右侧就会有信息展示出来，如下：\n上图我框起来的有一处是说响应体被加密，需要点击来解密(Response body is encoded. Click to decode)，鼠标点击一下，在textView下就可以找到对应的id了,这个id从上到下一次递增，越新的版本越靠后：\n通过上边查看onedrive的版本说明看出是倒数第7个版本，从这个版本列表里倒序去找第7个再下载一下看看是不是需要的版本，我在尝试后发现并不是倒数第7个id，具体的规则也不清楚，但是大概位置不会错，下载后看版本：如果大了就继续倒序往上找，如果小了就正序再往下找。最终我是找到了id：861576168，下边说一下怎么去下载历史版本。\n下载历史版本 通过上一步拿到了很多的版本id，倒序从后边先随便找一个id来下载一下看看版本具体是什么。因为在获取版本的时候已经下载过了一次，所以需要在iTunes中把原来的给删除了：\n通过文件-\u0026gt;资料库-\u0026gt;打开Genius来打开已下载的程序,如下选择应用，然后把已经下载的给删除了。\n删除成功了后，需要在fiddler程序里输出一下命令: bpu MZBuy.woa。，然后fiddler就可以拦截请求，给咱们机会去修改请求的id，从而达到下载历史版本的需求，输入完需要敲回车，使之生效：\n然后就是继续清除fiddler里已经抓取的url方便下边去找url，清除后再去itunes里点击一次下载：\n点击下载后，在fiddler里可以看到图标是一个T字的url，它此时已经被拦截了，需要等待我们手动的处理是中断(Break on Response)还是继续运行完成(Run to Completion),此时需要我们在TextView下去修改string包裹的那一串id，替换成需要的历史id，替换完成后，点击Run to Completion就会按照我们替换后的id来继续下载了。下载完成后在文件夹里查看当前下载的文件，就会显示是什么版本：\n如上下载到了最终的14.21.7版本。\n安装 下载了之后就需要安装到手机上，这里也非常简单，电脑下载爱思助手，选择手动安装软件，选择上边下载好的ipa文件就可以了。\n记录如上。愉快的使用oneDrive来购买office365\n","date":"2024-02-20T15:17:33Z","image":"https://images.iminling.com/app/hide.php?key=U0c5REZ3L1p2bU1COUVtaVVxeWhJUndqNHNUYXYwQ0E5aGM1Zld1dEhyMUt1c0l5eGpxQjhUOGJOOS84RXhaN0FIcXo3SWs9","permalink":"https://konghanghang.github.io/iminling-pages/2024/fiddler-captures-the-old-version-of-itunes/","title":"使用fiddler抓包旧版本iTunes并下载ios历史版本软件"},{"content":"前边写过一篇通过fail2ban来拦截ssh暴力破解：docker安装fail2ban并配置防止ssh登录爆破，fail2ban能做到的远不止这些，如果你有一个属于自己的网站，那么一定会遇到有无数不知明ip来访问你网站的敏感路径，总是想着要来获取你网站的一些有用信息。今天我们就来使用fail2ban去拦截那些非法访问的ip地址。\n环境与目录情况 fail2ban如上篇：中的安装方式，是使用docker来安装的 nginx也是使用docker来安装的，并使用的是桥接网络。 然后再来看一下配置的目录：\n1 2 3 4 5 6 7 8 9 10 11 ubuntu@VM-20-3-ubuntu:~/images/fail2ban$ tree . ├── data │ ├── filter.d │ │ └── nginx-cc.conf │ └── jail.d │ ├── nginx-cc.conf │ ├── sshd.conf ├── docker-compose.yaml ├── .env └── logs 如上，需要创建两个文件，一个是针对非法访问的日志的过滤规则，另一个是针对非法访问的ip的监狱规则。我这里暂定这个监狱的名称就叫做：nginx-cc,filter.d和jail.d中的配置文件名称一致。\n过滤配置 先来看一下过滤规则的配置：\n1 2 3 [Definition] failregex = ^\u0026lt;HOST\u0026gt; .* \u0026#34;(GET|POST|HEAD).*HTTP.*\u0026#34; (404|503) .*$ ignoreregex =.*(robots.txt|favicon.ico|jpg|png) failregex配置的就是针对错误访问日志进行过滤的正则表达试，以ip开头，并把ip使用\u0026lt;HOST\u0026gt;代替。这里是针对访问状态是404和503的请求。 ignoreregex配置了针对什么样的路径日志进行忽略。\n以上是nginx默认日志的访问日志匹配的正则，如果你修改了自己的nginx的访问日志输出格式，则需要按自己的日志输出格式来编写失败请求的正则表达式。\n监狱配置 直接先看一下监狱的具体配置：\n1 2 3 4 5 6 7 8 9 10 11 [nginx-cc] enabled = true filter = nginx-cc chain = DOCKER-USER #action = iptables-multiport[name=nginx-cc, port=\u0026#34;http,https\u0026#34;, protocol=tcp] port = http,https logpath = /var/logs/nginx/access.log maxretry = 3 bantime = 86400 findtime = 3600 ignoreip = 192.168.0.1/24 下边详细说明一下各参数： filter对应的就是上边的过滤规则中的名称 chain为DOCKER-USER,因为nginx是使用docker安装的，所以需要把iptables的规则添加到DOCKER-USER中，DOCKER-USER中的规则在Docker自动创建的任何规则之前加载，拥有更高的优先级。 port满足添加是禁止的端口 logpath读取的日志路径 findtime日志文件中分析错误连接数的时间。以秒计算\n启动配置 因为以前已经配置过sshd的监狱，并且fail2ban也是正常运行的，此时只需要对配置进行重新加载就可以了，可以使用以下命令：\n1 2 ubuntu@VM-20-3-ubuntu:~/images/fail2ban$ docker exec fail2ban fail2ban-client reload OK 再来查看当前生效的监狱有哪些：\n1 2 3 4 ubuntu@VM-20-3-ubuntu:~/images/fail2ban# docker exec fail2ban fail2ban-client status Status |- Number of jail: 2 `- Jail list: nginx-cc, sshd 可以看到nginx-cc监狱已经生效了，再来看一下这个监狱的详细情况：\n1 2 3 4 5 6 7 8 9 10 ubuntu@VM-20-3-ubuntu:~/images/fail2ban# docker exec fail2ban fail2ban-client status nginx-cc Status for the jail: nginx-cc |- Filter | |- Currently failed: 0 | |- Total failed: 134 | `- File list: /var/logs/nginx/access.log `- Actions |- Currently banned: 0 |- Total banned: 21 `- Banned IP list: 可以看到鉴于的详细信息，此时不出意外就可以拦截到那些异常情况了。\n遇到的问题 不出意外，肯定会出意外。我在debian11的机器上安装，请求404的url会被记录到Total failed里，并且请求失败的ip也会出现在Banned Ip list里，但是被ban后竟然还可以访问，此时通过查看fail2ban容器发现竟然添加iptables规则的时候出现了异常。\n如上图，出现iptables: No chain/target/match by that name 错误，导致iptables规则添加失败，通过iptables -nvL的确也看不添加的被禁的ip。在网上找了好久不知道是什么原因，后来发现官方的github仓库的说明里就有关于这个的说明crazy-max/docker-fail2ban：\nIf your system\u0026rsquo;s iptables tooling uses the nftables backend, this will throw the error stderr: 'iptables: No chain/target/match by that name.'. You need to switch the iptables tooling to \u0026rsquo;legacy\u0026rsquo; mode to avoid these problems. This is the case on at least Debian 10 (Buster), Ubuntu 19.04, Fedora 29 and newer releases of these distributions by default. RHEL 8 does not support switching to legacy mode, and is therefore currently incompatible with this image.\n原来是因为iptable的模式问题，默认debian11使用的nf_tables模式,按照官方的提示需要切换为legacy模式，如何查看自己的iptables是哪种模式呢？可以使用iptables --version来查看，如下就使用的是nf_tables模式。\n1 2 ubuntu@VM-20-3-ubuntu:~# iptables --version iptables v1.8.7 (nf_tables) 那如何修改成legacy模式呢？官方也给了解决方案：\nOn Ubuntu or Debian：\n1 2 3 4 $ update-alternatives --set iptables /usr/sbin/iptables-legacy $ update-alternatives --set ip6tables /usr/sbin/ip6tables-legacy $ update-alternatives --set arptables /usr/sbin/arptables-legacy $ update-alternatives --set ebtables /usr/sbin/ebtables-legacy On Fedora:\n1 $ update-alternatives --set iptables /usr/sbin/iptables-legacy 我的系统是debian，所以按照上边的四条来执行，后边两条并没有执行成功，提示没有开启，那就不管了。执行完后可以再使用上边的version命令查看模式是否已经改过来了:\n1 2 3 ubuntu@VM-20-3-ubuntu:~/images/fail2ban# iptables --version iptables v1.8.7 (legacy) ubuntu@VM-20-3-ubuntu:service networking restart 可以看到，已经切换成功了，并且重启了networking服务。此时再去看禁止ip发现还是不行，仍然可以访问，官方建议重启，我以为重启networking就可以了，但是并不行，最后只好对服务器进行了重启，最终终于生效，成功的对异常访问ip进行了禁止。\n以上就是折腾过程，希望可以帮助到大家。\n","date":"2024-02-05T13:12:33Z","image":"https://images.iminling.com/app/hide.php?key=S2lnNFVkM3BpS1h5b1RvRlF3V0tocVFuZ3YrTHQ3YWhJQXp6YnNJdUZlenRpSTZOdmF2b0M0MTJpR2VoaVU1eG1PNTZ6Z1E9","permalink":"https://konghanghang.github.io/iminling-pages/2024/docker-install-fail2ban-interception-nginx-ip/","title":"docker配置fail2ban拦截nginx非法请求ip"},{"content":"平时也没有怎么关注过ssh的日志，而且服务器的ssh登录端口也是默认的22，只是密码设置的相对来说复杂了点，后边听说有人会进行密码爆破，于是就查看了一下ssh的日志，日志路径是/var/log/auth.log，一看整个人都呆了，登录错误的日志不停的刷，都不带停的。如果密码设置的简单点，估计早就被人给试出来了。在网上查询到可以使用fail2ban来进行防御，把经常访问出错的ip加入到iptables中，禁止掉它的访问，于是就开干了，开始摸索fail2ban如何安装使用。\n1 2 3 4 5 6 Feb 3 15:04:36 localhost sshd[3030796]: pam_unix(sshd:auth): check pass; user unknown Feb 3 15:04:36 localhost sshd[3030796]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=170.64.155.113 Feb 3 15:04:37 localhost sshd[3030785]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=104.250.50.16 user=root Feb 3 15:04:38 localhost sshd[3030796]: Failed password for invalid user es from 170.64.155.113 port 56728 ssh2 Feb 3 15:04:39 localhost sshd[3030796]: Connection closed by invalid user es 170.64.155.113 port 56728 [preauth] Feb 3 15:04:39 localhost sshd[3030785]: Failed password for root from 104.250.50.16 port 57284 ssh2 安装fail2ban 我这里使用docker进行安装fail2ban,使用的docker镜像地址：crazy-max/docker-fail2ban,目录如下所示：\n1 2 3 4 5 6 7 8 ubuntu@VM-20-3-ubuntu:~/images/fail2ban$ tree . ├── data │ └── jail.d │ └── sshd.conf ├── docker-compose.yaml ├── .env └── logs docker-compose.yaml文件 先看一下docker-compose.yaml的内容：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 version: \u0026#34;3\u0026#34; services: fail2ban: image: crazymax/fail2ban:latest container_name: fail2ban restart: unless-stopped network_mode: \u0026#34;host\u0026#34; cap_add: - NET_ADMIN - NET_RAW env_file: - .env volumes: - ./data:/data - ./logs/:/var/log/ # sshd 日志映射 - /var/log:/var/logs/sshd:ro logging: driver: \u0026#34;json-file\u0026#34; options: max-size: \u0026#34;5m\u0026#34; max-file: \u0026#34;10\u0026#34; 这里说明两点，首先是网络模式使用的是host模式，第二，因为我们是要检测暴力破解sshd登录的，所以我们需要读取ssh登录的日志，日志文件路径是/var/log/auth.log,所以在卷挂载那里就把ssh日志的目录进行挂载。\n配置监狱拦截 fail2ban中是需要定义监狱(jail)来对访问者进行过滤，每个监狱(jail)可以对应我们的一个服务或者服务的某一个维度，比如我们要对ssh的登录这个场景进行监控，那我们就可以定义一个名称为sshd.conf的监狱配置，这里也是参考github上的示例：sshd.conf,内容如下：\n1 2 3 4 5 6 7 8 9 [sshd] enabled = true chain = INPUT # port = ssh port = 22 filter = sshd[mode=aggressive] logpath = /var/logs/sshd/auth.log maxretry = 3 bantime = 86400 # 禁止一天，单位秒 logpath的配置，因为在docker-compose.yaml中对ssh日志的目录进行了挂载配置，这里根据自己的需要进行修改maxretry也修改为3次，严格一点\n启动拦截 首先启动容器：\n1 2 3 4 5 6 7 8 ubuntu@VM-20-3-ubuntu:~/images/fail2ban$ docker compose up -d [+] Running 4/4 ⠿ fail2ban Pulled 36.8s ⠿ 7264a8db6415 Pull complete 8.6s ⠿ 81330df9fd42 Pull complete 9.4s ⠿ 39280c79d189 Pull complete 9.5s [+] Running 1/1 ⠿ Container fail2ban Started 0.6s 查看当前fail2ban的状态，如下，可以看到有一个监狱：sshd正在生效中:\n1 2 3 4 ubuntu@VM-20-3-ubuntu:~/images/fail2ban$ docker exec fail2ban fail2ban-client status Status |- Number of jail: 1 `- Jail list: sshd 然后再来查看一下sshd监狱的状态，可以看到总共出现了53次错误登录，当前已经拦截了6个ip，信息很详细：\n1 2 3 4 5 6 7 8 9 10 ubuntu@VM-20-3-ubuntu:~/images/fail2ban$ docker exec fail2ban fail2ban-client status sshd Status for the jail: sshd |- Filter | |- Currently failed: 6 | |- Total failed: 53 | `- File list: /var/logs/sshd/auth.log `- Actions |- Currently banned: 6 |- Total banned: 6 `- Banned IP list: 112.213.110.8 196.189.21.247 104.250.50.16 175.144.208.9 183.56.193.178 141.98.11.90 被ban的ip会添加到iptables中，并且fail2ban会主动为每个监狱创建一个Chain,Chain的名称为f2b-监狱名，可以通过命令来查看iptables中添加的规则:\n1 2 3 4 5 6 7 8 9 ubuntu@VM-20-3-ubuntu:~/images/fail2ban$ sudo iptables -nvL f2b-sshd Chain f2b-sshd (1 references) pkts bytes target prot opt in out source destination 0 0 REJECT all -- * * 183.56.193.178 0.0.0.0/0 reject-with icmp-port-unreachable 3 156 REJECT all -- * * 175.144.208.9 0.0.0.0/0 reject-with icmp-port-unreachable 1 60 REJECT all -- * * 104.250.50.16 0.0.0.0/0 reject-with icmp-port-unreachable 3 180 REJECT all -- * * 196.189.21.247 0.0.0.0/0 reject-with icmp-port-unreachable 0 0 REJECT all -- * * 112.213.110.8 0.0.0.0/0 reject-with icmp-port-unreachable 354 24037 RETURN all -- * * 0.0.0.0/0 0.0.0.0/0 可以看到很多ip已经被ban了，这是我才刚启动1分钟不到，就这么多ip被ban了，可见坏人真多，老是想着爆破我的服务器。\nfail2ban的使用 使用docker exec \u0026lt;容器名称\u0026gt; fail2ban-client命令来操作fail2ban。\n查看状态 一个是查看当前总状态：启用了什么监狱，另一个是查看某个监狱的状态，上边已经展示过了，这里就不再详细说了：\n1 2 3 4 5 # 查看状态 docker exec fail2ban fail2ban-client status # 查看指定监狱状态 docker exec fail2ban fail2ban-client status sshd 主动屏蔽ip 我们也可以主动的屏蔽某个ip的访问，通过下边命令：\n1 2 3 4 5 # 指定监狱屏蔽IP（\u0026lt;JAIL\u0026gt;为监狱名） docker exec fail2ban fail2ban-client set \u0026lt;JAIL\u0026gt; banip \u0026lt;IP\u0026gt; # 示例：docker exec fail2ban fail2ban-client set sshd banip 1.1.1.1 ubuntu@VM-20-3-ubuntu:~$ docker exec fail2ban fail2ban-client set sshd banip 183.56.193.179 1 然后再通过查看监狱状态命令查看Banned Ip List中是否已经有了这个ip来判断是否成功。\n主动解除已屏蔽ip 有主动的去屏蔽某个ip，如果设置错误就需要主动把设置错误的取消掉，可以通过下边的命令来进行取消：\n1 2 3 4 5 # 指定监狱解封IP（\u0026lt;JAIL\u0026gt;为监狱名） docker exec fail2ban fail2ban-client set \u0026lt;JAIL\u0026gt; upbanip \u0026lt;IP\u0026gt; # 示例：docker exec fail2ban fail2ban-client set sshd upbanip 1.1.1.1 ubuntu@VM-20-3-ubuntu:~$ docker exec fail2ban fail2ban-client set sshd unbanip 183.56.193.179 1 然后再通过查看监狱状态的命令查看ip是否已经被取消掉。\n以上就是通过安装fail2ban来对暴力破解ssh密码进行拦截，另外也可以通过修改ssh的端口来进行简单的拦截，通常默认的ssh端口是22，如果换了端口他们想要找到这个ssh端口也是要花费一些时间的，再就是可以通过禁用密码只使用key来登录，会更安全一些，这个可以参考我的另一篇文章：修改SSH端口使用公钥登录并禁用root密码登录修改SSH端口使用公钥登录并禁用root密码登录。希望可以帮到大家。\n","date":"2024-02-03T14:52:53Z","image":"https://images.iminling.com/app/hide.php?key=SVBwbXRUTnkxdENoNlUzQ0w1QjVKd2xKc3pVK3BWZjlZNk1aeEtRT1BmcXpEcGlaa1h2c3ZhMnVGZlRXV2sweE1TcDhYTVU9","permalink":"https://konghanghang.github.io/iminling-pages/2024/docker-install-fail2ban-protect-ssh/","title":"docker安装fail2ban并配置防止ssh登录爆破"},{"content":"上篇文章介绍了如何快速的注册土耳其虚拟银行FUPS：土耳其虚拟银行FUPS注册教程，注册后可以申请三张土耳其的visa虚拟银行卡，申请后想要使用面临的第一个问题就是如何给这张虚拟银行卡来进行入金，没法入金基本就代表这张卡是一张废卡。这篇文章就来介绍一下如何使用火币来给这张土耳其的虚拟银行卡进行入金，满足购买需求。\n火币注册 我在注册火币前是先注册了币安的，刚开始什么都不清楚，直接就在币安中购买了20USDT，后来发现大陆KYC的用户只能交易RMB，然后就找到了火币，火币的KYC用四级认证，L1基础认证就可以进行交易，而且L1的认证只需要选择国家就可以认证成功，然后就可以进行交易，对币种也没有限制，很是方便。\n购买USDT USDT是一种资产支持的加密稳定币，基本和美元等价，我们需要把自己的RMB转换成USDT，然后再通过USDT换成我们想要的土耳其里拉TRY，首先我们要登录到火币官网，选择C2C交易，如下图：\n然后就是购买，使用RMB进行购买，然后对商家进行筛选，首先是选择可交易的，有些商家对交易有限制，需要实名或者有交易过等条件，所以需要先筛选出我们可以立马进行交易的；其次是选择可以使用微信、支付宝或银行卡的商家，用这些付款最方便；另外有些商家对购买额度有限制，比如下图中的第一个需要1.5w起购买，我可能只需要购买几十元，所以这类商家就适合我们，需要找一些起步金额较低的商家：\n然后就购买了，我当时购买的一个是需要进行添加微信，然后在微信直接转账给他，他在HTX平台进行放行，然后我们就可以收到购买的币了，整个过程还是比较丝滑的，5分钟搞定。\n购买后的usdt好像是在法币中，具体也不记得了，火币好像不需要在法币和现货里进行转换就可以直接进行交易卖出，如果不行，就需要从法币转移到现货，这个根据具体操作的时候的情况进行调整。资产-我的资产-划转 三步搞定。\n卖出换TRY 购买到USDT后，需要进行卖出换TRY到我们的FUPS账户中，还是在C2C交易中进行，在此之前需要先在火币平台绑定一种收款方式，具体路径如下图，可以随便添加一种方式，实际的付款方式还是在下单后的聊天窗口进行沟通，只要确保可以最后可以收到钱就行了。\n添加了收款方式后我们就可以进行卖出了，选择TRY进行交易：\n同样也有交易限额，选择我们可以接受的限额商家进行交易，然后在聊天窗口询问是否支持FUPS，或者有些商家描述里也是有写的，根据实际需求来选择具体的商家。\n使用FUPS收款我们可以提供二维码或者一个付款链接，具体的生成是在FUPS的应用程序的首页点击top up，然后跳转到下面页面，选择request from others，然后就通过生成二维码或付款链接让对方来付款。\n生成的时候需要输入对方付款的金额，输入完成就可以生成，然后发送给对方，对方付款后立马就可以到。\n我选择的商家使用FUPS需要收取4%的手续费，所以在生成付款链接的时候自己算后扣出手续费后的金额并生成，发送给对方。\n愉快购物 在出U成功后，我收到1080的里拉，然后就去spotify进行Premium的购买，在购买的时候发现需要先对虚拟卡进行交易金额限制，否则spotify无法进行扣款，具体的限额设置是在FUPS的app下方菜单中的Cards中进行设置，可以看到Your Virtual Card Limit选项，有一个new limit和Automatic Card Limit选项，这里一定要设置New Limit,否则还是无法购买。我这里设置100里拉。\n最后祝大家都可以成功的入金进行购买自己想要买的东西。\n","date":"2024-01-31T14:07:04Z","image":"https://images.iminling.com/app/hide.php?key=VkRUWThzZStta2habm5URkFLUHNTRHM3aVI5Nm0rcHdwZE1hU01aMWQxRU91Ry9NUWN3alQrbWdQY1crZ2FtdmZWSVhOaXM9","permalink":"https://konghanghang.github.io/iminling-pages/2024/huobi-fups-payment/","title":"使用火币给土耳其虚拟银行FUPS进行快速入金"},{"content":"以前注册过Oldubil，后来Oldubil限制交易后，一直没有去研究新的代替方案，最近在论坛看到有人成功使用FUPS来购买的Telegram的会员，想着自己的termius会员也快要过期了，所以就研究一下如何注册FUPS来代替Oldubil，下面分享一下注册流程。\n注册条件 注册FUPS算是比较简单的了，需要两个重要的信息：\n土耳其手机号 土耳其身份信息 以上两个信息看似很难，但是对于我们云土耳其用户来说没有什么困难是不能解决的。下边我们就看一下两种信息如何快速的获取到。\n土耳其手机号 对于经常撸土耳其相关服务的人来说，肯定都知道可以找接码平台，但是并不是随便哪个接码平台就可以接FUPS的码，比如我经常使用的sms-activate就没有可以接FUPS的服务，不过功夫不负有心人，在另一个接码平台sms-man还是找到了:\n上边就是在sms-man平台通过先选择国家，然后再选择服务后锁定的FUPS的可用接码服务。成功解决了手机号问题。\n土耳其身份信息 看网上说土耳其有泄漏过一次信息，导致他们国家很多人的信息都被泄漏出去了，如果有能力可以找到那个泄漏的数据就很容易解决这个问题。但是我信息大部分人和我一样，只需要快速的拿到信息就行了，无需了解过多，那么我在网上也搜到一个发卡站，里边有出售土耳其身份信息，售价5元，可以无脑购买。网站：https://pay.catiz.cn。\n收到的信息格式如下：\u0026ldquo;TC\u0026rdquo; \u0026ldquo;FIRST NAME\u0026rdquo; \u0026ldquo;LAST NAME\u0026rdquo; \u0026ldquo;性别\u0026rdquo; \u0026ldquo;出生日期\u0026rdquo; \u0026ldquo;地址\u0026rdquo; \u0026ldquo;区\u0026rdquo; \u0026ldquo;教区\u0026rdquo;\n最后还真的找到了免费的土耳其用户信息：Telegram，里边有免费的用户信息，大家根据自己需要进行获取。\n至次，两个难题就都解决了。\n注册 满足了两上边两个条件后，注册就变的很简单了，手机下载FUPS的应用程序，首次打开默认显示的是土耳其语，我想大部分人都是看不懂的，可以点又上角的_三个点_设置语言为英文，最起码可以读懂一些：\n点击第一个按钮：register，进入注册页面：\n相关信息填写如下：\nYour Name: 购买的土耳其信息中的firstName\nYour Surname: 购买的土耳其信息中的lastName\nID Number: 购买的土耳其信息中的TC\nBirth: 购买的土耳其信息中的出生日期\n填完信息就下一步，进行接码验证，在发送验证码后在接码平台点击获取验证码就可以了。\n获取虚拟卡 注册成功后我们就可以去获取虚拟卡了，我们默认注册的账户是标准账户，限制最大金额是2750里拉，更高的限额需要升级账户等级，升级可能就需要更多资料了，默认2750也是够用的。\n登录后，点击下方的transactions菜单进行，然后选择New Card选项来进行开卡：\n点击了New Card后跳转到如下页面，选择virtual Card进行开卡:\n一个账户最多有3张免费的虚拟卡，经过上边步骤就成功的开到了土耳其的虚拟visa卡，为我们快乐的购物奠定了基础。\n注意 在注册成功后，我想在另一台手机上登录FUPS，发现无法登录，需要用注册时的手机号再一次接码，因为我们是用的接码平台，再一次接码是不可能的了，所以这个账户应该就只能在这一个手机上登录了，大家需要记住相关的卡信息，防止app无法登录，就无法再使用这些虚拟卡了。\n上边介绍了如何注册FUPS，但是距离能购物还有一段距离，教程就先到这里，后续再更新如何入金到FUPS中来进行购物。\n入金教程已更新，详细：使用火币给土耳其虚拟银行FUPS进行快速入金。\n","date":"2024-01-29T15:10:25Z","image":"https://images.iminling.com/app/hide.php?key=MVR5VDd0N0p4aGdsc2s1azE5bng2aHZMb2RndnVrM211TVgxTFNSck1ualZzVnQxVWZ5Q3lvSU1DQkJVYTZTVE40Nm11c2M9","permalink":"https://konghanghang.github.io/iminling-pages/2024/turkey-fups-register/","title":"土耳其虚拟银行FUPS注册教程"},{"content":"不得不说这个世界上坏人还是比较多的，以为购买一台服务器后部署自己的服务后就可以高枕无忧了吗？NO，总有刁民想还朕，默认的SSH端口是22，这个是SSH协议的规范，那么大部分人购买了服务器后也不会想着去更改这个端口，那么就会被一些不法分子利用，服务器用户名默认root，端口默认22，那么他们就会通过这个来扫你的机器，不停的尝试登录，如果我们设置的密码强度不够，那么很快就会被穷举出来，然后你的服务器就被别人控制。今天我们就来做三步操作增强我们服务器的安全性。\n配置公钥 生成密钥对 我们首先要做的就是生成一对密钥，可以使用ssh-keygen来生成一对，生成语法如下：\n1 ssh-keygen -t rsa -f ~/.ssh/my-ssh-key -C [USERNAME] 其中\n-t 指定算法，一般使用rsa非对称加密算法\n-f 指定生成的密钥对存放的路径，可以不指定。\n-C 为该密钥对分配一个用户名，只是为了分组使用，可以随意命名。\n当我们执行生成命令时，如果不指定文件路径，默认会放在当前用户的.ssh目录下，并会为改密钥设置密码，默认不设置，直接回车跳过，经过这个命令就生成了一对密钥，公钥名称：id_rsa.pub，私钥名称：id_rsa\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 $ ssh-keygen -t rsa Generating public/private rsa key pair. Enter file in which to save the key (/Users/aaa/.ssh/id_rsa): Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /Users/aaa/.ssh/id_rsa Your public key has been saved in /Users/aaa/.ssh/id_rsa.pub The key fingerprint is: SHA256:03Gf81aw0hniwCGSylV1VbOntYOrgsw1RicsUxWwKs aaa The key\u0026#39;s randomart image is: +---[RSA 3072]----+ | .oo.o ooB=o| | o. o o B.oo| | . o + O.*.o| | o . = XoOo| | S . +oOo.| | . Eo.ooo| | + . .o| | o . | | | +----[SHA256]-----+ $ ls .ssh config id_rsa.pub id_rsa known_hosts 上传公钥 生成密钥后，我们需要做的是把公钥上传的需要登录的服务器上，这样子我们才能在自己本地或者其他服务器上使用私钥去登录到这台服务器。上传公钥有两种方式，一种是我们直接拷贝公钥里的内容到需要登录服务器的\n1 ~/.ssh/authorized_keys 文件中，如果文件不存在直接新建一个。另一种是直接使用ssh-copy-id命令来完成。\n直接上传文件内容 我这里使用scp命令把文件传到服务器上，然后在服务器上把内容写入到authorized_keys中。上传命令中端口是非必填的默认是22端口，如果没有修改端口可以添加此参数，后边的.pub文件就是你要上传的文件，后边紧跟着你服务器的用户名@ip:具体服务器路径\n1 2 3 4 5 6 7 # scp [-P 端口] ./my-ssh-key.pub [USERNAME]@[EXTERNAL_IP_ADDRESS]:/root/.ssh scp ./my-ssh-key.pub root@192.168.31.1:/root/.ssh # 上传成功后，ssh登录到服务器上，把上传的pub文件追加到.ssh目录下的authorized_keys中。 $ ssh root@192.168.31.1 $ cd .ssh $ cat my-ssh-key.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys 经过上边步骤就上传好了pub公钥了，就可以使用key来登录了。下边介绍一下使用ssh-copy-id来上传。\nssh-copy-id上传 这个上传就很简单了，直接使用命令：\n1 2 # ssh-copy-id -i ./my-ssh-key.pub [USERNAME]@[EXTERNAL_IP_ADDRESS] [-p 端口] $ ssh-copy-id -i ./my-ssh-key.pub root@192.168.31.1 -i 指定要上传的文件路径，\n-p 指定端口，默认22，如果没修改过ssh端口就直接不需要该参数\n公钥登录 在登录前要先确认要登录的服务器是否开启了支持公钥登录，其实现在大部分服务器都是默认支持的，如果遇到登录不了的情况可以检查一下是否开启，具体的文件路径是/etc/ssh/sshd_conf,设置以下参数为yes：\n1 2 3 PasswordAuthentication yes　# 口令登录 RSAAuthentication yes　# RSA认证 PubkeyAuthentication yes　# 公钥登录 如果有修改需要重启一下服务器的sshd服务：\n1 service sshd restart 然后就可以在本地或者其他服务器使用ssh并指定要使用的私钥文件目录来连接这个远程的服务器了：\n1 2 # ssh -i .ssh/my-ssh-key [USERNAME]@[EXTERNAL_IP_ADDRESS] [-p 端口] ssh -i .ssh/my-ssh-key root@192.168.31.1 经过上边步骤就可以使用公钥连接到服务器了。\n修改SSH端口 默认的ssh端口是22，是在/etc/ssh/sshd_conf中配置的，在这个配置文件中我们先找到原来的配置22端口，然后复制一行出来，改成另外一个端口，比如我改成1024端口，那么此时22端口和1024端口应该都是可以通过SSH来访问的，这里一定要小心，不能一上来就把22端口干掉，万一配置错误就凉凉了。所以配置两个端口，保证22端口是肯定可以使用的，然后再添加一个新的端口，配置后重启sshd服务。然后看新配置的端口是否可以访问SSH，如果可以那说明配置没有问题，就可以干掉原来的22端口了。\n1 2 Port 22 Port 1024 配置的属性就叫Port。\n禁用密码登录 上边已经配置了使用公钥登录，并且也修改了SSH的端口，但是root用户的密码还在，那么一旦一些人扫到了服务器的1024端口是ssh，那么他们还是会不停的尝试密码，暴力破解密码，所以需要把密码登录关掉，只用公钥来登录。同样也是修改/etc/ssh/sshd_conf，修改PasswordAuthentication为no就可以了：\n1 2 3 PasswordAuthentication no # 口令登录 RSAAuthentication yes　# RSA认证 PubkeyAuthentication yes　# 公钥登录 经过上边的配置就可以禁用掉root用户的密码登录功能，并修改了SSH登录的端口，这样子服务器的安全性就提高了一些。\n遇到的问题 在第一步上传公钥到服务器的时候，上传成功了，但是始终无法通过公钥去登录到服务器，研究了好久发现是服务器上的目录权限不正确，正确的权限应该是下边这样子的:\n1 2 $ chmod 700 ~/.ssh $ chmod 600 ~/.ssh/authorized_keys ","date":"2024-01-05T15:14:15Z","image":"https://images.iminling.com/app/hide.php?key=b0w0Mnh3eThuS0JueUNaajQrNU1LVXlDSVZsMEY4YlRqQU9leUEzazk0eVJXU2xxRFlLV1pKbXhmdnFpUnArVE1GbTEvZlU9","permalink":"https://konghanghang.github.io/iminling-pages/2024/modify-ssh-port-and-use-publick-key-login/","title":"修改SSH端口使用公钥登录并禁用root密码登录"},{"content":"在本地开发或者在线上环境的时候，本地开发机器和线上都有可能有多张网卡：物理网卡或者虚拟网卡，如果只有一张网卡，那么 Spring Cloud微服务也不会有注册错ip的情况，一旦有多张网卡，问题就会暴露出来，不同的网卡网络段肯定是不同的，那么ip之间也不可能互通，就会出现虽然服务注册到了注册中心，但是却无法访问到这个已注册的服务。\n遇到问题过程 我遇到这个问题主要是在自己的本地电脑上，我电脑上有两个网卡的地址不是同一个段上的，如下：\n有一个192.168.6.6和另一个192.168.64.1的，在我启动我的本地的Cloud服务的时候，Nacos中默认注册的是192.168.6.6的地址：\n经过查询后在boostrap.yaml配置文件中进行修改：\n1 2 3 4 5 spring: cloud: inetutils: preferredNetworks: - 192.168.64 经过配置后，再次启动项目，再看注册中心中注册的地址如下：\n已经是想要的结果了。\n问题深入 在spring官方文档可以查询到，有几种方式可以配置，地址：common-abstractions。\n可以使用忽略特定的网络接口：\n1 2 3 4 5 6 spring: cloud: inetutils: ignoredInterfaces: - docker0 - veth.* 如上忽略了docker的网络接口以及veth相关的网络接口。\n另一种就是我上边提到的preferredNetworks\n配置首选网络，偏向与使用哪个ip地址。\n官网还提到可以强制只使用站点本地地址，如下例所示：\n1 2 3 4 spring: cloud: inetutils: useOnlySiteLocalInterfaces: true 具体详见官网的文档。\n","date":"2023-12-24T09:02:19Z","image":"https://images.iminling.com/app/hide.php?key=SmJabnJsdTlXbDExYlljU3RzemUyTVRlcHFScHFZRUJYSTR1c1BoYkhrZHE3L2RpK05qbkpLQlprcTFPY2QvY3lJaVB3Y3M9","permalink":"https://konghanghang.github.io/iminling-pages/2023/spring-cloud-use-true-ip-register-nacos/","title":"多网卡环境下Spring Cloud微服务注册特定网卡Ip到注册中心(Nacos)"},{"content":"公司有一个项目使用的是Ant来进行打包构建的，没升级IDEA前还可以在工具栏找到Ant功能来进行构建，升级2023.3版本后，Ant就找不到了，经过一番折腾，终于找回了Ant。再次提醒各位，升级还是需要谨慎呀，旧的又不是不能用，哈哈。废话不多说，下边给出具体的解决方法。\n2023.3以前版本 在2023.3版本以前，如果在工具栏找不到Ant，可以在IDEA的菜单中把Ant给添加到工具栏，如下图：\nview菜单 tool windows - Ant就可以找到Ant工具。\n2023.3版本 升级到2023.3版本后，在view菜单 tool windows中找不到Ant选项了，但是多了一个 AI Assistant 的功能，在IDEA中找Ant相关的配置也是无果。\n最后在IDEA的官方日志中找到了原因，官方地址：IntelliJ IDEA 2023.3 最新变化。其实上图里也有说明，只是升级后并没有仔细阅读，而是后来网上找到了中文的升级说明：\n在新版本中Ant要去到市场下载了。\n下载Ant插件 在plugin中搜索Ant，就可以看到一个jetbrains提供的Ant插件，进行下载，然后就可以在view - tool windows中找到Ant插件了。\n安装后立马就可以找到，也不需要重启IDEA，经过上述过程就成功的找回了Ant插件，可以愉快的使用Ant来编译打包项目了。\nIDEA如何使用开源项目申请可以参考我的另一篇文章：开源项目申请JetBrains Open Source Development License。\n","date":"2023-12-16T03:00:20Z","image":"https://images.iminling.com/app/hide.php?key=MklMSXFFczNLSWQ5Zkl4N1RrVGo4NkxlOXJXRTZ6L1B2cndwZEJ2ai9OMnRkV21kdVdzcTZsek1qK1ZKMFJINHVWenoyNjg9","permalink":"https://konghanghang.github.io/iminling-pages/2023/intellij-idea2023-find-ant-tool/","title":"升级Intellij IDEA 2023.3后找回Ant构建工具"},{"content":"在今年三月份我成功的拿到了itin，然后使用itin申请了第一张美国信用卡：captail one的押金信用卡，具体的申请过程可以参考我的另一篇文章：使用ITIN申请capital one信用卡，经过几个月的使用，信用分也积攒的差不多了，所以就萌生了申请American Express(美国运通)信用卡的想法，于是就开始了申请之路，这里分享一下我的申请经历。\n自身情况 从三月份拿到itin申请captial one信用卡后，从5月开始出账单，到现在大概也是出了半年的账单，11月6日在equifax查询信用分是731分，经过11月wise扣款失败产生逾期费用，我本以为信用分会降低，没想到12月6号在equifax查询信用分的时候还涨了1分，申请的时候信用分是732分。\n申请 我们去到AE官网，找到免年费的信用卡，我申请的是：Blue Cash Everyday® Card， 可以根据需求来申请**。**\n往下来找到需要申请的卡片，点击apply now 或者 view details，下面是详细信息页面：\n申请页面需要填的都是一些基础信息，根据自己的实际情况进行填写，填写SSN的时候，根据提示实际上ITIN也是ok的。\n填写完成就提交下一步，同意一些条款并提交申请：\n之后就会出现你的追踪号码页面：\n同时也会收到一封邮件，和上图的提示差不多，总之就是让打电话给他们提供更多的信息来申请这张卡。除了这个邮件外，还有一个是可以查看申请进度的邮件，后边我们会使用这个地址来查看我们的申请进度：\n提交申请后的申请进度查看\n电话客服 我大概是在晚上10点左右给客服电话，客服询问了我的名字，生日，SSN(我报的是ITIN)。以及还问我的军事身份，回答NO。然后说让我记下资料上传的网址，需要上传SSN或者驾驶证等一些资料信息，具体的网址是：https://www.americanexpress.com/upload，随后就挂了电话，我就在资料上传的地址上把护照和ITIN的信上传了上去，同时也收到了邮件，提示收到资料。刚上传完没多久，就收到了美国打来的一个电话，进行二次信息确认，也是简单的问了一下生日和SSN，以及提醒我上传这些信息，但是她很快就发现我已经上传了，就简单说了两句就挂了电话。\n二次电话客服 在提交申请资料后的第二天，我通过查看申请进度的连接发现还需要我上传一些资料，点击查看详情，里边要让我提供SSN，我只有ITIN怎么提供呢？\nview the full decision details的如下：\n无奈又打电话给了客服，报了名字，追踪号码以及地址信息，然后表明没有SSN，只有ITIN，然后就让我再次上传这些资料，挂了电话后我就又去上传了ITIN信和护照的照片，这次提交资料并没有像第一次那样收到邮件提示说收到资料，然后就是继续等待。\n审批通过 再二次致电客服并提交资料后，终于在第二天早上醒来收到了审批通过的邮件：\n根据邮件提示，当前这个节点还没有影响到我的信用分，如果我在美国东部时间12月14日晚上11点59分之前没有接受这个卡片，那申请将会被取消。\nAccept Your Card 根据邮件提示，去接受申请的那张卡片，打开链接后先是一个验证，需要输入邮编号和生日\n继续下一步： 接受或者取消申请，当时就接受了。\n成功接受了申请卡片，根据图片提示我的卡应该会在12月19号收到。然后就是创建AE的账户了。根据提示自行创建就可以了，也没有太多需要注意的。\n卡片额度 captial one的额度是$3200，AE的额度5000，中规中矩吧\n从申请到下卡也不算太曲折，中间历时三天。希望对大家有所帮助。\n卡片邮寄 在12月11日收到邮件通知卡片已邮寄\n追踪邮件，在12月15日显示就已经到了，但是后边两天迟迟没有收到anytimemailbox的邮件，我还以为丢件了呢，后来想想应该是周六日的缘故吧，更新延迟了一些，在12月19日收到了通知\n之后就是转运回国，让房东使用的DHL邮寄回来，费用80$。从12月20号从美国寄出，到今天(12月26号)终于收到了卡片，历时6天。\n卡片照片 信用分 在申请的卡片的时候，我用equifax查询的信用分是732，在运通寄来的信里边有一张纸写是FICO信用分，竟然是769分，不同的地方信用分原来还不一样。\n","date":"2023-12-09T03:40:08Z","image":"https://images.iminling.com/app/hide.php?key=WU9YMHZjQWREeUdDWmVDOVhpWS9RSkRMQU1yejdWSGFZcUZmVCt5aHJDd0ZIZUlzMXBGM085MzgyOEJ6NFB3WFM5bUJyZGs9","permalink":"https://konghanghang.github.io/iminling-pages/2023/itin-apply-american-express-credit-card/","title":"使用ITIN申请American Express(美国运通)信用卡"},{"content":"在上一篇文章中讲解了如何在docker环境下快速的安装prometheus：debian系统使用docker快速安装promutheus，这篇文章咱们来讲一下如何在linux主机中安装node exporter来采集linux系统的各项指标。\n安装node exporter node exporter的安装非常简单，可以去prometheus的官网下载：node exporter - prometheus，或者去github进行下载：node_exporter - github，我这里直接使用wget命令从github上下载最新的安装包wget https://github.com/prometheus/node_exporter/releases/download/v1.2.2/node_exporter-1.2.2.linux-amd64.tar.gz：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 root@admin:~# wget https://github.com/prometheus/node_exporter/releases/download/v1.2.2/node_exporter-1.2.2.linux-amd64.tar.gz --2023-11-25 22:35:44-- https://github.com/prometheus/node_exporter/releases/download/v1.2.2/node_exporter-1.2.2.linux-amd64.tar.gz Resolving github.com (github.com)... 20.205.243.166 Connecting to github.com (github.com)|20.205.243.166|:443... connected. HTTP request sent, awaiting response... 302 Found Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/9524057/28598a7c-d8ad-483d-85ba-8b2c9c08cf57?X-Amz-Algorithm=AWS4-HMAC-SHA256\u0026amp;X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231126%2Fus-east-1%2Fs3%2Faws4_request\u0026amp;X-Amz-Date=20231126T033542Z\u0026amp;X-Amz-Expires=300\u0026amp;X-Amz-Signature=cf09a0c524756802e669d7ccb2b60b9dcc5f3cfd0855cd9abad7d31947596c2f\u0026amp;X-Amz-SignedHeaders=host\u0026amp;actor_id=0\u0026amp;key_id=0\u0026amp;repo_id=9524057\u0026amp;response-content-disposition=attachment%3B%20filename%3Dnode_exporter-1.2.2.linux-amd64.tar.gz\u0026amp;response-content-type=application%2Foctet-stream [following] --2023-11-25 22:35:45-- https://objects.githubusercontent.com/github-production-release-asset-2e65be/9524057/28598a7c-d8ad-483d-85ba-8b2c9c08cf57?X-Amz-Algorithm=AWS4-HMAC-SHA256\u0026amp;X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231126%2Fus-east-1%2Fs3%2Faws4_request\u0026amp;X-Amz-Date=20231126T033542Z\u0026amp;X-Amz-Expires=300\u0026amp;X-Amz-Signature=cf09a0c524756802e669d7ccb2b60b9dcc5f3cfd0855cd9abad7d31947596c2f\u0026amp;X-Amz-SignedHeaders=host\u0026amp;actor_id=0\u0026amp;key_id=0\u0026amp;repo_id=9524057\u0026amp;response-content-disposition=attachment%3B%20filename%3Dnode_exporter-1.2.2.linux-amd64.tar.gz\u0026amp;response-content-type=application%2Foctet-stream Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ... Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 8898481 (8.5M) [application/octet-stream] Saving to: ‘node_exporter-1.2.2.linux-amd64.tar.gz’ node_exporter-1.2.2.linux-amd64.tar.gz 100%[===============================================================================\u0026gt;] 8.49M 20.2MB/s in 0.4s 2023-11-25 22:35:46 (20.2 MB/s) - ‘node_exporter-1.2.2.linux-amd64.tar.gz’ saved [8898481/8898481] 下载到本地主机后解压刚下载的文件，里边有三个文件，node_exporter就是我们需要的可执行文件：\n1 2 3 4 5 6 root@admin:~# tar -zxf node_exporter-1.2.2.linux-amd64.tar.gz root@admin:~# ls images node_exporter-1.2.2.linux-amd64 node_exporter-1.2.2.linux-amd64.tar.gz root@admin:~# cd node_exporter-1.2.2.linux-amd64 root@admin:~/node_exporter-1.2.2.linux-amd64# ls LICENSE node_exporter NOTICE 运行node exporter 可以进入到node_exporter-1.2.2.linux-amd64\n目录，执行./node_export来执行项目，如下：\n1 2 3 4 5 root@admin:~/node_exporter-1.2.2.linux-amd64# ./node_exporter level=info ts=2023-11-26T06:17:11.718Z caller=node_exporter.go:182 msg=\u0026#34;Starting node_exporter\u0026#34; version=\u0026#34;(version=1.2.2, branch=HEAD, revision=26645363b486e12be40af7ce4fc91e731a33104e)\u0026#34; ....... level=info ts=2023-11-26T06:17:11.720Z caller=node_exporter.go:199 msg=\u0026#34;Listening on\u0026#34; address=:9100 level=info ts=2023-11-26T06:17:11.720Z caller=tls_config.go:191 msg=\u0026#34;TLS is disabled.\u0026#34; http2=false 从上边启动的日志可以看出采集的具体指标，倒数第二行日志可以看出node_exporter占用的是9100端口，如果我们想控制采集的指标或者更改占用端口，可以使用-h命令查看启动参数说明：\n1 2 3 4 5 6 7 8 9 10 root@admin:~/node_exporter-1.2.2.linux-amd64# ./node_exporter -h --web.listen-address=\u0026#34;:9100\u0026#34; # 监听的端口，默认是9100 --web.telemetry-path=\u0026#34;/metrics\u0026#34; # metrics的路径，默认为/metrics --web.disable-exporter-metrics # 是否禁用go、prome默认的metrics --web.max-requests=40 # 最大并行请求数，默认40，设置为0时不限制 --log.level=\u0026#34;info\u0026#34; # 日志等级: [debug, info, warn, error, fatal] --log.format=logfmt # 置日志打印target和格式: [logfmt, json] --version # 版本号 --collector.{metric-name} # 各个metric对应的参数 ...... 具体的采集参数后续在使用的时候再详细研究，这里就先全部让它采集。以上边的方式启动是以前台运行的，我们关闭窗口程序就会自动退出，下边来配置systemd管理node_exporter.\n配置node_exporter.services 首先把把解压后的node_exporter移动到/usr/local/bin目录下，然后新建一个node_exporter.service，需要建到/etc/systemd/system目录下，具体内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 Unit] Description=node exporter service Documentation=https://prometheus.io After=network.target [Service] Type=simple User=root Group=root ExecStart=/usr/local/bin/node_exporter --web.listen-address=\u0026#34;:9100\u0026#34; Restart=on-failure [Install] WantedBy=multi-user.target 如上所示，启动命令指定了启动的时候占用的端口，这个根据自己的实际情况进行更改，创建完毕后需要重启systemd服务，并使用systemd启动服务：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 root@admin:/usr/local/bin# systemctl daemon-reload root@admin:/usr/local/bin# systemctl start node_exporter root@admin:/usr/local/bin# systemctl status node_exporter ● node_exporter.service - node exporter service Loaded: loaded (/etc/systemd/system/node_exporter.service; disabled; vendor preset: enabled) Active: active (running) since Sun 2023-11-26 01:28:25 EST; 6s ago Docs: https://prometheus.io Main PID: 2794065 (node_exporter) Tasks: 4 (limit: 2358) Memory: 4.7M CPU: 15ms CGroup: /system.slice/node_exporter.service └─2794065 /usr/local/bin/node_exporter --web.listen-address=:9100 Nov 26 01:28:25 WIKI-HK-A1 node_exporter[2794065]: level=info ts=2023-11-26T06:28:25.705Z caller=node_exporter.go:115 collector=xfs Nov 26 01:28:25 WIKI-HK-A1 node_exporter[2794065]: level=info ts=2023-11-26T06:28:25.705Z caller=node_exporter.go:115 collector=zfs Nov 26 01:28:25 WIKI-HK-A1 node_exporter[2794065]: level=info ts=2023-11-26T06:28:25.706Z caller=node_exporter.go:199 msg=\u0026#34;Listening on\u0026#34; address=:9100 Nov 26 01:28:25 WIKI-HK-A1 node_exporter[2794065]: level=info ts=2023-11-26T06:28:25.706Z caller=tls_config.go:191 msg=\u0026#34;TLS is disabled.\u0026#34; http2=false 经过上述步骤就在需要被监控的linux主机上安装好了node exporter，接下来需要在prometheus中配置对该主机的指标进行抓取。\nprometheus指标获取 在文章：debian系统使用docker快速安装promutheus中只配置了对promutheus本身指标的采集，下边我们修改prometheus的配置文件，对刚才配置的linux主机进行指标采集，修改prometheus的配置文件如下：\n1 2 3 4 5 6 7 8 9 10 11 12 global: scrape_interval: 1m scrape_configs: - job_name: \u0026#39;prometheus\u0026#39; scrape_interval: 1m static_configs: - targets: [\u0026#39;localhost:9090\u0026#39;] - job_name: \u0026#39;linux-node\u0026#39; static_configs: - targets: [\u0026#39;127.0.0.1:9100\u0026#39;] 如上，配置了一个任务名称为linux-node的任务，它去获取127.0.0.1机器的指标，我们可以在prometheus的后台查看到对应的targets:\n到这里就配置好了prometheus采集linux主机指标的配置，可以在prometheus的后台对信息进行查询，后续也可以配置grafana的图形界面来对node exporter采集的数据进行可视化展示。\n","date":"2023-11-26T06:42:47Z","image":"https://images.iminling.com/app/hide.php?key=M3JOYmRIT1UyZHJjcTZJRXloNjR6aTUyME1KbkhNak8yVDlTVm9saGloSXUwWkNsN0VZSStxRGU1Q1ZTQS9xVzRuY0szTHM9","permalink":"https://konghanghang.github.io/iminling-pages/2023/install-node-exporter/","title":"安装node exporter监控linux主机各项指标"},{"content":"Prometheus是一套开源的监控\u0026amp;报警\u0026amp;时间序列数据库的组合,起始是由SoundCloud公司开发的。它的功能强大，被广泛使用。今天这边文章就简单介绍一下如何使用docker快速的搭建一个prometheus的服务，其他相关的知识在后续的文章里再详细分享。先把服务跑起来。\n如果还没有安装docker的同学可以参考的我另一篇文章来快速的安装docker环境：docker安装。\ndocker-compose文件准备 我习惯直接使用docker-compose来安装所有服务，我的所有服务都使用同一个网络，实现服务的互通，下边贴出我的配置：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 networks: mynet: external: true services: prometheus: image: prom/prometheus:v2.46.0 restart: unless-stopped container_name: prometheus volumes: - ./config/prometheus.yml:/etc/prometheus/prometheus.yml - /data/prometheus/data:/prometheus command: - \u0026#39;--config.file=/etc/prometheus/prometheus.yml\u0026#39; - \u0026#39;--storage.tsdb.path=/prometheus\u0026#39; - \u0026#39;--web.console.libraries=/etc/prometheus/console_libraries\u0026#39; - \u0026#39;--web.console.templates=/etc/prometheus/consoles\u0026#39; - \u0026#39;--web.enable-lifecycle\u0026#39; networks: - mynet ports: - 9090:9090 environment: - TZ=Asia/Shanghai user: \u0026#34;0\u0026#34; 以上是我的docker-compose文件，下边我们介绍一下个项的意义\nnetworks 网络，我指定了一个已经创建好的桥接网络：mynet，这个大家可以指定自己的网络，或者删除这个networks，让docker为该compose创建一个网络。\nservices 服务，就是我们要创建的prometheus服务了，指定了镜像，重启策略，启动命令，网络，端口以及时区等信息。\n目录结构 上边是docker-compose的配置信息，里边指定了prometheus启动的配置文件地址，我们准备一个最简单的配置文件，prometheus自己拉取自己的监控信息：\n1 2 3 4 5 6 7 8 global: scrape_interval: 1m scrape_configs: - job_name: \u0026#39;prometheus\u0026#39; scrape_interval: 1m static_configs: - targets: [\u0026#39;localhost:9090\u0026#39;] 具体的配置信息以后再讲，这里的global设置了整个拉取间隔为1分钟，并添加了一个拉取配置，任务名叫：prometheus，目标是localhost:9090，就是安装的prometheus自己。\n整个的目录结构如下：\n1 2 3 4 5 prometheus ├── README.md ├── config │ └── prometheus.yml └── docker-compose.yaml 启动服务 在根目录使用命令来启动prometheus：\n1 docker compose up -d 启动后可以使用docker ps 来查看服务是否启动成功，如下启动成功：\n1 2 3 root@WIKI-HK-A1:~# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 9b24b2c868ad prom/prometheus:v2.46.0 \u0026#34;/bin/prometheus --c…\u0026#34; 3 hours ago Up 34 minutes 0.0.0.0:9090-\u0026gt;9090/tcp, :::9090-\u0026gt;9090/tcp prometheus 访问服务 prometheus启动占用的是9090端口，我们可以使用自己服务器的ip:9090来访问：\n访问后如上，我们可以在staus-targets中查看我们添加的那个任务：\n以上就是简单的安装prometheus的过程，希望可以帮到大家。\n","date":"2023-11-26T00:00:00Z","image":"https://images.iminling.com/app/hide.php?key=M3JOYmRIT1UyZHJjcTZJRXloNjR6aTUyME1KbkhNak8yVDlTVm9saGloSXUwWkNsN0VZSStxRGU1Q1ZTQS9xVzRuY0szTHM9","permalink":"https://konghanghang.github.io/iminling-pages/2023/debian-use-docker-install-promutheus/","title":"debian系统使用docker快速安装promutheus"},{"content":"使用Mac的同学应该对Mac自带的终端配置都没什么好感，默认白底黑字，文件夹也没有特殊标识，还是上一张图来感受一下吧：\n黑呼呼的一团，看着实在是难受，下边就让我们使用Oh My Zsh来进行美化一下。\nOh My Zsh安装 oh my zsh的安装是非常简单的，大家可以参考官网来进行安装：Oh My Zsh Install,通过curl或wget都可以安装，下边使用curl进行安装：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 k@MacBook-Pro ~ % sh -c \u0026#34;$(curl -fsSL https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh)\u0026#34; Cloning Oh My Zsh... remote: Enumerating objects: 1370, done. remote: Counting objects: 100% (1370/1370), done. remote: Compressing objects: 100% (1318/1318), done. remote: Total 1370 (delta 32), reused 1155 (delta 28), pack-reused 0 Receiving objects: 100% (1370/1370), 2.01 MiB | 2.66 MiB/s, done. Resolving deltas: 100% (32/32), done. From https://github.com/ohmyzsh/ohmyzsh * [new branch] master -\u0026gt; origin/master branch \u0026#39;master\u0026#39; set up to track \u0026#39;origin/master\u0026#39;. Switched to a new branch \u0026#39;master\u0026#39; /Users/k Looking for an existing zsh config... Using the Oh My Zsh template file and adding it to /Users/k/.zshrc. __ __ ____ / /_ ____ ___ __ __ ____ _____/ /_ / __ \\/ __ \\ / __ `__ \\/ / / / /_ / / ___/ __ \\ / /_/ / / / / / / / / / / /_/ / / /_(__ ) / / / \\____/_/ /_/ /_/ /_/ /_/\\__, / /___/____/_/ /_/ /____/ ....is now installed! Before you scream Oh My Zsh! look over the `.zshrc` file to select plugins, themes, and options. • Follow us on Twitter: https://twitter.com/ohmyzsh • Join our Discord community: https://discord.gg/ohmyzsh • Get stickers, t-shirts, coffee mugs and more: https://shop.planetargon.com/collections/oh-my-zsh 上边就安装成功了oh my zsh。\n切换主题 安装成功后，默认的主题(robbyrussell)如下所示：\n文件夹也可以高亮了，看着还是不错的。剩下的就是修改自己喜欢的主题了。oh my zsh自带了一些主题，存放在~/.oh-my-sh/themes下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 # k @ MacBook-Pro in ~/.oh-my-zsh/themes on git:master o [17:47:16] $ ls 3den.zsh-theme kennethreitz.zsh-theme Soliah.zsh-theme kiwi.zsh-theme adben.zsh-theme kolo.zsh-theme af-magic.zsh-theme kphoen.zsh-theme afowler.zsh-theme lambda.zsh-theme agnoster.zsh-theme linuxonly.zsh-theme alanpeabody.zsh-theme lukerandall.zsh-theme amuse.zsh-theme macovsky-ruby.zsh-theme apple.zsh-theme macovsky.zsh-theme arrow.zsh-theme maran.zsh-theme aussiegeek.zsh-theme mgutz.zsh-theme avit.zsh-theme mh.zsh-theme awesomepanda.zsh-theme michelebologna.zsh-theme bira.zsh-theme mikeh.zsh-theme blinks.zsh-theme miloshadzic.zsh-theme bureau.zsh-theme minimal.zsh-theme candy-kingdom.zsh-theme mira.zsh-theme candy.zsh-theme mlh.zsh-theme clean.zsh-theme mortalscumbag.zsh-theme cloud.zsh-theme mrtazz.zsh-theme crcandy.zsh-theme murilasso.zsh-theme crunch.zsh-theme muse.zsh-theme cypher.zsh-theme nanotech.zsh-theme dallas.zsh-theme nebirhos.zsh-theme darkblood.zsh-theme nicoulaj.zsh-theme daveverwer.zsh-theme norm.zsh-theme dieter.zsh-theme obraun.zsh-theme dogenpunk.zsh-theme oldgallois.zsh-theme dpoggi.zsh-theme peepcode.zsh-theme dst.zsh-theme philips.zsh-theme dstufft.zsh-theme pmcgee.zsh-theme duellj.zsh-theme pygmalion-virtualenv.zsh-theme eastwood.zsh-theme pygmalion.zsh-theme edvardm.zsh-theme random.zsh-theme emotty.zsh-theme re5et.zsh-theme essembeh.zsh-theme refined.zsh-theme evan.zsh-theme rgm.zsh-theme fino-time.zsh-theme risto.zsh-theme fino.zsh-theme rixius.zsh-theme fishy.zsh-theme rkj-repos.zsh-theme flazz.zsh-theme rkj.zsh-theme fletcherm.zsh-theme robbyrussell.zsh-theme fox.zsh-theme sammy.zsh-theme frisk.zsh-theme simonoff.zsh-theme frontcube.zsh-theme simple.zsh-theme funky.zsh-theme skaro.zsh-theme fwalch.zsh-theme smt.zsh-theme gallifrey.zsh-theme sonicradish.zsh-theme gallois.zsh-theme sorin.zsh-theme garyblessington.zsh-theme sporty_256.zsh-theme gentoo.zsh-theme steeef.zsh-theme geoffgarside.zsh-theme strug.zsh-theme gianu.zsh-theme sunaku.zsh-theme gnzh.zsh-theme sunrise.zsh-theme gozilla.zsh-theme superjarin.zsh-theme half-life.zsh-theme suvash.zsh-theme humza.zsh-theme takashiyoshida.zsh-theme imajes.zsh-theme terminalparty.zsh-theme intheloop.zsh-theme theunraveler.zsh-theme itchy.zsh-theme tjkirch.zsh-theme jaischeema.zsh-theme tjkirch_mod.zsh-theme jbergantine.zsh-theme tonotdo.zsh-theme jispwoso.zsh-theme trapd00r.zsh-theme jnrowe.zsh-theme wedisagree.zsh-theme jonathan.zsh-theme wezm+.zsh-theme josh.zsh-theme wezm.zsh-theme jreese.zsh-theme wuffers.zsh-theme jtriley.zsh-theme xiong-chiamiov-plus.zsh-theme juanghurtado.zsh-theme xiong-chiamiov.zsh-theme junkfood.zsh-theme ys.zsh-theme kafeitu.zsh-theme zhann.zsh-theme kardan.zsh-theme 比如默认的主题：robbyrussell.zsh-theme，根据自己的需求，在.zshrc文件中进行修改，\n1 2 3 4 5 6 # Set name of the theme to load --- if set to \u0026#34;random\u0026#34;, it will # load a random theme each time oh-my-zsh is loaded, in which case, # to know which specific one was loaded, run: echo $RANDOM_THEME # See https://github.com/ohmyzsh/ohmyzsh/wiki/Themes #ZSH_THEME=\u0026#34;robbyrussell\u0026#34; ZSH_THEME=\u0026#34;ys\u0026#34; 终端配色 我这里将主题修改为了ys。下边展示一下我修改后的终端配色：\n加了一些透明在里边，下边把我自己使用的终端配色分享给大家，大家如果喜欢可以直接下载后进行导入：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE plist PUBLIC \u0026#34;-//Apple//DTD PLIST 1.0//EN\u0026#34; \u0026#34;http://www.apple.com/DTDs/PropertyList-1.0.dtd\u0026#34;\u0026gt; \u0026lt;plist version=\u0026#34;1.0\u0026#34;\u0026gt; \u0026lt;dict\u0026gt; \u0026lt;key\u0026gt;BackgroundAlphaInactive\u0026lt;/key\u0026gt; \u0026lt;real\u0026gt;0.29155388779527558\u0026lt;/real\u0026gt; \u0026lt;key\u0026gt;BackgroundBlur\u0026lt;/key\u0026gt; \u0026lt;real\u0026gt;0.197831572862122\u0026lt;/real\u0026gt; \u0026lt;key\u0026gt;BackgroundBlurInactive\u0026lt;/key\u0026gt; \u0026lt;real\u0026gt;0.15034141538180704\u0026lt;/real\u0026gt; \u0026lt;key\u0026gt;BackgroundColor\u0026lt;/key\u0026gt; \u0026lt;data\u0026gt; YnBsaXN0MDDUAQIDBAUGKyxYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3AS AAGGoKcHCBMZHSQoVSRudWxs1QkKCwwNDg8QERJcTlNDb21wb25lbnRzVU5TUkdCXE5T Q29sb3JTcGFjZV8QEk5TQ3VzdG9tQ29sb3JTcGFjZVYkY2xhc3NPECowLjQwMjQ2MTQ0 OTcgMC40MDExMDYzNjA2IDAuNDAzODE2NTM4OCAwLjVPECowLjMyODQwNDM2NyAwLjMy Njc0MDM4NDEgMC4zMjk2NjQyMzAzIDAuNQAQAYACgAbTFA0VFhcYVU5TSUNDWU5TU3Bh Y2VJRIADgAUQDNIaDRscV05TLmRhdGFPEQIkAAACJGFwcGwEAAAAbW50clJHQiBYWVog B+EABwAHAA0AFgAgYWNzcEFQUEwAAAAAQVBQTAAAAAAAAAAAAAAAAAAAAAAAAPbWAAEA AAAA0y1hcHBsyhqVgiV/EE04mRPV0eoVggAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA AAAAAAAKZGVzYwAAAPwAAABlY3BydAAAAWQAAAAjd3RwdAAAAYgAAAAUclhZWgAAAZwA AAAUZ1hZWgAAAbAAAAAUYlhZWgAAAcQAAAAUclRSQwAAAdgAAAAgY2hhZAAAAfgAAAAs YlRSQwAAAdgAAAAgZ1RSQwAAAdgAAAAgZGVzYwAAAAAAAAALRGlzcGxheSBQMwAAAAAA AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAB0ZXh0AAAAAENvcHlyaWdodCBBcHBsZSBJ bmMuLCAyMDE3AABYWVogAAAAAAAA81EAAQAAAAEWzFhZWiAAAAAAAACD3wAAPb////+7 WFlaIAAAAAAAAEq/AACxNwAACrlYWVogAAAAAAAAKDgAABELAADIuXBhcmEAAAAAAAMA AAACZmYAAPKnAAANWQAAE9AAAApbc2YzMgAAAAAAAQxCAAAF3v//8yYAAAeTAAD9kP// +6L///2jAAAD3AAAwG6ABNIeHyAhWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxl RGF0YaMgIiNWTlNEYXRhWE5TT2JqZWN00h4fJSZcTlNDb2xvclNwYWNloicjXE5TQ29s b3JTcGFjZdIeHykqV05TQ29sb3KiKSNfEA9OU0tleWVkQXJjaGl2ZXLRLS5Ucm9vdIAB AAgAEQAaACMALQAyADcAPwBFAFAAXQBjAHAAhQCMALkA5gDoAOoA7ADzAPkBAwEFAQcB CQEOARYDPgNAA0UDUANZA2cDawNyA3sDgAONA5ADnQOiA6oDrQO/A8IDxwAAAAAAAAIB AAAAAAAAAC8AAAAAAAAAAAAAAAAAAAPJ \u0026lt;/data\u0026gt; \u0026lt;key\u0026gt;BackgroundSettingsForInactiveWindows\u0026lt;/key\u0026gt; \u0026lt;true/\u0026gt; \u0026lt;key\u0026gt;CursorColor\u0026lt;/key\u0026gt; \u0026lt;data\u0026gt; YnBsaXN0MDDUAQIDBAUGKyxYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3AS AAGGoKcHCBMZHSQoVSRudWxs1QkKCwwNDg8QERJcTlNDb21wb25lbnRzVU5TUkdCXE5T Q29sb3JTcGFjZV8QEk5TQ3VzdG9tQ29sb3JTcGFjZVYkY2xhc3NPECswLjA5MDY1NzM4 MzIxIDAuMDkwMzY5NTgxOTkgMC4wOTA5NDUxODQ0MyAxTxAqMC4wNzEzODQ3ODc1NiAw LjA3MTE0Nzg2NjU1IDAuMDcxNTY2Mzg4MDEAEAGAAoAG0xQNFRYXGFVOU0lDQ1lOU1Nw YWNlSUSAA4AFEAzSGg0bHFdOUy5kYXRhTxECJAAAAiRhcHBsBAAAAG1udHJSR0IgWFla IAfhAAcABwANABYAIGFjc3BBUFBMAAAAAEFQUEwAAAAAAAAAAAAAAAAAAAAAAAD21gAB AAAAANMtYXBwbMoalYIlfxBNOJkT1dHqFYIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA AAAAAAAACmRlc2MAAAD8AAAAZWNwcnQAAAFkAAAAI3d0cHQAAAGIAAAAFHJYWVoAAAGc AAAAFGdYWVoAAAGwAAAAFGJYWVoAAAHEAAAAFHJUUkMAAAHYAAAAIGNoYWQAAAH4AAAA LGJUUkMAAAHYAAAAIGdUUkMAAAHYAAAAIGRlc2MAAAAAAAAAC0Rpc3BsYXkgUDMAAAAA AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAdGV4dAAAAABDb3B5cmlnaHQgQXBwbGUg SW5jLiwgMjAxNwAAWFlaIAAAAAAAAPNRAAEAAAABFsxYWVogAAAAAAAAg98AAD2///// u1hZWiAAAAAAAABKvwAAsTcAAAq5WFlaIAAAAAAAACg4AAARCwAAyLlwYXJhAAAAAAAD AAAAAmZmAADypwAADVkAABPQAAAKW3NmMzIAAAAAAAEMQgAABd7///MmAAAHkwAA/ZD/ //ui///9owAAA9wAAMBugATSHh8gIVokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJs ZURhdGGjICIjVk5TRGF0YVhOU09iamVjdNIeHyUmXE5TQ29sb3JTcGFjZaInI1xOU0Nv bG9yU3BhY2XSHh8pKldOU0NvbG9yoikjXxAPTlNLZXllZEFyY2hpdmVy0S0uVHJvb3SA AQAIABEAGgAjAC0AMgA3AD8ARQBQAF0AYwBwAIUAjAC6AOcA6QDrAO0A9AD6AQQBBgEI AQoBDwEXAz8DQQNGA1EDWgNoA2wDcwN8A4EDjgORA54DowOrA64DwAPDA8gAAAAAAAAC AQAAAAAAAAAvAAAAAAAAAAAAAAAAAAADyg== \u0026lt;/data\u0026gt; \u0026lt;key\u0026gt;Font\u0026lt;/key\u0026gt; \u0026lt;data\u0026gt; YnBsaXN0MDDUAQIDBAUGGBlYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3AS AAGGoKQHCBESVSRudWxs1AkKCwwNDg8QVk5TU2l6ZVhOU2ZGbGFnc1ZOU05hbWVWJGNs YXNzI0AqAAAAAAAAEBCAAoADXxAcTWVzbG9MR01Gb3JQb3dlcmxpbmUtUmVndWxhctIT FBUWWiRjbGFzc25hbWVYJGNsYXNzZXNWTlNGb250ohUXWE5TT2JqZWN0XxAPTlNLZXll ZEFyY2hpdmVy0RobVHJvb3SAAQgRGiMtMjc8QktSW2JpcnR2eJecp7C3usPV2N0AAAAA AAABAQAAAAAAAAAcAAAAAAAAAAAAAAAAAAAA3w== \u0026lt;/data\u0026gt; \u0026lt;key\u0026gt;FontAntialias\u0026lt;/key\u0026gt; \u0026lt;true/\u0026gt; \u0026lt;key\u0026gt;FontWidthSpacing\u0026lt;/key\u0026gt; \u0026lt;integer\u0026gt;1\u0026lt;/integer\u0026gt; \u0026lt;key\u0026gt;ProfileCurrentVersion\u0026lt;/key\u0026gt; \u0026lt;real\u0026gt;2.0499999999999998\u0026lt;/real\u0026gt; \u0026lt;key\u0026gt;SelectionColor\u0026lt;/key\u0026gt; \u0026lt;data\u0026gt; YnBsaXN0MDDUAQIDBAUGKyxYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3AS AAGGoKcHCBMZHSQoVSRudWxs1QkKCwwNDg8QERJcTlNDb21wb25lbnRzVU5TUkdCXE5T Q29sb3JTcGFjZV8QEk5TQ3VzdG9tQ29sb3JTcGFjZVYkY2xhc3NPECcwLjYyOTkyNTMz OSAwLjY2NTY2MzQyMjEgMC42MzA0MjI5NTI5IDFPECcwLjU1NDMwNjk4MzkgMC42MDU2 NzE1ODQ2IDAuNTU5NTI2NjIyMwAQAYACgAbTFA0VFhcYVU5TSUNDWU5TU3BhY2VJRIAD gAUQDNIaDRscV05TLmRhdGFPEQIkAAACJGFwcGwEAAAAbW50clJHQiBYWVogB+EABwAH AA0AFgAgYWNzcEFQUEwAAAAAQVBQTAAAAAAAAAAAAAAAAAAAAAAAAPbWAAEAAAAA0y1h cHBsyhqVgiV/EE04mRPV0eoVggAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAK ZGVzYwAAAPwAAABlY3BydAAAAWQAAAAjd3RwdAAAAYgAAAAUclhZWgAAAZwAAAAUZ1hZ WgAAAbAAAAAUYlhZWgAAAcQAAAAUclRSQwAAAdgAAAAgY2hhZAAAAfgAAAAsYlRSQwAA AdgAAAAgZ1RSQwAAAdgAAAAgZGVzYwAAAAAAAAALRGlzcGxheSBQMwAAAAAAAAAAAAAA AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA AAAAAAAAAAAAAAAAAAAAAAAAAAB0ZXh0AAAAAENvcHlyaWdodCBBcHBsZSBJbmMuLCAy MDE3AABYWVogAAAAAAAA81EAAQAAAAEWzFhZWiAAAAAAAACD3wAAPb////+7WFlaIAAA AAAAAEq/AACxNwAACrlYWVogAAAAAAAAKDgAABELAADIuXBhcmEAAAAAAAMAAAACZmYA APKnAAANWQAAE9AAAApbc2YzMgAAAAAAAQxCAAAF3v//8yYAAAeTAAD9kP//+6L///2j AAAD3AAAwG6ABNIeHyAhWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMg IiNWTlNEYXRhWE5TT2JqZWN00h4fJSZcTlNDb2xvclNwYWNloicjXE5TQ29sb3JTcGFj ZdIeHykqV05TQ29sb3KiKSNfEA9OU0tleWVkQXJjaGl2ZXLRLS5Ucm9vdIABAAgAEQAa ACMALQAyADcAPwBFAFAAXQBjAHAAhQCMALYA4ADiAOQA5gDtAPMA/QD/AQEBAwEIARAD OAM6Az8DSgNTA2EDZQNsA3UDegOHA4oDlwOcA6QDpwO5A7wDwQAAAAAAAAIBAAAAAAAA AC8AAAAAAAAAAAAAAAAAAAPD \u0026lt;/data\u0026gt; \u0026lt;key\u0026gt;TextColor\u0026lt;/key\u0026gt; \u0026lt;data\u0026gt; YnBsaXN0MDDUAQIDBAUGKyxYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3AS AAGGoKcHCBMZHSQoVSRudWxs1QkKCwwNDg8QERJcTlNDb21wb25lbnRzVU5TUkdCXE5T Q29sb3JTcGFjZV8QEk5TQ3VzdG9tQ29sb3JTcGFjZVYkY2xhc3NHMSAxIDEgMU8QHDAu OTk5ODg2MDk1NSAxIDAuOTk5ODM5ODQyMwAQAYACgAbTFA0VFhcYVU5TSUNDWU5TU3Bh Y2VJRIADgAUQDNIaDRscV05TLmRhdGFPEQIkAAACJGFwcGwEAAAAbW50clJHQiBYWVog B+EABwAHAA0AFgAgYWNzcEFQUEwAAAAAQVBQTAAAAAAAAAAAAAAAAAAAAAAAAPbWAAEA AAAA0y1hcHBsyhqVgiV/EE04mRPV0eoVggAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA AAAAAAAKZGVzYwAAAPwAAABlY3BydAAAAWQAAAAjd3RwdAAAAYgAAAAUclhZWgAAAZwA AAAUZ1hZWgAAAbAAAAAUYlhZWgAAAcQAAAAUclRSQwAAAdgAAAAgY2hhZAAAAfgAAAAs YlRSQwAAAdgAAAAgZ1RSQwAAAdgAAAAgZGVzYwAAAAAAAAALRGlzcGxheSBQMwAAAAAA AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAB0ZXh0AAAAAENvcHlyaWdodCBBcHBsZSBJ bmMuLCAyMDE3AABYWVogAAAAAAAA81EAAQAAAAEWzFhZWiAAAAAAAACD3wAAPb////+7 WFlaIAAAAAAAAEq/AACxNwAACrlYWVogAAAAAAAAKDgAABELAADIuXBhcmEAAAAAAAMA AAACZmYAAPKnAAANWQAAE9AAAApbc2YzMgAAAAAAAQxCAAAF3v//8yYAAAeTAAD9kP// +6L///2jAAAD3AAAwG6ABNIeHyAhWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxl RGF0YaMgIiNWTlNEYXRhWE5TT2JqZWN00h4fJSZcTlNDb2xvclNwYWNloicjXE5TQ29s b3JTcGFjZdIeHykqV05TQ29sb3KiKSNfEA9OU0tleWVkQXJjaGl2ZXLRLS5Ucm9vdIAB AAgAEQAaACMALQAyADcAPwBFAFAAXQBjAHAAhQCMAJQAswC1ALcAuQDAAMYA0ADSANQA 1gDbAOMDCwMNAxIDHQMmAzQDOAM/A0gDTQNaA10DagNvA3cDegOMA48DlAAAAAAAAAIB AAAAAAAAAC8AAAAAAAAAAAAAAAAAAAOW \u0026lt;/data\u0026gt; \u0026lt;key\u0026gt;UseBoldFonts\u0026lt;/key\u0026gt; \u0026lt;false/\u0026gt; \u0026lt;key\u0026gt;columnCount\u0026lt;/key\u0026gt; \u0026lt;integer\u0026gt;90\u0026lt;/integer\u0026gt; \u0026lt;key\u0026gt;name\u0026lt;/key\u0026gt; \u0026lt;string\u0026gt;me\u0026lt;/string\u0026gt; \u0026lt;key\u0026gt;rowCount\u0026lt;/key\u0026gt; \u0026lt;integer\u0026gt;25\u0026lt;/integer\u0026gt; \u0026lt;key\u0026gt;type\u0026lt;/key\u0026gt; \u0026lt;string\u0026gt;Window Settings\u0026lt;/string\u0026gt; \u0026lt;/dict\u0026gt; \u0026lt;/plist\u0026gt; 新建一个文件，名字随意，文件格式为.terminal,例如ohmyzsh.terminal。然后在终端中进行导入并设置为默认：\n选择import后，在上边的选项中就会有你刚才文件名称对应的一个配置文件，比如我这里叫me-old,然后设置为default就可以了，就和我图片中的终端配色一样了。\n","date":"2023-10-27T10:07:07Z","image":"https://images.iminling.com/app/hide.php?key=U1V5NUZ5WlYrTGt1dElzaVc2VkgrOENSZkRib09zbVk0RjVKTFhkeXNyQkJvdmdOeVhYZWM1aHR1NjdDTWNQU2h3Y1ZHVTQ9","permalink":"https://konghanghang.github.io/iminling-pages/2023/mac-install-oh-my-zsh/","title":"Mac终端美化之Oh My Zsh安装配置"},{"content":"首先mac机器需要先安装Homebrew,具体的安装教程参考我的另一篇文章：Mac更换源更快速的安装Homebrew，有了Homebrew后一切安装都变的很简单了。\n安装 首先是来搜索一下gradle:\n1 2 3 4 5 6 7 k@MacBook-Pro ~ % brew search gradle ==\u0026gt; Formulae gradle gradle-profiler gradle@7 grails gradle-completion gradle@6 grace glade ==\u0026gt; Casks grads qlgradle 如上有几个版本的gradle:6,7以及没有加版本号的代表最新的。我这里安装gradle@7的版本：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 k@MacBook-Pro ~ % brew install gradle@7 ==\u0026gt; Downloading https://ghcr.io/v2/homebrew/core/gradle/7/manifests/7.6.3 ######################################################################### 100.0% ==\u0026gt; Fetching gradle@7 ==\u0026gt; Downloading https://ghcr.io/v2/homebrew/core/gradle/7/blobs/sha256:cc0def9cb ######################################################################### 100.0% ==\u0026gt; Pouring gradle@7--7.6.3.all.bottle.tar.gz ==\u0026gt; Caveats gradle@7 is keg-only, which means it was not symlinked into /usr/local, because this is an alternate version of another formula. If you need to have gradle@7 first in your PATH, run: echo \u0026#39;export PATH=\u0026#34;/usr/local/opt/gradle@7/bin:$PATH\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.zshrc ==\u0026gt; Summary 🍺 /usr/local/Cellar/gradle@7/7.6.3: 11,535 files, 272.3MB ==\u0026gt; Running `brew cleanup gradle@7`... Disable this behaviour by setting HOMEBREW_NO_INSTALL_CLEANUP. Hide these hints with HOMEBREW_NO_ENV_HINTS (see `man brew`). 经过上边就已经安装好了gradle,可以看到默认安装的是7.6.3版本的gradle,安装目录是/usr/local/Cellar/gradle@7/7.6.3,接下来我们就需要配置一下maven的环境变量。\n添加环境变量 上边安装完输出的信息中有提示可以直接把上边提示的命令在终端执行就可以添加环境变量到.zshrc文件中：\n1 echo \u0026#39;export PATH=\u0026#34;/usr/local/opt/gradle@7/bin:$PATH\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.zshrc 或者直接编辑.zshrc文件，在文件末尾添加：\n1 export PATH=\u0026#34;/usr/local/opt/gradle@7/bin:$PATH\u0026#34; 然后就是刷新变量信息：\n1 source .zshrc 然后就可以通过命令来查看gradle的版本信息：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 k@MacBook-Pro ~ % gradle -v Welcome to Gradle 7.6.3! Here are the highlights of this release: - Added support for Java 19. - Introduced `--rerun` flag for individual task rerun. - Improved dependency block for test suites to be strongly typed. - Added a pluggable system for Java toolchains provisioning. For more details see https://docs.gradle.org/7.6.3/release-notes.html ------------------------------------------------------------ Gradle 7.6.3 ------------------------------------------------------------ Build time: 2023-10-04 15:59:47 UTC Revision: 1694251d59e0d4752d547e1fd5b5020b798a7e71 Kotlin: 1.7.10 Groovy: 3.0.13 Ant: Apache Ant(TM) version 1.10.11 compiled on July 10 2021 JVM: 17.0.9 (Homebrew 17.0.9+0) OS: Mac OS X 14.1 x86_64 以上，Gradle就安装成功。也可以参考官网的安装步骤进行手工下载安装：Installing manually。\n","date":"2023-10-27T05:24:40Z","image":"https://images.iminling.com/app/hide.php?key=b1RZQ08wVXRyaHZ6RWNrVmZJTU53b3VobUVYZG5PM1lPRjVqTTV3QSt5N0IxTzJidFh6VFlCRVhMSGY2cUZGcnR2VG1ob1k9","permalink":"https://konghanghang.github.io/iminling-pages/2023/mac-use-homebrew-install-gradle/","title":"Mac使用Homebrew安装Gradle环境"},{"content":"首先mac机器需要先安装Homebrew,具体的安装教程参考我的另一篇文章：Mac更换源更快速的安装Homebrew，有了Homebrew后一切安装都变的很简单了。\n安装 首先是来搜索一下maven:\n1 2 3 4 5 6 k@MacBook-Pro ~ % brew search maven ==\u0026gt; Formulae maven maven-completion maven-shell ==\u0026gt; Casks marvel marvin mauve mavensmate 如上，第一个就是我们需要安装的maven,通过安装命令进行安装：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 k@MacBook-Pro ~ % brew install maven ==\u0026gt; Downloading https://formulae.brew.sh/api/formula.jws.json ##O#- # ==\u0026gt; Downloading https://formulae.brew.sh/api/cask.jws.json ##O#- # ==\u0026gt; Downloading https://ghcr.io/v2/homebrew/core/maven/manifests/3.9.5 ######################################################################### 100.0% ==\u0026gt; Fetching dependencies for maven: openjdk ==\u0026gt; Downloading https://ghcr.io/v2/homebrew/core/openjdk/manifests/21.0.1 ######################################################################### 100.0% ==\u0026gt; Fetching openjdk ==\u0026gt; Downloading https://ghcr.io/v2/homebrew/core/openjdk/blobs/sha256:ab5d32ae29 ######################################################################### 100.0% ==\u0026gt; Fetching maven ==\u0026gt; Downloading https://ghcr.io/v2/homebrew/core/maven/blobs/sha256:3c0cb2c2df11 ######################################################################### 100.0% ==\u0026gt; Installing dependencies for maven: openjdk ==\u0026gt; Installing maven dependency: openjdk ==\u0026gt; Downloading https://ghcr.io/v2/homebrew/core/openjdk/manifests/21.0.1 Already downloaded: /Users/k/Library/Caches/Homebrew/downloads/bb8a78296beb0d39c64166622e2df1a553bdf78572bac0ce95765a7007a46b8a--openjdk-21.0.1.bottle_manifest.json ==\u0026gt; Pouring openjdk--21.0.1.sonoma.bottle.tar.gz 🍺 /usr/local/Cellar/openjdk/21.0.1: 600 files, 331.4MB ==\u0026gt; Installing maven ==\u0026gt; Pouring maven--3.9.5.sonoma.bottle.tar.gz 🍺 /usr/local/Cellar/maven/3.9.5: 92 files, 10.4MB ==\u0026gt; Running `brew cleanup maven`... Disable this behaviour by setting HOMEBREW_NO_INSTALL_CLEANUP. Hide these hints with HOMEBREW_NO_ENV_HINTS (see `man brew`). 经过上边就已经安装好了maven,可以看到默认安装的是3.9.5版本的maven,安装目录是/usr/local/Cellar/maven/3.9.5,接下来我们就需要配置一下maven的环境变量。\n添加环境变量 编辑~/.zshrc文件,在文件末尾添加环境变量信息：\n1 2 # maven export PATH=/usr/local/Cellar/maven/3.9.5/bin:$PATH 添加完环境变量信息后，我们还需要让环境变量生效，可以使用source：\n1 source .zshrc 然后就可以通过命令来查看maven的版本信息：\n1 2 3 4 5 6 k@MacBook-Pro ~ % mvn -v Apache Maven 3.9.5 (57804ffe001d7215b5e7bcb531cf83df38f93546) Maven home: /usr/local/Cellar/maven/3.9.5/libexec Java version: 17.0.9, vendor: Homebrew, runtime: /usr/local/Cellar/openjdk@17/17.0.9/libexec/openjdk.jdk/Contents/Home Default locale: en_CN, platform encoding: UTF-8 OS name: \u0026#34;mac os x\u0026#34;, version: \u0026#34;14.1\u0026#34;, arch: \u0026#34;x86_64\u0026#34;, family: \u0026#34;mac\u0026#34; 至此maven就安装完成了，我这里使用的是brew来进行安装，除了这个方法，还可以直接去maven官网进行下载maven的压缩包，然后进行解压，再进行环境变量的配置就可以了。maven官网的下载地址：Maven - Download，这里默认下载的是最新版本，如果想下载历史的版本可以去到历史库下载，具体地址：Maven Releases History。\n","date":"2023-10-27T04:01:20Z","image":"https://images.iminling.com/app/hide.php?key=VllGYlZxRmg1enZJWWNjVDJWQzRteEN4Mi9JdlJ3d0tGbjlldkZRem9CdkxqSU5FdGxVdUsyVVMxWlh2VG5DdlA5YUY4emc9","permalink":"https://konghanghang.github.io/iminling-pages/2023/mac-use-homebrew-install-maven/","title":"Mac使用Homebrew安装maven环境"},{"content":"日志在日常开发中是非常重要的东西，在出现错误后可以快速的进行排查，对Nginx而言同样也很重要，同Nginx的日志我们可以清晰的了解什么url被访问，是什么Ip访问过来等一些重要信息，所以无论是在开发中还是线上环境，都会开启日志。下边就来了解一下Nginx的日志。\n日志类型 在Nginx的配置文件中，日志相关的配置可以出现在_http,server,location_中，通常我们会设置以下格式：\n1 2 3 4 5 6 7 8 9 10 11 12 13 server { listen 443 ssl http2; server_name _; index index.php index.html index.htm; root /var/www/html; server_tokens off; client_max_body_size 75M; access_log /var/log/access.log; error_log /var/log/error.log; } 设置了access和error两种类型的日志，日志的设置语法是：\n1 2 access_log path [format [buffer=size] [gzip[=level]] [flush=time] [if=condition]]; access_log off; 可以设置开启日志，也可以设置关闭日志。access_log中记录了所有的访问日志，error_log中则记录访问中的一些异常请求，方便在出现问题的时候进行错误排查。\n另外也可以定义缓存区以及刷新时间等属性。\n如果使用 gzip 参数，则缓冲数据将在写入文件之前被压缩。压缩级别可以设置在 1（最快，压缩程度较低）和 9（最慢，压缩效果最佳）之间。默认情况下，缓冲区大小等于64K字节，压缩级别设置为1。由于数据被压缩在原子块中，因此日志文件可以随时由“zcat”解压或读取。使用gzip有一个要求，那就是在构建Nginx必须使用 zlib 库构建。\n以上只是设置了访问日志和错误日志的记录位置或者不记录日志，那么日志记录的格式是怎样的呢？\n日志格式 上边的配置没有指定具体的日志格式，那么Nginx有一个默认的日志记录格式：\n1 2 3 log_format combined \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#39; \u0026#39;\u0026#34;$request\u0026#34; $status $body_bytes_sent \u0026#39; \u0026#39;\u0026#34;$http_referer\u0026#34; \u0026#34;$http_user_agent\u0026#34;\u0026#39;; 它的名称叫combined,具体log_format的语法如下：\n1 log_format name [escape=default|json|none] string ...; 每一个日志格式都有一个名称，然后在配置access_log的时候可以指定用哪种格式来进行记录日志。log_format只能定义在_http_块中。查看在Nginx配置文件中的定义：\n1 2 3 4 5 6 7 8 9 10 11 http { log_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; } server { access_log /var/log/nginx/access.log main; error_log /var/log/nginx/error.log; } 如上在http块中定义了一个名称为main的日志格式，在server块中通过名称对该日志格式进行了引用，这样子日志的格式都会按找main中定义的一些属性来进行记录访问信息。\nescape 参数（1.11.8）允许在变量中设置 json 或默认字符转义，默认情况下使用默认转义。 none 值 (1.13.10) 禁用转义。\n对于默认转义，字符“\u0026quot;”、“\\”以及其他值小于32（0.7.0）或大于126（1.1.6）的字符将被转义为“\\xXX”。如果找不到变量值，将记录连字符（“-”）。\n对于json转义，JSON字符串中不允许的所有字符都将被转义：字符“\u0026quot;”和“\\”被转义为“\\”和“\\”，值小于32的字符被转义为“\\n”， “\\r”、“\\t”、“\\b”、“\\f”或“\\u00XX”。\n但是这些属性究竟什么意思？Nginx有哪些属性可以使用呢？\n日志属性 日志属性可以包含公共变量以及仅在日志写入时存在的变量：\n$bytes_sent：发送到客户端的字节数 $connection：连接序列号 $connection_requests：当前通过连接发出的请求数 (1.1.18) $msec：日志写入时的时间（以秒为单位，精度为毫秒） $pipe：如果请求是通过管道传输的，则为“p”，“.”否则 $request_length：请求长度（包括请求行、请求头和请求正文） $request_time：请求处理时间以秒为单位，精度为毫秒；从客户端读取第一个字节与将最后一个字节发送到客户端后写入日志之间经过的时间 $status：响应状态 $time_iso8601：ISO 8601 标准格式的当地时间 $time_local：通用日志格式中的本地时间 具体的参考：Module ngx_http_log_module\n设置JSON格式 通过上边对日志格式和日志文件的一些了解，我们就可以非常容易的把日志的格式设置成JSON了，只需要定义一个log_format，把它的格式定义成一个json字符串，然后在打印日志的时候引用这个格式就可以实现了，下边是一个完成的定义文件:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 http { log_format json escape=json \u0026#39;{\u0026#39; \u0026#39;\u0026#34;msec\u0026#34;: \u0026#34;$msec\u0026#34;, \u0026#39; # request unixtime in seconds with a milliseconds resolution \u0026#39;\u0026#34;connection\u0026#34;: \u0026#34;$connection\u0026#34;, \u0026#39; # connection serial number \u0026#39;\u0026#34;connection_requests\u0026#34;: \u0026#34;$connection_requests\u0026#34;, \u0026#39; # number of requests made in connection \u0026#39;\u0026#34;pid\u0026#34;: \u0026#34;$pid\u0026#34;, \u0026#39; # process pid \u0026#39;\u0026#34;request_id\u0026#34;: \u0026#34;$request_id\u0026#34;, \u0026#39; # the unique request id \u0026#39;\u0026#34;request_length\u0026#34;: \u0026#34;$request_length\u0026#34;, \u0026#39; # request length (including headers and body) \u0026#39;\u0026#34;remote_addr\u0026#34;: \u0026#34;$remote_addr\u0026#34;, \u0026#39; # client IP \u0026#39;\u0026#34;remote_user\u0026#34;: \u0026#34;$remote_user\u0026#34;, \u0026#39; # client HTTP username \u0026#39;\u0026#34;remote_port\u0026#34;: \u0026#34;$remote_port\u0026#34;, \u0026#39; # client port \u0026#39;\u0026#34;time_local\u0026#34;: \u0026#34;$time_local\u0026#34;, \u0026#39; \u0026#39;\u0026#34;time_iso8601\u0026#34;: \u0026#34;$time_iso8601\u0026#34;, \u0026#39; # local time in the ISO 8601 standard format \u0026#39;\u0026#34;request\u0026#34;: \u0026#34;$request\u0026#34;, \u0026#39; # full path no arguments if the request \u0026#39;\u0026#34;request_uri\u0026#34;: \u0026#34;$request_uri\u0026#34;, \u0026#39; # full path and arguments if the request \u0026#39;\u0026#34;args\u0026#34;: \u0026#34;$args\u0026#34;, \u0026#39; # args \u0026#39;\u0026#34;status\u0026#34;: \u0026#34;$status\u0026#34;, \u0026#39; # response status code \u0026#39;\u0026#34;body_bytes_sent\u0026#34;: \u0026#34;$body_bytes_sent\u0026#34;, \u0026#39; # the number of body bytes exclude headers sent to a client \u0026#39;\u0026#34;bytes_sent\u0026#34;: \u0026#34;$bytes_sent\u0026#34;, \u0026#39; # the number of bytes sent to a client \u0026#39;\u0026#34;http_referer\u0026#34;: \u0026#34;$http_referer\u0026#34;, \u0026#39; # HTTP referer \u0026#39;\u0026#34;http_user_agent\u0026#34;: \u0026#34;$http_user_agent\u0026#34;, \u0026#39; # user agent \u0026#39;\u0026#34;http_x_forwarded_for\u0026#34;: \u0026#34;$http_x_forwarded_for\u0026#34;, \u0026#39; # http_x_forwarded_for \u0026#39;\u0026#34;http_host\u0026#34;: \u0026#34;$http_host\u0026#34;, \u0026#39; # the request Host: header \u0026#39;\u0026#34;server_name\u0026#34;: \u0026#34;$server_name\u0026#34;, \u0026#39; # the name of the vhost serving the request \u0026#39;\u0026#34;request_time\u0026#34;: \u0026#34;$request_time\u0026#34;, \u0026#39; # request processing time in seconds with msec resolution \u0026#39;\u0026#34;upstream\u0026#34;: \u0026#34;$upstream_addr\u0026#34;, \u0026#39; # upstream backend server for proxied requests \u0026#39;\u0026#34;upstream_connect_time\u0026#34;: \u0026#34;$upstream_connect_time\u0026#34;, \u0026#39; # upstream handshake time incl. TLS \u0026#39;\u0026#34;upstream_header_time\u0026#34;: \u0026#34;$upstream_header_time\u0026#34;, \u0026#39; # time spent receiving upstream headers \u0026#39;\u0026#34;upstream_response_time\u0026#34;: \u0026#34;$upstream_response_time\u0026#34;, \u0026#39; # time spend receiving upstream body \u0026#39;\u0026#34;upstream_response_length\u0026#34;: \u0026#34;$upstream_response_length\u0026#34;, \u0026#39; # upstream response length \u0026#39;\u0026#34;upstream_cache_status\u0026#34;: \u0026#34;$upstream_cache_status\u0026#34;, \u0026#39; # cache HIT/MISS where applicable \u0026#39;\u0026#34;ssl_protocol\u0026#34;: \u0026#34;$ssl_protocol\u0026#34;, \u0026#39; # TLS protocol \u0026#39;\u0026#34;ssl_cipher\u0026#34;: \u0026#34;$ssl_cipher\u0026#34;, \u0026#39; # TLS cipher \u0026#39;\u0026#34;scheme\u0026#34;: \u0026#34;$scheme\u0026#34;, \u0026#39; # http or https \u0026#39;\u0026#34;request_method\u0026#34;: \u0026#34;$request_method\u0026#34;, \u0026#39; # request method \u0026#39;\u0026#34;server_protocol\u0026#34;: \u0026#34;$server_protocol\u0026#34;, \u0026#39; # request protocol, like HTTP/1.1 or HTTP/2.0 \u0026#39;\u0026#34;pipe\u0026#34;: \u0026#34;$pipe\u0026#34;, \u0026#39; # \u0026#34;p\u0026#34; if request was pipelined, \u0026#34;.\u0026#34; otherwise \u0026#39;\u0026#34;gzip_ratio\u0026#34;: \u0026#34;$gzip_ratio\u0026#34;, \u0026#39; \u0026#39;\u0026#34;http_cf_ray\u0026#34;: \u0026#34;$http_cf_ray\u0026#34;\u0026#39; \u0026#39;}\u0026#39;; } server { listen 443 ssl http2; server_name _; access_log /var/log/nginx/access.log json; } 如上定义了一个完成的json格式的输出形式，实际的请求输出是这样子的：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 { \u0026#34;msec\u0026#34;: \u0026#34;1696428300.136\u0026#34;, \u0026#34;connection\u0026#34;: \u0026#34;849615\u0026#34;, \u0026#34;connection_requests\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;pid\u0026#34;: \u0026#34;89\u0026#34;, \u0026#34;request_id\u0026#34;: \u0026#34;f17e4e5dcda30462ac83b120f05fedab\u0026#34;, \u0026#34;request_length\u0026#34;: \u0026#34;619\u0026#34;, \u0026#34;remote_addr\u0026#34;: \u0026#34;65.108.78.33\u0026#34;, \u0026#34;remote_user\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;remote_port\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;time_local\u0026#34;: \u0026#34;04/Oct/2023:22:05:00 +0800\u0026#34;, \u0026#34;time_iso8601\u0026#34;: \u0026#34;2023-10-04T22:05:00+08:00\u0026#34;, \u0026#34;request\u0026#34;: \u0026#34;GET /category/%E4%BF%A1%E7%94%A8%E5%8D%A1 HTTP/1.1\u0026#34;, \u0026#34;request_uri\u0026#34;: \u0026#34;/category/%E4%BF%A1%E7%94%A8%E5%8D%A1\u0026#34;, \u0026#34;args\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;status\u0026#34;: \u0026#34;200\u0026#34;, \u0026#34;body_bytes_sent\u0026#34;: \u0026#34;12354\u0026#34;, \u0026#34;bytes_sent\u0026#34;: \u0026#34;12987\u0026#34;, \u0026#34;http_referer\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;http_user_agent\u0026#34;: \u0026#34;Mozilla/5.0 (compatible; MJ12bot/v1.4.8; http://mj12bot.com/)\u0026#34;, \u0026#34;http_x_forwarded_for\u0026#34;: \u0026#34;65.108.78.33\u0026#34;, \u0026#34;http_host\u0026#34;: \u0026#34;www.iminling.com\u0026#34;, \u0026#34;server_name\u0026#34;: \u0026#34;www.iminling.com,iminling.com\u0026#34;, \u0026#34;request_time\u0026#34;: \u0026#34;0.093\u0026#34;, \u0026#34;upstream\u0026#34;: \u0026#34;192.168.0.3:9000\u0026#34;, \u0026#34;upstream_connect_time\u0026#34;: \u0026#34;0.000\u0026#34;, \u0026#34;upstream_header_time\u0026#34;: \u0026#34;0.092\u0026#34;, \u0026#34;upstream_response_time\u0026#34;: \u0026#34;0.093\u0026#34;, \u0026#34;upstream_response_length\u0026#34;: \u0026#34;49160\u0026#34;, \u0026#34;upstream_cache_status\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;ssl_protocol\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;ssl_cipher\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;scheme\u0026#34;: \u0026#34;http\u0026#34;, \u0026#34;request_method\u0026#34;: \u0026#34;GET\u0026#34;, \u0026#34;server_protocol\u0026#34;: \u0026#34;HTTP/1.1\u0026#34;, \u0026#34;pipe\u0026#34;: \u0026#34;.\u0026#34;, \u0026#34;gzip_ratio\u0026#34;: \u0026#34;3.98\u0026#34;, \u0026#34;http_cf_ray\u0026#34;: \u0026#34;810dfa2978c4376f-HEL\u0026#34;, \u0026#34;geoip_country_code\u0026#34;: \u0026#34;FI\u0026#34;, \u0026#34;geoip_city\u0026#34;: \u0026#34;Helsinki\u0026#34; #这里的国家和城市需要开启新的功能，后续再详细说。 } 以上就是对日志格式的说明以及如何实现以json格式输出日志。\n","date":"2023-10-04T15:04:07Z","image":"https://images.iminling.com/app/hide.php?key=eEZmbmFBSW14MCtoRHpiR0RHeW52cHZqTmNJRU1Zblg0cCtiYWo1Z3VSbHNiNUY2cHF0OHJKZHlpbGVCQUpGRVRMWmRwYXM9","permalink":"https://konghanghang.github.io/iminling-pages/2023/custom-nginx-log-output-json/","title":"自定义Nginx日志属性并设置日志以JSON输出"},{"content":"对于java开发者来说jdk是再熟悉不过的了，在java圈还流行这样一句话：你发任你发，我用java8。jdk8是2013年发布的，是一个LTS版本，而在17年发布了jdk9之后，jdk的发布周期变化的更快了，很多开发者直呼学不动了。截止目前已经发布到jdk21了，关于jdk版本的发布可以参考wikipedia的Java历史版本来了解详细。我们今天要安装的是jdk17。\n这么多jdk版本我们应该选择哪个来使用呢？我们先来看看jdk的版本收费情况：\nJDK8以前版本，目前免费。 JDK8，免费版本至8u202，从8u211开始商用收费。 JDK9、JDK10 未收费。 JDK11，免费版本版本至11.0.2，从11.0.3开始商用收费。 JDK12、JDK13、JDK14、JDK15、JDK16，全版本商用收费。 JDK17开始，免费到2024 年 9 月，后续是否收费不明。 作为企业，很大一部分都是不想付费的，所以这也是为什么很多企业使用jdk8的8u202版本，并且不愿意升级的原因。而且jdk8是一个LTS版本，支持到2030年。而下一个LTS版本是jdk11，而jdk11又是收费的，很大一部分企业都不愿意使用，所以直到jdk17出来后，jdk又开始不收费了，而且jdk17是一个LTS版本，所以如果企业想要升级jdk，那么jdk17是一个很好的选择，oracel会支持jdk17到2029年。\n为了体验jdk17以及为以后切换jdk17做准备，所以就需要我们来安装jdk17的开发环境。\nmac可以选择安装Homebrew来快速安装jdk17，关于Homebrew的安装可以参考历史文章：Mac更换源更快速的安装Homebrew，这里就不再多说了，下边我们使用Homebrew来安装jdk。\n安装 先搜索jdk版本：\n1 2 3 4 5 # ko @ MacMini in ~ [10:32:25] $ brew search jdk ==\u0026gt; Formulae openjdk openjdk@17 ✔ jd cdk openjdk@11 openjdk@8 mdk 可以看到有几个jdk的版本可以安装，我们需要的是17，接下来就是安装了：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 # ko @ MacMini in ~ [11:28:24] $ brew install openjdk@17 ==\u0026gt; openjdk@17 For the system Java wrappers to find this JDK, symlink it with sudo ln -sfn /opt/homebrew/opt/openjdk@17/libexec/openjdk.jdk /Library/Java/JavaVirtualMachines/openjdk-17.jdk openjdk@17 is keg-only, which means it was not symlinked into /opt/homebrew, because this is an alternate version of another formula. If you need to have openjdk@17 first in your PATH, run: echo \u0026#39;export PATH=\u0026#34;/opt/homebrew/opt/openjdk@17/bin:$PATH\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.zshrc For compilers to find openjdk@17 you may need to set: export CPPFLAGS=\u0026#34;-I/opt/homebrew/opt/openjdk@17/include\u0026#34; 经过上边的命令后，jdk17就已经安装好了。\n环境变量设置 根据安装最后的提示我们需要先新建一个软链接：\n1 2 3 # konghang @ MacMini in ~ [10:37:47] $ sudo ln -sfn /opt/homebrew/opt/openjdk@17/libexec/openjdk.jdk /Library/Java/JavaVirtualMachines/openjdk-17.jdk Password: 接下来是添加环境变量，我使用的是.base_profile，使用vim编辑后添加以下内容：\n1 2 3 4 # JDK #export JAVA_HOME=\u0026#34;/Library/Java/JavaVirtualMachines/adoptopenjdk-8.jdk/Contents/Home\u0026#34; export JAVA_HOME=\u0026#34;/Library/Java/JavaVirtualMachines/openjdk-17.jdk/Contents/Home\u0026#34; export PATH=${JAVA_HOME}/bin:$PATH 然后刷新变量，然后查看jdk版本看是否成功：\n1 2 3 4 5 6 7 8 # ko @ MacMini in ~ [10:43:55] $ source .bash_profile # ko @ MacMini in ~ [10:43:59] $ java -version openjdk version \u0026#34;17.0.8.1\u0026#34; 2023-08-24 OpenJDK Runtime Environment Homebrew (build 17.0.8.1+0) OpenJDK 64-Bit Server VM Homebrew (build 17.0.8.1+0, mixed mode, sharing) 看到当前的环境下使用的是jdk17了，截止到这里jdk17就已经安装成功了。接下来就可以使用jdk来进行开发和研究了。\n","date":"2023-10-03T02:55:28Z","image":"https://images.iminling.com/app/hide.php?key=bEt3WUtUZk13dFI3Z0FyckVUZGdnRDZNd1E0aVBaMDZPbVdZTm1RR1lsS3NtNWkyOWZ4UkI5R0g3ZFlVTjVxdWtzcDdkMjA9","permalink":"https://konghanghang.github.io/iminling-pages/2023/mac-install-jdk17/","title":"Mac快速安装jdk17环境"},{"content":"Homebrew是一款Mac OS平台下的软件包管理工具，拥有安装、卸载、更新、查看、搜索等很多实用的功能。简单的一条指令，就可以实现包管理，而不用你关心各种依赖和文件路径的情况，十分方便快捷。但是安装却是需要去github去拉仓库然后进行安装，github在国内的访问速度堪忧，所以会导致整个安装过程很长，甚至安装失败，这里我记录一下我替换源进行安装的过程，希望可以帮助大家。\n安装准备 Homebrew的官网提供了一键安装的脚本，脚本的实际指向是github仓库中的install仓库，查看安装脚本install.sh,可以发现安装的过程会优先读环境变量中的git仓库地址，如果没有则使用脚本中默认的github中的仓库地址，所以我们可以把要使用的源设置好环境变量，在install.sh脚本安装的时候直接使用我们设置好的源来加快安装速度：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 HOMEBREW_BREW_DEFAULT_GIT_REMOTE=\u0026#34;https://github.com/Homebrew/brew\u0026#34; HOMEBREW_CORE_DEFAULT_GIT_REMOTE=\u0026#34;https://github.com/Homebrew/homebrew-core\u0026#34; # Use remote URLs of Homebrew repositories from environment if set. HOMEBREW_BREW_GIT_REMOTE=\u0026#34;${HOMEBREW_BREW_GIT_REMOTE:-\u0026#34;${HOMEBREW_BREW_DEFAULT_GIT_REMOTE}\u0026#34;}\u0026#34; HOMEBREW_CORE_GIT_REMOTE=\u0026#34;${HOMEBREW_CORE_GIT_REMOTE:-\u0026#34;${HOMEBREW_CORE_DEFAULT_GIT_REMOTE}\u0026#34;}\u0026#34; # The URLs with and without the \u0026#39;.git\u0026#39; suffix are the same Git remote. Do not prompt. if [[ \u0026#34;${HOMEBREW_BREW_GIT_REMOTE}\u0026#34; == \u0026#34;${HOMEBREW_BREW_DEFAULT_GIT_REMOTE}.git\u0026#34; ]] then HOMEBREW_BREW_GIT_REMOTE=\u0026#34;${HOMEBREW_BREW_DEFAULT_GIT_REMOTE}\u0026#34; fi if [[ \u0026#34;${HOMEBREW_CORE_GIT_REMOTE}\u0026#34; == \u0026#34;${HOMEBREW_CORE_DEFAULT_GIT_REMOTE}.git\u0026#34; ]] then HOMEBREW_CORE_GIT_REMOTE=\u0026#34;${HOMEBREW_CORE_DEFAULT_GIT_REMOTE}\u0026#34; fi export HOMEBREW_{BREW,CORE}_GIT_REMOTE 所以我们需要设置两个环境变量HOMEBREW_BREW_GIT_REMOTE和HOMEBREW_CORE_GIT_REMOTE\n，我这里使用的是中科大的源来进行安装，具体可以参考中科的的介绍页面：Homebrew 源使用帮助。两个变量的设置脚本如下：\n1 2 export HOMEBREW_BREW_GIT_REMOTE=\u0026#34;https://mirrors.ustc.edu.cn/brew.git\u0026#34; export HOMEBREW_CORE_GIT_REMOTE=\u0026#34;https://mirrors.ustc.edu.cn/homebrew-core.git\u0026#34; 这样就完成了源的替换，不要关闭执行上边export命令的窗口，下一步在同一个窗口执行安装脚本。\n安装 执行官网的一键安装脚本：\n1 /bin/bash -c \u0026#34;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\u0026#34; 由于替换了中科大的源，安装上不会很慢，等待程序执行完成就可以了。\n安装完成后把brew添加到环境变量，编辑.bash_profile文件，添加下边一行代码：\n1 export PATH=/opt/homebrew/bin:$PATH 保存后刷新环境，使配置的变量生效：\n1 source .bash_profile 然后就可以正常使用brew来安装和管理应用了。\n使用 下边列举一些常用的brew的使用命令：\n1 2 3 4 5 6 7 brew search ** //查找某个软件包 brew list //列出已经安装的软件的包 brew install ** //安装某个软件包,默认安装的是稳定版本 brew uninstall **//卸载某个软件的包 brew upgrade ** //更新某个软件包 brew info ** //查看指定软件包的说明 brew cache clean //清理缓存 以上就是homebrew简单快速的安装过程。\n","date":"2023-10-02T00:00:00Z","image":"https://images.iminling.com/app/hide.php?key=NmtEZ1ZGOE1SbXJlVENkbTFYQTBQcko2NVc4UHBtT044clNuYUZpQStJZHpieGVORmFLbFhTVnBRczhwNWpyRTlKL3N5TWM9","permalink":"https://konghanghang.github.io/iminling-pages/2023/mac-change-source-install-homebrew/","title":"Mac更换源更快速的安装Homebrew"},{"content":"前段遇到了一个大麻烦，我的网站主页发布了两篇非我自己写的文章，在登录了worpress后台后，发现的确是有两篇文章，随后赶紧删除了那两篇文章。经过排查发现是xmlrpc功能没有关闭导致的，所以就有了我的上篇文章：禁用xmlrpc.php防止wordpress被暴力破解，事后及时关闭了该功能，然后就想着，既然要发布文章，是不是要登录我的管理后台，那么是否可以设置在用户登录wordpress管理后台的时候进行通知我呢，然后就去搜索了一下相关功能，果然还是有办法通知到我的。下边简单的分享一下该功能。\n邮件配置 邮件的配置网上有很多教程，比如使用WP Mail SMTP插件，这里就跳过了。\nTelegram配置 其实使用邮件配置就可以了，当有登录的时候就会通过邮件来通知我们。我这里并不想在自己的邮箱里留存太多的邮件，而且自己用Telegram比较多，就想着把通知发送Telegram会更好，我就安装了插件：WP Telegram。功能也很强，它能在要发邮件的时候劫持邮件内容到telegram:\n只需要在Telegram申请好机器人就可以了，插件中也有申请步骤。\n发送配置 编辑主题文件中的functions.php文件[外观-主题文件编辑器]，在文件末尾添加以下代码就可以实现了：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 /***************************************************** 函数名称：wp_login_notify v1.0 by DH.huahua. 函数作用：有登录wp后台就会email通知博主 ******************************************************/ function wp_login_notify() { date_default_timezone_set(\u0026#39;PRC\u0026#39;); $admin_email = get_bloginfo (\u0026#39;admin_email\u0026#39;); $to = $admin_email; $subject = \u0026#39;你的博客空间登录提醒\u0026#39;; $message = \u0026#39;\u0026lt;p\u0026gt;你好！你的博客空间(\u0026#39; . get_option(\u0026#34;blogname\u0026#34;) . \u0026#39;)有登录！\u0026lt;/p\u0026gt;\u0026#39; . \u0026#39;\u0026lt;p\u0026gt;请确定是您自己的登录，以防别人攻击！登录信息如下：\u0026lt;/p\u0026gt;\u0026#39; . \u0026#39;\u0026lt;p\u0026gt;登录名：\u0026#39; . $_POST[\u0026#39;username\u0026#39;] . \u0026#39;\u0026lt;p\u0026gt;\u0026#39; . \u0026#39;\u0026lt;p\u0026gt;登录密码：\u0026#39; . $_POST[\u0026#39;password\u0026#39;] . \u0026#39;\u0026lt;p\u0026gt;\u0026#39; . \u0026#39;\u0026lt;p\u0026gt;登录时间：\u0026#39; . date(\u0026#34;Y-m-d H:i:s\u0026#34;) . \u0026#39;\u0026lt;p\u0026gt;\u0026#39; . \u0026#39;\u0026lt;p\u0026gt;登录IP：\u0026#39; . $_SERVER[\u0026#39;REMOTE_ADDR\u0026#39;] . \u0026#39;\u0026lt;p\u0026gt;\u0026#39;; $wp_email = \u0026#39;no-reply@\u0026#39; . preg_replace(\u0026#39;#^www\\.#\u0026#39;, \u0026#39;\u0026#39;, strtolower($_SERVER[\u0026#39;SERVER_NAME\u0026#39;])); $from = \u0026#34;From: \\\u0026#34;\u0026#34; . get_option(\u0026#39;blogname\u0026#39;) . \u0026#34;\\\u0026#34; \u0026lt;$wp_email\u0026gt;\u0026#34;; $headers = \u0026#34;$from\\nContent-Type: text/html; charset=\u0026#34; . get_option(\u0026#39;blog_charset\u0026#39;) . \u0026#34;\\n\u0026#34;; wp_mail( $to, $subject, $message, $headers ); } add_action(\u0026#39;wp_login\u0026#39;, \u0026#39;wp_login_notify\u0026#39;); /***************************************************** 函数名称：wp_login_failed_notify v1.0 by DH.huahua. 函数作用：有错误登录wp后台就会email通知博主 ******************************************************/ function wp_login_failed_notify() { date_default_timezone_set(\u0026#39;PRC\u0026#39;); $admin_email = get_bloginfo (\u0026#39;admin_email\u0026#39;); $to = $admin_email; $subject = \u0026#39;你的博客空间登录错误警告\u0026#39;; $message = \u0026#39;\u0026lt;p\u0026gt;你好！你的博客空间(\u0026#39; . get_option(\u0026#34;blogname\u0026#34;) . \u0026#39;)有登录错误！\u0026lt;/p\u0026gt;\u0026#39; . \u0026#39;\u0026lt;p\u0026gt;请确定是您自己的登录失误，以防别人攻击！登录信息如下：\u0026lt;/p\u0026gt;\u0026#39; . \u0026#39;\u0026lt;p\u0026gt;登录名：\u0026#39; . $_POST[\u0026#39;username\u0026#39;] . \u0026#39;\u0026lt;p\u0026gt;\u0026#39; . \u0026#39;\u0026lt;p\u0026gt;登录密码：\u0026#39; . $_POST[\u0026#39;password\u0026#39;] . \u0026#39;\u0026lt;p\u0026gt;\u0026#39; . \u0026#39;\u0026lt;p\u0026gt;登录时间：\u0026#39; . date(\u0026#34;Y-m-d H:i:s\u0026#34;) . \u0026#39;\u0026lt;p\u0026gt;\u0026#39; . \u0026#39;\u0026lt;p\u0026gt;登录IP：\u0026#39; . $_SERVER[\u0026#39;REMOTE_ADDR\u0026#39;] . \u0026#39;\u0026lt;p\u0026gt;\u0026#39;; $wp_email = \u0026#39;no-reply@\u0026#39; . preg_replace(\u0026#39;#^www\\.#\u0026#39;, \u0026#39;\u0026#39;, strtolower($_SERVER[\u0026#39;SERVER_NAME\u0026#39;])); $from = \u0026#34;From: \\\u0026#34;\u0026#34; . get_option(\u0026#39;blogname\u0026#39;) . \u0026#34;\\\u0026#34; \u0026lt;$wp_email\u0026gt;\u0026#34;; $headers = \u0026#34;$from\\nContent-Type: text/html; charset=\u0026#34; . get_option(\u0026#39;blog_charset\u0026#39;) . \u0026#34;\\n\u0026#34;; wp_mail( $to, $subject, $message, $headers ); } add_action(\u0026#39;wp_login_failed\u0026#39;, \u0026#39;wp_login_failed_notify\u0026#39;); 一个是登录成功的提醒，一个是登录失败的提醒，如果有人登录wordpress后台的时候就会在telegram的机器人中进行通知：\n1 2 3 4 5 6 7 8 9 10 11 12 13 🔔‌你的博客空间登录提醒🔔 你好！你的博客空间(分享)有登录！ 请确定是您自己的登录，以防别人攻击！登录信息如下： 登录名： 登录密码： 登录时间：2023-09-29 16:02:40 登录IP：24:4:2:: 经过上边的配置，就可以在有人登录worpress后台的时候及时的通知我们，避免出现我上次遇到的情况，相对来说避免发生一些自己预想以外的事情。\n","date":"2023-09-29T08:46:00Z","image":"https://images.iminling.com/app/hide.php?key=NE1yYVdkUjdQS3Q1UTBUODVkbW5zcUF5ckdjQzBHNzJHSWdQZGN2bFN0N1pJK1JEN0FxVG9OZFc1SUQrekV4Um9janlZWDQ9","permalink":"https://konghanghang.github.io/iminling-pages/2023/wordpress-login-use-mail-telegram-notice/","title":"WordPress用户登录管理后台进行邮件或Telegram通知"},{"content":"很多刚接触wordpress的朋友估计和我一样，对于xmlrpc.php的了解几乎为0，这玩意儿是干嘛的？为什么它会导致wordpress被暴力破解？下面我们就先来认识一下xmlrpc.php是个什么东西。\n什么是xmlrpc.php XML-RPC是支持WordPress与其他系统之间通信的规范。它通过使用HTTP作为传输机制和XML作为编码机制来标准化这些通信来实现此目的。例如，假设您想通过移动设备在您的网站上发帖，因为您的计算机不在附近。 您可以使用 xmlrpc.php 启用的远程访问功能来做到这一点。\n在WordPress的早期版本中，默认情况下已关闭XML-RPC。但是自v3.5版本开始，默认情况下又启用它。这样做的主要原因是允许WordPress移动应用程序与WordPress安装进行对话通讯。\n但是由于REST API已集成到WordPress核心中，因此xmlrpc.php文件不再用于此通信。相反，REST API用于与WordPress移动应用程序，桌面客户端，其他博客平台，WordPress.com（用于Jetpack插件）以及其他系统和服务进行通信。REST API-可与之交互的系统范围比xmlrpc.php所允许的大得多。此外，拥有更强的灵活性。\n经历 为什么我会知道这个玩意儿呢？因为在某一天的早上，我发现我的网站突然就多了两篇文章，并不是我写的，莫名其妙的就多了两篇，于是马上修改了管理用户的登录密码，防止别人再登录。之后便开始了此次被攻击的思考，我的密码设置的也并不简单，他们是怎么知道我的密码的呢？于是我就开始了查看请求日志，在nginx的日志中果然发现了一些端倪，有大量的请求在请求xmlrpc.php这个文件：\n于是我就去搜索了xmlrpc.php这个文件，不搜索不知道，一搜索吓一跳，md，肯定是这玩意儿导致我的网站多了两篇文章出来。于是开始了探索如何禁用之路。\n禁用xmlrpc.php 既然wordpress出了REST API取代XML-RPC，为了安全我们应该在站点上禁用xmlrpc.php。接下来介绍三种禁用的方案。\n通过nginx过滤请求 这种是我在使用的方案，通过nginx的location来定位这个请求，然后相应403，禁止请求访问。关于location的用法，参考我的另一篇文章：nginx中location使用方法总结。在处理wordpress站点的server代码块中添加以下代码来阻止其他人访问xmlrpc.php:\n1 2 3 location ~* ^/xmlrpc\\.php$ { return 403; } 添加以后，再有人访问xmlrpc.php文件的时候就会返回403.\n通过functions.php禁用 刚开始我使用的就是这种方式来禁用的，但是在更新了主题文件后，设置丢失了，所以就换成了nginx来进行拦截，这里也顺带说一下这种方式。在后台中，找到外观-主题文件编辑器菜单，然后点击右侧的functions.php,在编辑区将以下方法添加进去保存文件就可以了。\n1 add_filter(\u0026#39;xmlrpc_enabled\u0026#39;, \u0026#39;__return_false\u0026#39;); 保存后，就没办法再访问xmlrpc.php文件了。\n通过.htaccess 文件禁用 .htaccess文件在/var/www/html目录下，是一个隐藏文件，我们编辑这个文件，在文件中添加以下内容来达到屏蔽xmlrpc.php文件的目的：\n1 2 3 4 5 6 # Block WordPress xmlrpc.php requests \u0026lt;Files xmlrpc.php\u0026gt; order deny,allow deny from all allow from xxx.xxx.xxx.xxx \u0026lt;/Files\u0026gt; 可以禁用所有调用该文件的情况，但是可以设置例外，我们可以把允许的ip替换xxx.xxx.xxx.xxx来达到只允许特定的ip来访问该文件。\n以上就是我因为xmlrpc.php文件遭遇到的问题以及针对这种情况进行的防御，希望可以帮到大家。\n","date":"2023-09-03T09:07:36Z","image":"https://images.iminling.com/app/hide.php?key=NnVNTjhMWXJ5N2tkOGpzYWFnVWJuYnhhOGFtQnZmYzc2S3BzdDJhY29HUEUvUHU5TkZVRk90VkgyTzlHUzMyVDAvMDlXcDg9","permalink":"https://konghanghang.github.io/iminling-pages/2023/disable-xmlrpc-php/","title":"禁用xmlrpc.php防止wordpress被暴力破解"},{"content":"双协议栈技术就是指在一台设备上同时启用 IPv4 协议栈和 IPv6 协议栈，这样就可以同时使用 IPv4 和 IPv6 的网络。但是在默认情况下都会以IPv6网络优先，只有 IPv6 无法访问的时候才会尝试访问 IPv4，某些特定的应用和场景下，我们并不想要 IPv6 优先，这时候就需要修改一些配置文件让 IPv4 优先。\n查看网络优先级 可以通过以下命令来查看当前的机器是以哪个网络优先的：\n1 2 root@gc:~# curl ip.sb 2000::97e4 如上返回了IPv6的地址，所以该机器默认就是通过IPv6来访问网站的，通过配置curl强制使用IPv4协议来进行访问：\n1 2 root@gc:~# curl ip.sb -4 192.168.0.235 接下来就来修改配置使IPv4成功默认的出栈协议。\n修改/etc/gai.conf 在 Debian、Ubuntu 等 Linux 系统下，有一个 /etc/gai.conf 文件，用于系统的 getaddrinfo 调用，默认情况下，它会使用 IPv6 优先，编辑gai.conf文件，会看到以下配置：\n1 2 3 4 5 6 7 8 9 10 11 12 13 # precedence \u0026lt;mask\u0026gt; \u0026lt;value\u0026gt; # Add another rule to the RFC 3484 precedence table. See section 2.1 # and 10.3 in RFC 3484. The default is: # #precedence ::1/128 50 #precedence ::/0 40 #precedence 2002::/16 30 #precedence ::/96 20 #precedence ::ffff:0:0/96 10 # # For sites which prefer IPv4 connections change the last line to # #precedence ::ffff:0:0/96 100 里边有一行提示：For sites which prefer IPv4 connections change the last line to，想要IPv4出栈，可以设置：precedence ::ffff:0:0/96 100\n，根据提示把该行前的注释去掉，如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 # precedence \u0026lt;mask\u0026gt; \u0026lt;value\u0026gt; # Add another rule to the RFC 3484 precedence table. See section 2.1 # and 10.3 in RFC 3484. The default is: # #precedence ::1/128 50 #precedence ::/0 40 #precedence 2002::/16 30 #precedence ::/96 20 #precedence ::ffff:0:0/96 10 # # For sites which prefer IPv4 connections change the last line to # precedence ::ffff:0:0/96 100 修改后保存，然后再使用curl访问网站，不指定使用的IPv4还是IPv6，默认情况下就走了IPv4，如下：\n1 2 root@gc:~# curl ip.sb -4 192.168.0.235 修改gai.conf后就默认走了IPv4协议了。\n禁用IPv6 有一些极端情况下，我们可能需要禁止系统的 IPv6 功能，这时候就需要修改 /etc/sysctl.conf 文件，首先找到你的网卡名称，默认是 eth0 ，可以通过以下命令查看自己的网卡名：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 root@gc:~# ip address 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 2: eth0: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc fq state UP group default qlen 1000 link/ether 00:16:3c:6b:b7:c3 brd ff:ff:ff:ff:ff:ff altname enp0s3 altname ens3 inet 192.168.0.235/24 brd 192.168.0.255 scope global eth0 valid_lft forever preferred_lft forever inet6 2000::97e4/112 scope global valid_lft forever preferred_lft forever inet6 fe80::216:3cff:fe6b:b7c3/64 scope link valid_lft forever preferred_lft forever 我的网卡名就是eth0，然后修改/etc/sysctl.conf，加入一下内容(将网卡名替换为自己的)：\n1 2 3 4 5 6 7 8 net.ipv6.conf.all.autoconf = 0 net.ipv6.conf.default.autoconf = 0 net.ipv6.conf.all.accept_ra = 0 net.ipv6.conf.default.accept_ra = 0 net.ipv6.conf.all.disable_ipv6 = 1 net.ipv6.conf.default.disable_ipv6 = 1 net.ipv6.conf.lo.disable_ipv6 = 1 net.ipv6.conf.eth0.disable_ipv6 = 1 然后使用 sysctl -p 来重新加载配置文件，此时查看 ip a 就可以发现 IPv6 已经被禁止了。\n以上就是双栈网络的机器设置IPv4网络优先的方法，自己测试了Debian和Ubuntu都是可以实现的，希望可以帮到大家。\n","date":"2023-09-03T02:58:44Z","image":"https://images.iminling.com/app/hide.php?key=cU9DUVBIUnEzWktLQnpML0x0b090RkVtOGRNa0VnNXpMMFNSSFZKcTNsZkQ3eXdWNDlnZS9pNWZvNHFXdVNZV0JZVVpBREE9","permalink":"https://konghanghang.github.io/iminling-pages/2023/linux-use-ipv4-first/","title":"linux双栈网络设置IPv4优先"},{"content":"在nignx中我们比较长使用的就是location，我们使用location来定位资源或者转发请求，使用不当经常就会遇到404错误，无法找到资源或者请求异常。下面我们来详细了解一下location的用法。\n语法 location的具体语法如下：\n1 2 location [ = | ~ | ~* | ^~ ] uri { ... } location @name { ... } 语法规则很简单，一个location关键字，后面跟着可选的修饰符，后面是要匹配的字符，花括号中是要执行的操作。\n修饰符 在语法中可以看到location有四中修饰符，其实还有一种就是修饰符就是什么也没有，location后边直接跟uri，下边来详细了解一下各种修饰符的作用：\n= 表示精确匹配。只有请求的url路径与后面的字符串完全相等时，才会命中。 ~ 表示该规则是使用正则定义的，区分大小写。 ~* 表示该规则是使用正则定义的，不区分大小写。 ^~ 表示如果该符号后面的字符是最佳匹配，采用该规则，不再进行后续的查找。 无修饰符 表示前缀匹配\n=、~和^~是非正则匹配，~和~*是正则匹配。\nlocation匹配还有一个特点：**非正则匹配优先！**非正则\u0026gt;正则\n匹配过程 总共5种修饰符，如果一个url请求过来可以匹配到多种，那nginx会如何选择呢？下边来看一下完整的匹配过程：\n用所有的前缀字符串去匹配URI(这里说的前缀字符串，是除和*修饰的字符串外的所有字符串，包括=、^~及无修饰符三种都算是前缀字符串)；\n如果找到=号修饰的字符串与URI匹配(无论它在哪个位置)，则终止匹配过程，并进入该location内部执行具体操作；\n如果不找到=号修饰的字符串，则继续匹配普通前缀字符串(即用^~修饰的或无修饰符的字符串)；\n在^~修饰的或无修饰符的字符串中如果有多个规则能匹配上URI，则会查看最长的那一个是否用^~修饰；\n如果最长的那个有用^~修饰，则终止匹配，这个用^~修饰的“最长”的匹配就是最终被选用的location，但是如果这个“最长”的匹配没有用^~修饰(说明它是无修饰符的)，则会暂时把它存储下来，但不会终止匹配，而是继续进行后面的正则匹配；\n开始正则匹配，匹配所有用或*修饰的字符串\n匹配到第一个正则表达式后终止匹配，使用对应的location；\n如果没有匹配到正则表达式，则使用之前存储的前缀字符串对应的location，至此，整个匹配过程结束。\n路径匹配 使用location的时候，代码块里一般会使用root或者alias或者proxy_pass下边详细说一下proxy_pass的用法。\nproxy_pass Nginx的官网将proxy_pass分为两种类型：\n种是只包含IP和端口号的（连端口之后的/也没有，这里要特别注意），比如proxy_pass http://localhost:8080，这种方式称为不带URI方式；\n另一种是在端口号之后有其他路径的，包含了只有单个/的，如proxy_pass http://localhost:8080/，以及其他路径，比如proxy_pass http://localhost:8080/abc。\n不带URI方式(相对路径) 对于不带URI方式，Nginx将会保留location中路径部分，比如：\u0026lt;\n1 2 3 location /api1/ { proxy_pass http://localhost:8080; } 在访问http://localhost/api1/xxx时，会代理到`http://localhost:8080/api1/xxx\n带URI方式(绝对路径) 对于带URI方式，nginx将使用诸如alias的替换方式对URL进行替换，并且这种替换只是字面上的替换，比如：\n1 2 3 location /api2/ { proxy_pass http://localhost:8080/; } 当访问http://localhost/api2/xxx时，http://localhost/api2/（注意最后的/）被替换成了http://localhost:8080/，然后再加上剩下的xxx，于是变成了http://localhost:8080/xxx。 下面再给一些例子来帮助大家理解相对路径和绝对路径：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 server { listen 80; server_name localhost; # proxy_pass中的域名是相对路径，所以会带上location中的路径 location /api1/ { proxy_pass http://localhost:8080; } # http://localhost/api1/xxx -\u0026gt; http://localhost:8080/api1/xxx # proxy_pass中的域名是绝对路径，所以不会带上location中的路径 location /api2/ { proxy_pass http://localhost:8080/; } # http://localhost/api2/xxx -\u0026gt; http://localhost:8080/xxx # proxy_pass中的域名是相对路径，所以会带上location中的路径 location /api3 { proxy_pass http://localhost:8080; } # http://localhost/api3/xxx -\u0026gt; http://localhost:8080/api3/xxx # proxy_pass中的域名是绝对路径，所以不会带上location中的路径 location /api4 { proxy_pass http://localhost:8080/; } # http://localhost/api4/xxx -\u0026gt; http://localhost:8080//xxx，匹配到/api4/xxx,location中是/api4需去掉剩下/xxx，加上proxy_pass则是//xxx # proxy_pass中的域名是绝对路径，所以不会带上location中的路径 location /api5/ { proxy_pass http://localhost:8080/haha; } # http://localhost/api5/xxx -\u0026gt; http://localhost:8080/hahaxxx，匹配到/api5/xxx, 去掉location中的/api5/剩下xxx，加上proxy_pass则是hahaxxx # proxy_pass中的域名是绝对路径，所以不会带上location中的路径 location /api6/ { proxy_pass http://localhost:8080/haha/; } # http://localhost/api6/xxx -\u0026gt; http://localhost:8080/haha/xxx # proxy_pass中的域名是绝对路径，所以不会带上location中的路径 location /api7 { proxy_pass http://localhost:8080/haha; } # http://localhost/api7/xxx -\u0026gt; http://localhost:8080/haha/xxx # proxy_pass中的域名是绝对路径，所以不会带上location中的路径 location /api8 { proxy_pass http://localhost:8080/haha/; } # http://localhost/api8/xxx -\u0026gt; http://localhost:8080/haha//xxx，匹配到/api8/xxx,去掉location中的/api8剩下/xxx,加上proxy_pass则是/haha//xxx } 以上就是nginx中location的使用方法，匹配规则，以及代码块中proxy_pass的使用方法，希望可以帮到大家。\n","date":"2023-08-30T14:57:18Z","permalink":"https://konghanghang.github.io/iminling-pages/2023/nginx-location-use-summary/","title":"nginx中location使用方法总结"},{"content":"\nnetflix中文名又叫网飞或者奈飞，在中国大陆是无法直接观看的，当我们买了一个vps搭建节点代理后正常情况是可以观看的，但是奈飞因为版权原因，有些vps机器并不能完整的看奈飞的所有内容，这时就引出了另一个概念：奈飞解锁。一台vps观看奈飞可以分为三种情况：\n无法观看，ip比较黑，直接连奈飞的官网都无法打开 只能观看奈飞的自制剧，因为是奈飞的自制剧，就没有所谓的严格版权，都可以看。大部分vps都是这种情况 可以观看奈飞非自制剧。可以观看奈飞购买的其他的版权剧。 上面我们了解到了奈飞的一些限制，所以网上就有很多解锁教程，通过warp，dns等来解锁。本文的前提是你的vps的ipv6是解锁奈飞的非自制剧的。\n我手上的这台vps就是这种情况，ipv4只能观看自制剧，ipv6可以观看奈飞非自制剧，关于查看自己的vps是否解锁，可以通过以下脚本来验证：bash \u0026lt;(curl -L -s check.unlock.media)\n我的机器解锁情况如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 ** 正在测试IPv4解锁情况 -------------------------------- ============[ Multination ]============ Dazn: No HotStar: No Disney+: Yes (Region: GB) Netflix: Originals Only YouTube Premium: Yes Amazon Prime Video: Yes (Region: HK) TVBAnywhere+: No iQyi Oversea Region: HK Viu.com: Yes (Region: HK) YouTube CDN: Hong Kong Netflix Preferred CDN: Hong Kong Spotify Registration: No Steam Currency: HKD ChatGPT: Yes ======================================= ** 正在测试IPv6解锁情况 -------------------------------- ============[ Multination ]============ Dazn: Failed (Network Connection) HotStar: No Disney+: No Netflix: Yes (Region: HK) YouTube Premium: No (Region: CN) Amazon Prime Video: Unsupported TVBAnywhere+: Failed (Network Connection) iQyi Oversea Region: Failed Viu.com: Failed YouTube CDN: Hong Kong Netflix Preferred CDN: Hong Kong Spotify Registration: No Steam Currency: Failed (Network Connection) ChatGPT: Yes ======================================= 本次测试已结束，感谢使用此脚本 可以看到ipv4的结果是Originals Only就是所谓的只能观看自制剧，ipv6就是完整的解锁香港的奈飞的。\n下面我们将使用xray来进行分流，使观看奈飞的时候走ipv6，观看奈飞的非自制剧。\nxray安装 xray可以使用官方的安装脚本，也可以参考我的xui安装教程：x-ui安装配置使用,具体的安装这里就不再详细讲了。\n配置节点 先建一个入站节点，即我们需要连接到这台vps所使用的节点，可以通过xui来配置，节点类型根据自己的情况配置(vless,vmess,ss等都可以，比较稳的还是vless)，可以参考我的教程来搭建vless节点：xray搭建reality和网站共用443端口启用网站SSL，我这里为了简单直接搭建一个ss的节点，下边直接贴出xray的具体配置：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 { \u0026#34;routing\u0026#34;: { \u0026#34;domainStrategy\u0026#34;: \u0026#34;IPIfNonMatch\u0026#34;, \u0026#34;rules\u0026#34;: [ { \u0026#34;type\u0026#34;: \u0026#34;field\u0026#34;, \u0026#34;inboundTag\u0026#34;: [ \u0026#34;api\u0026#34; ], \u0026#34;outboundTag\u0026#34;: \u0026#34;api\u0026#34; }, { \u0026#34;type\u0026#34;: \u0026#34;field\u0026#34;, \u0026#34;outboundTag\u0026#34;: \u0026#34;blocked\u0026#34;, \u0026#34;protocol\u0026#34;: [ \u0026#34;bittorrent\u0026#34; ] } ] }, \u0026#34;dns\u0026#34;: null, \u0026#34;inbounds\u0026#34;: [ { \u0026#34;listen\u0026#34;: null, \u0026#34;port\u0026#34;: 24567, \u0026#34;protocol\u0026#34;: \u0026#34;shadowsocks\u0026#34;, \u0026#34;settings\u0026#34;: { \u0026#34;method\u0026#34;: \u0026#34;aes-256-gcm\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;WqOQzCxMwdfeegegOK36n\u0026#34;, \u0026#34;network\u0026#34;: \u0026#34;tcp,udp\u0026#34; }, \u0026#34;streamSettings\u0026#34;: { \u0026#34;network\u0026#34;: \u0026#34;tcp\u0026#34;, \u0026#34;security\u0026#34;: \u0026#34;none\u0026#34;, \u0026#34;tcpSettings\u0026#34;: { \u0026#34;header\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;none\u0026#34; }, \u0026#34;acceptProxyProtocol\u0026#34;: false } }, \u0026#34;tag\u0026#34;: \u0026#34;inbound-13103\u0026#34;, \u0026#34;sniffing\u0026#34;: { \u0026#34;enabled\u0026#34;: true, \u0026#34;destOverride\u0026#34;: [ \u0026#34;http\u0026#34;, \u0026#34;tls\u0026#34;, \u0026#34;quic\u0026#34; ] } } ], \u0026#34;outbounds\u0026#34;: [ { \u0026#34;protocol\u0026#34;: \u0026#34;freedom\u0026#34;, \u0026#34;settings\u0026#34;: {} }, { \u0026#34;tag\u0026#34;: \u0026#34;blocked\u0026#34;, \u0026#34;protocol\u0026#34;: \u0026#34;blackhole\u0026#34;, \u0026#34;settings\u0026#34;: {} } ], \u0026#34;stats\u0026#34;: {}, \u0026#34;reverse\u0026#34;: null, \u0026#34;fakeDns\u0026#34;: null } 如上就是一个ss的完整配置，直接运行xray核心就可以访问了。上边的配置所有的网络都还是使用的ipv4来进行代理访问的。\n配置奈飞ipv6出站 这里我们就需要使用到xray的分流策略，需要在routing配置中进行分流配置，然后在outbounds中配置具体的策略。关于分流参考官方的教程：ruleObject,ruleObject的规则如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 { \u0026#34;domainMatcher\u0026#34;: \u0026#34;hybrid\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;field\u0026#34;, \u0026#34;domain\u0026#34;: [\u0026#34;baidu.com\u0026#34;, \u0026#34;qq.com\u0026#34;, \u0026#34;geosite:cn\u0026#34;], \u0026#34;ip\u0026#34;: [\u0026#34;0.0.0.0/8\u0026#34;, \u0026#34;10.0.0.0/8\u0026#34;, \u0026#34;fc00::/7\u0026#34;, \u0026#34;fe80::/10\u0026#34;, \u0026#34;geoip:cn\u0026#34;], \u0026#34;port\u0026#34;: \u0026#34;53,443,1000-2000\u0026#34;, \u0026#34;sourcePort\u0026#34;: \u0026#34;53,443,1000-2000\u0026#34;, \u0026#34;network\u0026#34;: \u0026#34;tcp\u0026#34;, \u0026#34;source\u0026#34;: [\u0026#34;10.0.0.1\u0026#34;], \u0026#34;user\u0026#34;: [\u0026#34;love@xray.com\u0026#34;], \u0026#34;inboundTag\u0026#34;: [\u0026#34;tag-vmess\u0026#34;], \u0026#34;protocol\u0026#34;: [\u0026#34;http\u0026#34;, \u0026#34;tls\u0026#34;, \u0026#34;bittorrent\u0026#34;], \u0026#34;attrs\u0026#34;: { \u0026#34;:method\u0026#34;: \u0026#34;GET\u0026#34; }, \u0026#34;outboundTag\u0026#34;: \u0026#34;direct\u0026#34;, \u0026#34;balancerTag\u0026#34;: \u0026#34;balancer\u0026#34; } 这里边的属性，如果配置多个则是要多个同时匹配中才能生效，下边我贴出配置奈飞的配置：\n1 2 3 4 5 6 7 { \u0026#34;type\u0026#34;: \u0026#34;field\u0026#34;, \u0026#34;outboundTag\u0026#34;: \u0026#34;netflix-tag\u0026#34;, \u0026#34;domain\u0026#34;: [ \u0026#34;geosite:netflix\u0026#34; ] } 我这里使用domain来配置所有netflix的网址，然后使用outboundTag来指定如果匹配中netflix的网址，应该使用netflix-tag来进行出站访问，这个netflix-tag名称是可以自定义的，但是它需要和接下来讲的outbonds中的属性匹配，outbouds的配置可以参考xray官方文档：outboudsObject,outboudsObject的规则如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 { \u0026#34;outbounds\u0026#34;: [ { \u0026#34;sendThrough\u0026#34;: \u0026#34;0.0.0.0\u0026#34;, \u0026#34;protocol\u0026#34;: \u0026#34;协议名称\u0026#34;, \u0026#34;settings\u0026#34;: {}, \u0026#34;tag\u0026#34;: \u0026#34;标识\u0026#34;, \u0026#34;streamSettings\u0026#34;: {}, \u0026#34;proxySettings\u0026#34;: { \u0026#34;tag\u0026#34;: \u0026#34;another-outbound-tag\u0026#34; }, \u0026#34;mux\u0026#34;: {} } ] } 下边我贴出具体的配置：\n1 2 3 4 5 6 7 { \u0026#34;tag\u0026#34;: \u0026#34;netflix-tag\u0026#34;, \u0026#34;protocol\u0026#34;: \u0026#34;freedom\u0026#34;, \u0026#34;settings\u0026#34;: { \u0026#34;domainStrategy\u0026#34;: \u0026#34;UseIPv6\u0026#34; } } tag和routing下的ruleobject中的tag对应，经过上边的两个配置就可以使奈飞通过ipv6出站了。\n完整配置 完整的xray配置config.json如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 { \u0026#34;routing\u0026#34;: { \u0026#34;domainStrategy\u0026#34;: \u0026#34;IPIfNonMatch\u0026#34;, \u0026#34;rules\u0026#34;: [ { \u0026#34;type\u0026#34;: \u0026#34;field\u0026#34;, \u0026#34;inboundTag\u0026#34;: [ \u0026#34;api\u0026#34; ], \u0026#34;outboundTag\u0026#34;: \u0026#34;api\u0026#34; }, { \u0026#34;type\u0026#34;: \u0026#34;field\u0026#34;, \u0026#34;outboundTag\u0026#34;: \u0026#34;netflix-tag\u0026#34;, \u0026#34;domain\u0026#34;: [ \u0026#34;geosite:netflix\u0026#34; ] }, { \u0026#34;type\u0026#34;: \u0026#34;field\u0026#34;, \u0026#34;outboundTag\u0026#34;: \u0026#34;blocked\u0026#34;, \u0026#34;protocol\u0026#34;: [ \u0026#34;bittorrent\u0026#34; ] } ] }, \u0026#34;dns\u0026#34;: null, \u0026#34;inbounds\u0026#34;: [ { \u0026#34;listen\u0026#34;: null, \u0026#34;port\u0026#34;: 13103, \u0026#34;protocol\u0026#34;: \u0026#34;shadowsocks\u0026#34;, \u0026#34;settings\u0026#34;: { \u0026#34;method\u0026#34;: \u0026#34;aes-256-gcm\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;WqOQzCxMwdfeegegOK36n\u0026#34;, \u0026#34;network\u0026#34;: \u0026#34;tcp,udp\u0026#34; }, \u0026#34;streamSettings\u0026#34;: { \u0026#34;network\u0026#34;: \u0026#34;tcp\u0026#34;, \u0026#34;security\u0026#34;: \u0026#34;none\u0026#34;, \u0026#34;tcpSettings\u0026#34;: { \u0026#34;header\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;none\u0026#34; }, \u0026#34;acceptProxyProtocol\u0026#34;: false } }, \u0026#34;tag\u0026#34;: \u0026#34;inbound-13103\u0026#34;, \u0026#34;sniffing\u0026#34;: { \u0026#34;enabled\u0026#34;: true, \u0026#34;destOverride\u0026#34;: [ \u0026#34;http\u0026#34;, \u0026#34;tls\u0026#34;, \u0026#34;quic\u0026#34; ] } } ], \u0026#34;outbounds\u0026#34;: [ { \u0026#34;protocol\u0026#34;: \u0026#34;freedom\u0026#34;, \u0026#34;settings\u0026#34;: {} }, { \u0026#34;tag\u0026#34;: \u0026#34;netflix-tag\u0026#34;, \u0026#34;protocol\u0026#34;: \u0026#34;freedom\u0026#34;, \u0026#34;settings\u0026#34;: { \u0026#34;domainStrategy\u0026#34;: \u0026#34;UseIPv6\u0026#34; } }, { \u0026#34;tag\u0026#34;: \u0026#34;blocked\u0026#34;, \u0026#34;protocol\u0026#34;: \u0026#34;blackhole\u0026#34;, \u0026#34;settings\u0026#34;: {} } ], \u0026#34;stats\u0026#34;: {}, \u0026#34;reverse\u0026#34;: null, \u0026#34;fakeDns\u0026#34;: null } 下边也给出在x-ui中的配置，具体配置位置是登录x-ui后左侧菜单：面板设置，然后点击到xray配置，然后把下边的配置粘贴到配置模板中就可以了：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 { \u0026#34;api\u0026#34;: { \u0026#34;services\u0026#34;: [ \u0026#34;HandlerService\u0026#34;, \u0026#34;LoggerService\u0026#34;, \u0026#34;StatsService\u0026#34; ], \u0026#34;tag\u0026#34;: \u0026#34;api\u0026#34; }, \u0026#34;inbounds\u0026#34;: [ { \u0026#34;listen\u0026#34;: \u0026#34;127.0.0.1\u0026#34;, \u0026#34;port\u0026#34;: 62789, \u0026#34;protocol\u0026#34;: \u0026#34;dokodemo-door\u0026#34;, \u0026#34;settings\u0026#34;: { \u0026#34;address\u0026#34;: \u0026#34;127.0.0.1\u0026#34; }, \u0026#34;tag\u0026#34;: \u0026#34;api\u0026#34; } ], \u0026#34;outbounds\u0026#34;: [ { \u0026#34;protocol\u0026#34;: \u0026#34;freedom\u0026#34;, \u0026#34;settings\u0026#34;: {} }, { \u0026#34;tag\u0026#34;: \u0026#34;netflix-tag\u0026#34;, \u0026#34;protocol\u0026#34;: \u0026#34;freedom\u0026#34;, \u0026#34;settings\u0026#34;: { \u0026#34;domainStrategy\u0026#34;: \u0026#34;UseIPv6\u0026#34; } }, { \u0026#34;protocol\u0026#34;: \u0026#34;blackhole\u0026#34;, \u0026#34;settings\u0026#34;: {}, \u0026#34;tag\u0026#34;: \u0026#34;blocked\u0026#34; } ], \u0026#34;policy\u0026#34;: { \u0026#34;levels\u0026#34;: { \u0026#34;0\u0026#34;: { \u0026#34;handshake\u0026#34;: 10, \u0026#34;connIdle\u0026#34;: 100, \u0026#34;uplinkOnly\u0026#34;: 2, \u0026#34;downlinkOnly\u0026#34;: 3, \u0026#34;statsUserUplink\u0026#34;: true, \u0026#34;statsUserDownlink\u0026#34;: true, \u0026#34;bufferSize\u0026#34;: 10240 } }, \u0026#34;system\u0026#34;: { \u0026#34;statsInboundDownlink\u0026#34;: true, \u0026#34;statsInboundUplink\u0026#34;: true } }, \u0026#34;routing\u0026#34;: { \u0026#34;rules\u0026#34;: [ { \u0026#34;inboundTag\u0026#34;: [ \u0026#34;api\u0026#34; ], \u0026#34;outboundTag\u0026#34;: \u0026#34;api\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;field\u0026#34; }, { \u0026#34;type\u0026#34;: \u0026#34;field\u0026#34;, \u0026#34;outboundTag\u0026#34;: \u0026#34;netflix-tag\u0026#34;, \u0026#34;domain\u0026#34;: [ \u0026#34;geosite:netflix\u0026#34; ] } ] }, \u0026#34;stats\u0026#34;: {} } 经过上边的配置，正确的创建节点，就可以愉快的通过ipv4入站，然后通过ipv6出站去访问netflix网站了，享受解锁的快乐。当然上边的配置只是netflix才走ipv6出站，其他的网站还是通过ipv4来出站，如果想要让其他什么网站也通过ipv6出站，就需要在routing中配置ruleObject来达到目的。\nxui网页配置(另一种方法) 上边介绍的是纯手工的去对配置文件进行编辑的方式，最近xui更新后，这些配置可以在网页端进行图形化的操作，大大降低了对新手的难度，下边来看一下如何在xui网页端来对netflix由IPv6处站做配置。如果对xui还不知道如何使用的同学可以参考我的文章来安装配置xui：x-ui安装配置使用.\n出站配置 登录xui网站，菜单栏有一个xray设置一级菜单：\n点开xray设置后看到有四个tab页：基本模板、路由规则、出站和高级模板部件。在上边纯手工配置xray的时候也提到过，需要有一个outboud和一个routing，在xui的网页上其实就对应出站(outbond)以及路由规则(routing)。所以在网页端配置这两个就可以了，先来配置出站，添加一个freedom类型的节点：\n协议：freedom\n标签：全局唯一(英文)，等下要在路由规则那里进行选择\nstrategy：选择使用IPv6\n然后点击保存就创建好了一个出站规则了，此时出站规则并没有任何路由规则引用到它，所以并不会有任何作用，接下来就需要在路由规则中进行引用，使特定网站使用IPv6进行出站访问。\n路由规则配置 如下图，添加一个路由规则，Outbound Tag就是刚才添加的出站配置的标签，是唯一的，因为是要设置netflix使用IPv6，所以Domain那项配置就把netflix的域名规则写进去，这里的配置是 且 的关系，所以如果需要更灵活的配置可以自己添加。例如我只想某个用户在访问netflix的时候使用IPv6出站，那么就可以在User里把这个用户的信息配置进去，具体用户是什么，是我们在添加节点的时候每个节点都要求填一个邮箱，邮箱即用户。\n配置好后就可以重启一下xray，规则就生效了。\n好了本文的教程就到这里，祝大家都可以成功的搭建成功。\n","date":"2023-08-13T15:13:49Z","image":"https://images.iminling.com/app/hide.php?key=a3J1MHlDOU5KWjlodHdVUnJyQm5EckxmcmwvMmVoVjRqdHNheGcveTM3ZUlqTWRjb0IyUCtZM0x6cUFzbFFQb2MvS1QrLzQ9","permalink":"https://konghanghang.github.io/iminling-pages/2023/xray-use-ipv6-unlock-netflix/","title":"xray分流使用IPV6解锁netflix"},{"content":"日常开发中都有使用到docker，一直对docker的网络不是很清楚，所以花了点时间了解一下docker的网络，这里对了解的知识进行一下总结。\n当我们安装好docker后，docker默认给我们创建了3个网络，如下：\n1 2 3 4 5 ubuntu@VM-20-3-ubuntu:~$ docker network ls NETWORK ID NAME DRIVER SCOPE cde83331f977 bridge bridge local 0e504852d7be host host local cdc83d5d9388 none null local 分别是bridge,host和none。下边我们就来看一下这三种网络的区别。\nbridge网络 桥接网络也是docker的默认网络，当我们安装好docker后，docker会在宿主机创建一个网卡docker0：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 2: eth0: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc mq state UP group default qlen 1000 link/ether 52:54:00:ee:63:60 brd ff:ff:ff:ff:ff:ff inet 10.0.20.3/22 brd 10.0.23.255 scope global eth0 valid_lft forever preferred_lft forever inet6 fe80::5054:ff::6360/64 scope link valid_lft forever preferred_lft forever 3: docker0: \u0026lt;NO-CARRIER,BROADCAST,MULTICAST,UP\u0026gt; mtu 1500 qdisc noqueue state DOWN group default link/ether 02:42:0c:be:59:f7 brd ff:ff:ff:ff:ff:ff inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0 valid_lft forever preferred_lft forever inet6 fe80::42:cff:febe:59f7/64 scope link valid_lft forever preferred_lft forever 如上，docker0网络就是docker默认的网络，他的网关是172.17.0.1,我们可以先查看一下这个bridge网络的情况(已去除多余属性)：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 ubuntu@VM-20-3-ubuntu:~$ docker inspect bridge [ { \u0026#34;Name\u0026#34;: \u0026#34;bridge\u0026#34;, \u0026#34;Id\u0026#34;: \u0026#34;cde83331f977b86b4eaa67fe05ea18e493691fd0d3fc5edc51dec4e62a512d37\u0026#34;, \u0026#34;Created\u0026#34;: \u0026#34;2022-08-25T20:37:27.17350164+08:00\u0026#34;, \u0026#34;Scope\u0026#34;: \u0026#34;local\u0026#34;, \u0026#34;Driver\u0026#34;: \u0026#34;bridge\u0026#34;, \u0026#34;EnableIPv6\u0026#34;: false, \u0026#34;IPAM\u0026#34;: { \u0026#34;Driver\u0026#34;: \u0026#34;default\u0026#34;, \u0026#34;Options\u0026#34;: null, \u0026#34;Config\u0026#34;: [ { \u0026#34;Subnet\u0026#34;: \u0026#34;172.17.0.0/16\u0026#34;, \u0026#34;Gateway\u0026#34;: \u0026#34;172.17.0.1\u0026#34; } ] }, \u0026#34;Containers\u0026#34;: {} } ] subnet和docker0是一样的，containers那里暂时也是没有容器，当我们启动一个容器来使用默认的bridge网络的时候，这里边就会有对应的容器了。\n我们来启动一个nginx容器，然后再来查看一下这个网络：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 ubuntu@VM-20-3-ubuntu:~$ docker run -d --name nginx-test nginx:1.22.0 4ee2915a41fa9ed6e2591f852789f5762343e3de5bdabe718896778305df3569 ubuntu@VM-20-3-ubuntu:~$ docker inspect bridge [ { \u0026#34;Name\u0026#34;: \u0026#34;bridge\u0026#34;, \u0026#34;Id\u0026#34;: \u0026#34;cde83331f977b86b4eaa67fe05ea18e493691fd0d3fc5edc51dec4e62a512d37\u0026#34;, \u0026#34;Created\u0026#34;: \u0026#34;2022-08-25T20:37:27.17350164+08:00\u0026#34;, \u0026#34;Scope\u0026#34;: \u0026#34;local\u0026#34;, \u0026#34;Driver\u0026#34;: \u0026#34;bridge\u0026#34;, \u0026#34;EnableIPv6\u0026#34;: false, \u0026#34;IPAM\u0026#34;: { \u0026#34;Driver\u0026#34;: \u0026#34;default\u0026#34;, \u0026#34;Options\u0026#34;: null, \u0026#34;Config\u0026#34;: [ { \u0026#34;Subnet\u0026#34;: \u0026#34;172.17.0.0/16\u0026#34;, \u0026#34;Gateway\u0026#34;: \u0026#34;172.17.0.1\u0026#34; } ] }, \u0026#34;Containers\u0026#34;: { \u0026#34;4ee2915a41fa9ed6e2591f852789f5762343e3de5bdabe718896778305df3569\u0026#34;: { \u0026#34;Name\u0026#34;: \u0026#34;nginx-test\u0026#34;, \u0026#34;EndpointID\u0026#34;: \u0026#34;f518fa3072bbabc3de35577e5dc99570e8e3604e23a19911473b83fe90a85d73\u0026#34;, \u0026#34;MacAddress\u0026#34;: \u0026#34;02:42:ac:11:00:02\u0026#34;, \u0026#34;IPv4Address\u0026#34;: \u0026#34;172.17.0.2/16\u0026#34;, \u0026#34;IPv6Address\u0026#34;: \u0026#34;\u0026#34; } } } ] containers中已经有刚才创建的nginx的容器了。如果该容器想要和外界进行交互就需要暴露端口出来，然后外界才能和他进行网络通信，否则就只能从容器内部访问到外部，而无法从外部访问到容器内部。\n1 2 3 ubuntu@VM-20-3-ubuntu:~$ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 4ee2915a41fa nginx:1.22.0 \u0026#34;/docker-entrypoint.…\u0026#34; 2 minutes ago Up 2 minutes 80/tcp nginx-test 我们刚才的容器，内部会暴露80端口，如果我们需要和外部的端口映射，需要在启动容器的时候加上-v参数来映射端口，这里就不再演示了。\n在默认bridge网络下的容器是无法相互通过容器名称进行通信的，因为没有进行name的主机解析，如果需要让多个容器通过name进行访问，就需要我们创建自己的bridge网络了。创建命令如下：\n1 docker network create --driver bridge --subnet 192.168.0.0/16 --gateway 192.168.0.1 mynet 上边命令创建了一个mynet的桥接网络，然后在创建容器的时候使用这个网络，不同的容器间就可以使用容器名进行网络访问，创建容器命令：\n1 ubuntu@VM-20-3-ubuntu:~$ docker run -d --network mynet --name nginx-test nginx:1.22.0 通过\u0026ndash;network指定容器工作的网络。\nhost网络 host顾名思义就是和宿主机共用同一个网络，容器没有和宿主机很好的隔离，容器占用的端口就是宿主机的端口，被容器占用的端口宿主机里的程序就没办法使用，容器里可以直接访问宿主机的其他应用程序服务，无需经过其他特殊的设置。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 ubuntu@VM-20-3-ubuntu:~$ docker inspect host [ { \u0026#34;Name\u0026#34;: \u0026#34;host\u0026#34;, \u0026#34;Id\u0026#34;: \u0026#34;0e504852d7be83b42232d744a36504266c52cca3f1647eaeaa9d090117826924\u0026#34;, \u0026#34;Created\u0026#34;: \u0026#34;2022-05-20T13:41:40.594740985+08:00\u0026#34;, \u0026#34;Scope\u0026#34;: \u0026#34;local\u0026#34;, \u0026#34;Driver\u0026#34;: \u0026#34;host\u0026#34;, \u0026#34;EnableIPv6\u0026#34;: false, \u0026#34;IPAM\u0026#34;: { \u0026#34;Driver\u0026#34;: \u0026#34;default\u0026#34;, \u0026#34;Options\u0026#34;: null, \u0026#34;Config\u0026#34;: [] }, \u0026#34;Internal\u0026#34;: false, \u0026#34;Attachable\u0026#34;: false, \u0026#34;Ingress\u0026#34;: false, \u0026#34;ConfigFrom\u0026#34;: { \u0026#34;Network\u0026#34;: \u0026#34;\u0026#34; }, \u0026#34;ConfigOnly\u0026#34;: false, \u0026#34;Containers\u0026#34;: {}, \u0026#34;Options\u0026#34;: {}, \u0026#34;Labels\u0026#34;: {} } ] 我们使用host模式创建的容器也不会显示在containers里边。\nnone网络 在这种模式下，docker容器没有任何网络设置，无法访问宿主机网络，宿主机也没办法访问容器的网络，做到了很好的隔离，开发中也很少用到。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 ubuntu@VM-20-3-ubuntu:~$ docker inspect none [ { \u0026#34;Name\u0026#34;: \u0026#34;none\u0026#34;, \u0026#34;Id\u0026#34;: \u0026#34;cdc83d5d9388583dcee94758821adcd70f57825cbb05f2bcab726d484e9e9fdb\u0026#34;, \u0026#34;Created\u0026#34;: \u0026#34;2022-05-20T13:41:40.580477496+08:00\u0026#34;, \u0026#34;Scope\u0026#34;: \u0026#34;local\u0026#34;, \u0026#34;Driver\u0026#34;: \u0026#34;null\u0026#34;, \u0026#34;EnableIPv6\u0026#34;: false, \u0026#34;IPAM\u0026#34;: { \u0026#34;Driver\u0026#34;: \u0026#34;default\u0026#34;, \u0026#34;Options\u0026#34;: null, \u0026#34;Config\u0026#34;: [] }, \u0026#34;Internal\u0026#34;: false, \u0026#34;Attachable\u0026#34;: false, \u0026#34;Ingress\u0026#34;: false, \u0026#34;ConfigFrom\u0026#34;: { \u0026#34;Network\u0026#34;: \u0026#34;\u0026#34; }, \u0026#34;ConfigOnly\u0026#34;: false, \u0026#34;Containers\u0026#34;: {}, \u0026#34;Options\u0026#34;: {}, \u0026#34;Labels\u0026#34;: {} } ] 我们正常使用的话，还是bridge网络用的多一些，因为各服务都是需要相互调用的，要做到网络互通。以上就是对docker三种模式的一些总结。\n","date":"2023-08-07T21:29:16Z","image":"https://images.iminling.com/app/hide.php?key=alYxQXJQb1dGYk9kMFhXVUtHR2NKNElMWkFmL2JGekd5a09YNmNzbWJBSERqeWR2OUFTTXo1a25MZGRPS2JlKytwUFgvQWs9","permalink":"https://konghanghang.github.io/iminling-pages/2023/introduction-to-docker-network-mode/","title":"docker网络模式简介"},{"content":" Nginx (engine x) 是一个高性能的HTTP和反向代理web服务器 ，同时也提供了IMAP/POP3/SMTP服务，是个软件肯定都会多多少少有一些漏洞，所以我们需要隐藏nginx的版本号，让攻击者没那么容易很快的攻破我们的网站。 nginx官方提供了关闭显示版本号的方法，其实也很简单，只需要添加server_tokens off就可以了，server_tokens可以到http,server和location块中，我们找一个合适的位置添加进去就可以了。 添加前 没有添加之前请求网站信息如下： ```bash $ curl -I https://www.iminling.com HTTP/2 200 server: nginx/2.24.2 date: Sun, 06 Aug 2023 03:02:12 GMT content-type: text/html; charset=UTF-8 x-powered-by: PHP link: ; rel=\"https://api.w.org/\" ``` 如上，server中会把nginx的完整版本号信息展示出来。\n添加server_token 我这里把server_token添加到server块中，如下：\nserver { listen 8443 ssl http2; server_name www.iminling.com; index index.php index.html index.htm; root /var/www/html; server_tokens off; # 添加server_tokens屏蔽显示版本号 include conf.d/ssl_params.conf; location / { try_files $uri $uri/ /index.php$is_args$args; } } 如上，在server中添加server_tokens为off，然后我们再去验证一下。\n添加后 再来看一下请求网站的信息：\n1 2 3 4 5 6 7 $ curl -I https://www.iminling.com HTTP/2 200 server: nginx date: Sun, 06 Aug 2023 03:02:31 GMT content-type: text/html; charset=UTF-8 x-powered-by: PHP link: \u0026lt;https://www.iminling.com/wp-json/\u0026gt;; rel=\u0026#34;https://api.w.org/\u0026#34; 如上，server里只显示了nginx。\n经过上边的配置就可以隐藏nginx的版本号了。\n","date":"2023-08-05T19:21:16Z","image":"https://images.iminling.com/app/hide.php?key=eEZmbmFBSW14MCtoRHpiR0RHeW52cHZqTmNJRU1Zblg0cCtiYWo1Z3VSbHNiNUY2cHF0OHJKZHlpbGVCQUpGRVRMWmRwYXM9","permalink":"https://konghanghang.github.io/iminling-pages/2023/nginx-hides-version-number/","title":"nginx配置隐藏版本号提升安全"},{"content":"当我们只有一个vps，又想部署网站同时又想搭建代理，当然两个程序可以分开占用端口，做到不冲突，但是感觉不怎么优雅，所以想要让两个程序都去共用一个443端口，这样子网站可以使用域名并开启ssl，代理也可以使用443(心理作用，感觉代理走443会更好一些，毕竟代理使用了ssl，走其他端口怪怪的)。下面就开启折腾之路。\n代理协议 目前比较稳定的协议要数reality了，所以自己搭建的代理也是使用reality，reality可以使用自己的证书，也可以使用其他域名的证书：就是宣传的“偷证书”。既然我的网站要使用443开启ssl，那我当时使用自己的证书最方便，而且延迟最小。\n证书申请 安装reality可以使用xui来安装，具体的xui安装可以参考我的文章：x-ui安装配置使用。xui本身可以帮助我们申请证书，如果不想使用xui的证书申请，还可以参考我的另一篇文章使用certbot来申请证书：docker部署certbot申请Let’s Encrypt证书，我这里就使用certbot来申请证书。\n站点部署 这里是为了演示，所以我这里就只启动nginx，然后配置ssl，对域名启用ssl。nginx我使用的是docker来启动的，具体的目录如下,所在的路径是：/root/images/nginx\n1 2 3 4 5 6 7 8 9 10 11 ├── README.md ├── conf │ ├── conf.d │ └── nginx.conf ├── docker-compose.yaml ├── html │ └── index.html └── logs ├── 1.txt ├── access.log ├── error.log\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt; conf目录下是站点的配置文件，nginx.conf是默认的，它包含了conf.d目录为的所有.conf结尾的文件。\nnginx.conf nginx.conf的配置如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 user nginx; worker_processes auto; error_log /var/log/nginx/error.log notice; pid /var/run/nginx.pid; events { worker_connections 1024; } http { include /etc/nginx/mime.types; default_type application/octet-stream; log_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; access_log /var/log/nginx/access.log main; sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; include /etc/nginx/conf.d/*.conf; } 很简单就是默认配置。\nweb.conf web.conf是在conf.d目录下的，就是我们部署的站点的配置文件，如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 # 设置 HTTP 服务器，将所有 HTTP 请求都重定向到 HTTPS server { listen 80; server_name test.xxx.me; # 重定向所有 HTTP 请求到 HTTPS location / { return 301 https://$server_name$request_uri; } } # 设置 HTTPS 服务器 server { listen 443 ssl http2; server_name test.xxx.me; # ======域名，需要改成自己的========= # SSL 证书和密钥文件的路径 ssl_certificate /etc/letsencrypt/ssl/xx/fullchain.pem; # ======自己的证书文件路径========= ssl_certificate_key /etc/letsencrypt/ssl/xx/privkey.pem;# ====自己的证书文件路径======= # 可选：设置 SSL 会话缓存 ssl_session_cache shared:SSL:10m; ssl_session_timeout 10m; # 可选：设置 SSL 协议和加密算法 ssl_protocols TLSv1.2 TLSv1.3; ssl_ciphers \u0026#34;ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384\u0026#34;; # 可选：开启 OCSP Stapling，提高 SSL 握手性能 ssl_stapling on; ssl_stapling_verify on; ssl_trusted_certificate /etc/letsencrypt/ssl/xx/fullchain.pem; # ======自己的证书文件路径======= # 可选：设置 Content Security Policy（内容安全策略）头 # add_header Content-Security-Policy \u0026#34;default-src \u0026#39;self\u0026#39;;\u0026#34; always; # 可选：设置访问日志 access_log /var/log/nginx/test.access.log; error_log /var/log/nginx/test.error.log; location / { root /usr/share/nginx/html; index index.html index.htm; } } 访问80端口强制转到443端口，证书使用的是docker中的使用certbot申请的证书。证书的路径是和下边的docker-compose.yaml中挂载的目录相关的，xx只是为了在nginx容器中找到正确的目录。\ndocker-compose.yaml 具体内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 version: \u0026#39;3\u0026#39; networks: mynet: external: true services: nginx: image: nginx:1.22.0 restart: unless-stopped container_name: nginx volumes: - ./conf/nginx.conf:/etc/nginx/nginx.conf - ./conf/conf.d:/etc/nginx/conf.d - ./html:/usr/share/nginx/html - ./logs:/var/log/nginx - /root/images/certbot/certs:/etc/letsencrypt - /root/images/certbot/certs/live/test.ml520.me:/etc/letsencrypt/ssl/xx networks: - mynet ports: - 80:80 - 443:443 这里映射了letsencrypt的两个目录，配合nginx，找到对应的证书路径，如果不是在docker中就按找实际的证书路径处理就行了。\nindex.html index.html就是一个非常简单的网页了，里边的内容很随意,就是一个欢迎语。\n这时候我们把nginx启动起来，通过域名访问我们的网站看是否已经可以正常使用https。\n代理配置 代理的配置这里就简单带过，通过x-ui或者直接安装xray-core来运行。也可以通过我的镜像：xray，直接使用docker安装，参考文章：xray配置使用reality\nxray的配置文件如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 { \u0026#34;log\u0026#34;: { \u0026#34;loglevel\u0026#34;: \u0026#34;warning\u0026#34;, \u0026#34;access\u0026#34;: \u0026#34;/var/log/xray/access.log\u0026#34;, \u0026#34;error\u0026#34;: \u0026#34;/var/log/xray/error.log\u0026#34; }, \u0026#34;api\u0026#34;: { \u0026#34;services\u0026#34;: [ \u0026#34;HandlerService\u0026#34;, \u0026#34;LoggerService\u0026#34;, \u0026#34;StatsService\u0026#34; ], \u0026#34;tag\u0026#34;: \u0026#34;api\u0026#34; }, \u0026#34;inbounds\u0026#34;: [ { \u0026#34;listen\u0026#34;: null, \u0026#34;port\u0026#34;: 8443, \u0026#34;protocol\u0026#34;: \u0026#34;vless\u0026#34;, \u0026#34;settings\u0026#34;: { \u0026#34;clients\u0026#34;: [ { \u0026#34;id\u0026#34;: \u0026#34;0c41318a-32b6-4017-9938-4033bf261234\u0026#34;, \u0026#34;flow\u0026#34;: \u0026#34;xtls-rprx-vision\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;reality@xray.com\u0026#34; } ], \u0026#34;decryption\u0026#34;: \u0026#34;none\u0026#34; }, \u0026#34;streamSettings\u0026#34;: { \u0026#34;network\u0026#34;: \u0026#34;tcp\u0026#34;, \u0026#34;security\u0026#34;: \u0026#34;reality\u0026#34;, \u0026#34;realitySettings\u0026#34;: { \u0026#34;show\u0026#34;: false, \u0026#34;dest\u0026#34;: \u0026#34;www.microsoft.com:443\u0026#34;, \u0026#34;xver\u0026#34;: 1, \u0026#34;serverNames\u0026#34;: [ \u0026#34;www.microsoft.com\u0026#34; ], \u0026#34;privateKey\u0026#34;: \u0026#34;uPPcl9806d81DMdlojRB_ps78jrxNpT0wcG0ueOmD69\u0026#34;, \u0026#34;shortIds\u0026#34;: [ \u0026#34;6ba85179e30d4fc2\u0026#34; ] } }, \u0026#34;sniffing\u0026#34;: { \u0026#34;enabled\u0026#34;: true, \u0026#34;destOverride\u0026#34;: [ \u0026#34;http\u0026#34;, \u0026#34;tls\u0026#34; ] } } ], \u0026#34;outbounds\u0026#34;: [ { \u0026#34;tag\u0026#34;: \u0026#34;common\u0026#34;, \u0026#34;protocol\u0026#34;: \u0026#34;freedom\u0026#34; } ], \u0026#34;routing\u0026#34;: { \u0026#34;rules\u0026#34;: [ { \u0026#34;type\u0026#34;: \u0026#34;field\u0026#34;, \u0026#34;outboundTag\u0026#34;: \u0026#34;common\u0026#34;, \u0026#34;network\u0026#34;: \u0026#34;udp,tcp\u0026#34; } ] }, \u0026#34;policy\u0026#34;: { \u0026#34;statsInboundUplink\u0026#34;: true, \u0026#34;statsInboundDownlink\u0026#34;: true, \u0026#34;statsOutboundUplink\u0026#34;: true, \u0026#34;statsOutboundDownlink\u0026#34;: true }, \u0026#34;dns\u0026#34;: null, \u0026#34;transport\u0026#34;: null, \u0026#34;stats\u0026#34;: null, \u0026#34;reverse\u0026#34;: null, \u0026#34;fakeDns\u0026#34;: null } 这里先使用偷微软的证书进行验证。不出意外就已经ok了，此时xray用的8443，nginx使用的443，两个单独占用端口，是完全可以正常访问的。\n共用端口 经过上边的准备，现在我们就可以开始来合并端口了，首先是修改nginx的配置，原来的nginx容器是暴露了80和443端口，现在我们需要把443端口让给xray，所以需要修改docker-compose.yaml文件，改变端口映射，让它的https使用18443，并且需要修改nginx的web.conf配置文件。\ndocker-compose.yaml 内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 version: \u0026#39;3\u0026#39; networks: mynet: external: true services: nginx: image: nginx:1.22.0 restart: unless-stopped container_name: nginx volumes: - ./conf/nginx.conf:/etc/nginx/nginx.conf - ./conf/conf.d:/etc/nginx/conf.d - ./html:/usr/share/nginx/html - ./logs:/var/log/nginx - ./../naiveproxy/conf/cert:/ssl - ./../wordpress/html:/wordpress - /root/images/certbot/certs:/etc/letsencrypt - /root/images/certbot/certs/live/test.ml520.me:/etc/letsencrypt/ssl/xx networks: - mynet ports: - 80:80 - 18443:18443 # 主要是修改这里，改变端口映射 主要是修改了端口，由原来的443改成18443，把443端口让给xray使用。\n改了开放端口后，还需要修改web.conf，把监听的443变成18443以及一些其他配置。\nweb.conf 先放出配置：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 # 设置 HTTP 服务器，将所有 HTTP 请求都重定向到 HTTPS server { listen 80; server_name test.xxx.me; # 重定向所有 HTTP 请求到 HTTPS location / { return 301 https://$server_name$request_uri; } } # 设置 HTTPS 服务器 server { listen 18443 ssl http2 proxy_protocol; # =======修改了这里====== server_name test.xxx.me; set_real_ip_from 127.0.0.1; # ======添加了这里======= real_ip_header proxy_protocol; # ======添加了这里====== # SSL 证书和密钥文件的路径 ssl_certificate /etc/letsencrypt/ssl/xx/fullchain.pem; # 证书文件，通常不区分扩展名，证书文件需要使用fullchain（全SSL证书链） ssl_certificate_key /etc/letsencrypt/ssl/xx/privkey.pem; # 私钥文件，通常不区分扩展名 # 可选：设置 SSL 会话缓存 ssl_session_cache shared:SSL:10m; ssl_session_timeout 10m; # 可选：设置 SSL 协议和加密算法 ssl_protocols TLSv1.2 TLSv1.3; ssl_ciphers \u0026#34;ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384\u0026#34;; # 可选：开启 OCSP Stapling，提高 SSL 握手性能 ssl_stapling on; ssl_stapling_verify on; ssl_trusted_certificate /etc/letsencrypt/ssl/xx/fullchain.pem; # 可选：设置访问日志 access_log /var/log/nginx/test.access.log; error_log /var/log/nginx/test.error.log; location / { root /usr/share/nginx/html; index index.html index.htm; } } 主要是修改了listen的配置，添加了proxy_protocol,另外添加了set_real_ip_from和real_ip_header。\n接下来就是修改xray的配置文件了。\nxray配置 主要是修改config.json文件，从原来的8443换成可，以及域名配置，详细改动如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 { \u0026#34;log\u0026#34;: { \u0026#34;loglevel\u0026#34;: \u0026#34;warning\u0026#34;, \u0026#34;access\u0026#34;: \u0026#34;/var/log/xray/access.log\u0026#34;, \u0026#34;error\u0026#34;: \u0026#34;/var/log/xray/error.log\u0026#34; }, \u0026#34;api\u0026#34;: { \u0026#34;services\u0026#34;: [ \u0026#34;HandlerService\u0026#34;, \u0026#34;LoggerService\u0026#34;, \u0026#34;StatsService\u0026#34; ], \u0026#34;tag\u0026#34;: \u0026#34;api\u0026#34; }, \u0026#34;inbounds\u0026#34;: [ { \u0026#34;listen\u0026#34;: null, \u0026#34;port\u0026#34;: 443, \u0026#34;protocol\u0026#34;: \u0026#34;vless\u0026#34;, \u0026#34;settings\u0026#34;: { \u0026#34;clients\u0026#34;: [ { \u0026#34;id\u0026#34;: \u0026#34;0c41234a-32b6-4017-9938-4033bf26b948\u0026#34;, \u0026#34;flow\u0026#34;: \u0026#34;xtls-rprx-vision\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;reality@xray.com\u0026#34; } ], \u0026#34;decryption\u0026#34;: \u0026#34;none\u0026#34; }, \u0026#34;streamSettings\u0026#34;: { \u0026#34;network\u0026#34;: \u0026#34;tcp\u0026#34;, \u0026#34;security\u0026#34;: \u0026#34;reality\u0026#34;, \u0026#34;realitySettings\u0026#34;: { \u0026#34;show\u0026#34;: false, \u0026#34;dest\u0026#34;: \u0026#34;nginx:18443\u0026#34;, # 这里目标网站要换成我们的nginx里的地址，这里使用了容器名加ssl监听端口 \u0026#34;xver\u0026#34;: 1, # 该参数我也不知道是什么意思 \u0026#34;serverNames\u0026#34;: [ \u0026#34;test.xxx.me\u0026#34; # 域名就换成自己的域名 ], \u0026#34;privateKey\u0026#34;: \u0026#34;uPPcl3v45d81DMdlojRB_ps78jrxNpT0wcG0ueOmD12\u0026#34;, \u0026#34;shortIds\u0026#34;: [ \u0026#34;6ba85179e30d4fc2\u0026#34; ] } }, \u0026#34;sniffing\u0026#34;: { \u0026#34;enabled\u0026#34;: true, \u0026#34;destOverride\u0026#34;: [ \u0026#34;http\u0026#34;, \u0026#34;tls\u0026#34; ] } } ], \u0026#34;outbounds\u0026#34;: [ { \u0026#34;tag\u0026#34;: \u0026#34;common\u0026#34;, \u0026#34;protocol\u0026#34;: \u0026#34;freedom\u0026#34; } ], \u0026#34;routing\u0026#34;: { \u0026#34;rules\u0026#34;: [ { \u0026#34;type\u0026#34;: \u0026#34;field\u0026#34;, \u0026#34;outboundTag\u0026#34;: \u0026#34;common\u0026#34;, \u0026#34;network\u0026#34;: \u0026#34;udp,tcp\u0026#34; } ] }, \u0026#34;policy\u0026#34;: { \u0026#34;statsInboundUplink\u0026#34;: true, \u0026#34;statsInboundDownlink\u0026#34;: true, \u0026#34;statsOutboundUplink\u0026#34;: true, \u0026#34;statsOutboundDownlink\u0026#34;: true }, \u0026#34;dns\u0026#34;: null, \u0026#34;transport\u0026#34;: null, \u0026#34;stats\u0026#34;: null, \u0026#34;reverse\u0026#34;: null, \u0026#34;fakeDns\u0026#34;: null } 如上，改动不大，主要是dest、xver和server_name。另外需要修改xray的docker-compose.yaml,把原来的8443端口改成443端口，并重新build启动。\n验证 经过上边的改变后，通过域名就可以访问到项目，并且reality也同时在监听443，代理工具的配置改成443端口，域名也改成自己的就可以正常使用了。我这里就不再贴图了。完美的实现网站和xray共存，xray也成功的偷了自己的证书。\n最后祝大家都能成功配置。\n参考：\nsteal_yourself\n","date":"2023-07-31T06:30:46Z","image":"https://images.iminling.com/app/hide.php?key=TUVLUjRhOHdSS21VVjh4dDdmbElGUVhHZHRFRlR3c3h1R2F2Qi8wOEg0V3V6cGZReGx5NUs1Z3FQYjRhVXdCdm14WWVma2c9","permalink":"https://konghanghang.github.io/iminling-pages/2023/both-xray-reality-website-use-443/","title":"xray搭建reality和网站共用443端口启用网站SSL"},{"content":"最近想给域名申请一个免费的证书，经过查询找到了Let\u0026rsquo;s Encrypt，并且可以使用certbot来申请，因为一直在使用docker,所以就想着看是否可以使用docker来进行证书的申请，于是就开启了此次的折腾之路：使用docker部署certbot申请Let\u0026rsquo;s Encrypt证书。\n安装certbot certbot的安装方式有很多种，官方也有一些系统的安装文档，可以根据官方的安装文档来直接安装到对应的操作系统上：installation，非常详细。官方推荐的方式是通过snap的形式来安装，另外还有docker、pip、第三放发行版本以及certbot-auto(官方已经标示为过期)。\n申请形式 申请证书的形式也有很多:\napache{#id9.reference.internal} Webroot{#id10.reference.internal} Nginx{#id11.reference.internal} Standalone{#id12.reference.internal} DNS Plugins{#id13.reference.internal} Manual{#id14.reference.internal} Combining plugins{#id15.reference.internal} Third-party plugins{#id16.reference.internal} 其中一些方式要配合开启80和443端口来实现，还需要进行域名解析，我这里就选择使用DNS Plugins的形式来进行申请，因为域名在cloudflare，所以就使用certbot-dns-cloudflare插件来进行申请，文档地址：Welcome to certbot-dns-cloudflare’s documentation!。\n申请准备 docker文件的目录如下：\n1 2 3 4 5 6 ├── certs //存放证书 ├── conf │ ├── cloudflare.ini //配置文件 ├── logs //日志 └── docker-compose.yml //docker-compse文件 └── .env //环境变量信息 certs 目录是映射到docker容器中的，存放证书文件。\ncloudflare.ini 该要存放cloudflare的api token,这里使用的是自己创建的token，配置文件内容如下：\ndns_cloudflare_api_token = your_cloudflare_api_key 具体的生成方式看下图：\n选择创建令牌：\n区域中选择DNS给一个编辑权限，然后就是区域字段选择自己的域名，我这里是给每个域名单独的token，所以需要选择一个域名，可以根据自己需求选择。\nlogs logs中是存在certbot执行日志的地方。\ndocker-compose.yaml docker-compose.yaml文件内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 version: \u0026#34;3\u0026#34; services: certbot: image: certbot/dns-cloudflare:v2.4.0 container_name: certbot env_file: - .env volumes: - ./certs:/etc/letsencrypt - ./logs:/var/log/letsencrypt - ./conf/cloudflare.ini:/secrets/cloudflare.ini # dry run # command: certonly --dns-cloudflare --agree-tos --non-interactive --dns-cloudflare-credentials /secrets/cloudflare.ini --email ${CERTBOT_EMAIL} --dns-cloudflare-propagation-seconds 20 -d ${CERTBOT_DOMAIN} --dry-run # issue --force-renewal command: certonly --dns-cloudflare --agree-tos --non-interactive --dns-cloudflare-credentials /secrets/cloudflare.ini --email ${CERTBOT_EMAIL} --dns-cloudflare-propagation-seconds 20 -d ${CERTBOT_DOMAIN} # renew # command: renew --dns-cloudflare --no-self-upgrade --agree-tos --non-interactive --dns-cloudflare-credentials /secrets/cloudflare.ini --dns-cloudflare-propagation-seconds 20 使用.env配置文件，然后把certbot中的/etc/letsencrypt目录映射到容器外部的certs目录，另外就是日志以及cloudflare的配置文件。\n执行的命令有三个，dry-run是测试申请功能是否正常，如果正常则使用issue的命令进行正常申请，因为申请的证书只有三个月的有效期，所以需要进行续期，续期使用renew的命令。\n\u0026ndash;agree-tos 同意tos(term of service)\n\u0026ndash;non-interactive 非交互式的\n\u0026ndash;dns-cloudflare-credentials 指定cloudflare的token文件位置\n\u0026ndash;eamil 邮箱\n\u0026ndash;dns-cloudfalre-propagation-seconds 等待时间\n-d 指定需要申请证书的域名，如果有多个域名则指定多个-d参数。如果需要申请泛域名证书，则使用*.xxx.com，生成的证书会在xxx.com目录下。\n.env env文件是一些配置信息，如上边的docker-compose.yaml文件中有两个动态的参数，一个是邮箱，另一个是申请证书的域名，我们就是在.env文件中指定的，内容如下：\nCERTBOT_DOMAIN=your_domain_name CERTBOT_EMAIL=your_email 指定邮箱和域名就可以了。\n申请 经过上边的文件准备，接下来就可以开始申请了，使用docker compose up 来进行申请。申请后的证书就在certs目录下。\n1 2 3 4 5 6 7 ├── 1.txt ├── accounts ├── archive ├── live ├── renewal ├── renewal-hooks └── ssl 证书文件在live下。然后我们就可以在nginx中使用我们申请的证书文件了。\n续期 证书三个月的有效期，在快要过期的时候需要进行续期，续期则使用docker-compose.yaml文件中的续期命令就可以了。大家也可以做一个corn定时任务来进行定期续期。\n最后祝大家申请顺利。\n","date":"2023-07-30T00:21:32Z","image":"https://images.iminling.com/app/hide.php?key=UVQ4dnZwSDJWNWNTTFNwWXo3QUxlM2wvcFhCdGEyU1diN0lUbGVKZ0gxQXExdFFJV2FIazdvVEorM0Vsak5xWFNDQ1FVNVU9","permalink":"https://konghanghang.github.io/iminling-pages/2023/docker-use-certbot-apply-lets-encrypt/","title":"docker部署certbot申请Let’s Encrypt证书"},{"content":"在默认情况下，docker默认只是配置了ipv4地址，并没有ipv6地址，需要我们手动的去进行ipv6地址配置。下面就介绍一下容器支持ipv6的一种方式。\ndocker启用ipv6 具体的方式我们先参考docker的官方文档：Enable IPv6 support,启用docker对ipv6的支持。需要修改daemon.json文件，具体位置为/etc/docker/目录下，如果没有则自己创建daemon.json,添加以下内容：\n{ \u0026ldquo;experimental\u0026rdquo;: true, \u0026ldquo;ip6tables\u0026rdquo;: true }\n然后对docker进行重启。systemctl restart docker\n创建网络 我安装docker后都会自己创建一个桥接网络已方便启动的各个容器之间的网络通信。创建网络的命令如下：\n1 docker network create --driver bridge --subnet 192.168.0.0/16 --gateway 192.168.0.1 mynet 如上创建了一个名字为mynet的网络，可以使用docker inspect来查看这个网络：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 root@us-la:~# docker inspect mynet [ { \u0026#34;Name\u0026#34;: \u0026#34;mynet\u0026#34;, \u0026#34;Id\u0026#34;: \u0026#34;914c2a3a0a6ae0bdc0b8d51ba4782b6d232e6c978f2b0596fc4b7938d6c72ddd\u0026#34;, \u0026#34;Created\u0026#34;: \u0026#34;2022-08-21T09:19:48.858428501Z\u0026#34;, \u0026#34;Scope\u0026#34;: \u0026#34;local\u0026#34;, \u0026#34;Driver\u0026#34;: \u0026#34;bridge\u0026#34;, \u0026#34;EnableIPv6\u0026#34;: false, \u0026#34;IPAM\u0026#34;: { \u0026#34;Driver\u0026#34;: \u0026#34;default\u0026#34;, \u0026#34;Options\u0026#34;: {}, \u0026#34;Config\u0026#34;: [ { \u0026#34;Subnet\u0026#34;: \u0026#34;192.168.0.0/16\u0026#34;, \u0026#34;Gateway\u0026#34;: \u0026#34;192.168.0.1\u0026#34; } ] }, \u0026#34;Internal\u0026#34;: false, \u0026#34;Attachable\u0026#34;: false, \u0026#34;Ingress\u0026#34;: false, \u0026#34;ConfigFrom\u0026#34;: { \u0026#34;Network\u0026#34;: \u0026#34;\u0026#34; }, \u0026#34;ConfigOnly\u0026#34;: false, \u0026#34;Containers\u0026#34;: { \u0026#34;edfd85b3884679256388f3c13afcd1774ac282a34de2438191bdad824a68f765\u0026#34;: { \u0026#34;Name\u0026#34;: \u0026#34;nginx\u0026#34;, \u0026#34;EndpointID\u0026#34;: \u0026#34;eafe61ed19613cfd2a7f56ee1737987d907a26210f0de557499fe4e6c1171e9c\u0026#34;, \u0026#34;MacAddress\u0026#34;: \u0026#34;02:42:c0:a8:00:02\u0026#34;, \u0026#34;IPv4Address\u0026#34;: \u0026#34;192.168.0.2/16\u0026#34;, \u0026#34;IPv6Address\u0026#34;: \u0026#34;\u0026#34; } }, \u0026#34;Options\u0026#34;: {}, \u0026#34;Labels\u0026#34;: {} } ] 这个网络只支持ipv4，我们可以ping一下v6看看：\n1 2 3 root@us-la:~# docker run --rm -it --net mynet busybox ping -6 -c4 ipv6-test.com PING ipv6-test.com (2001:41d0:701:1100::29c8): 56 data bytes ping: sendto: Cannot assign requested address 如果我们需要支持ipv6，需要创建一个ipv6网络。\n创建ipv6网络 用以下命令来创建一个ipv6网络：\n1 2 docker network create --ipv6 --subnet=\u0026#34;2001:db8:1::/64\u0026#34; --subnet=\u0026#34;192.168.0.0/24\u0026#34; mynet 9db7d457fd11f8c7c4256a1f4b2e00085d537f34e15dd0b0636bc00d4aa6d234 再次检查 网络：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 root@WIKIHOST-221108EU1RTF:~/images# docker network ls NETWORK ID NAME DRIVER SCOPE 9a75cccf2d9a bridge bridge local 5677c5bdadce host host local 9db7d457fd11 mynet bridge local 86ce569ad194 none null local root@1RTF:~/images# docker inspect mynet [ { \u0026#34;Name\u0026#34;: \u0026#34;mynet\u0026#34;, \u0026#34;Id\u0026#34;: \u0026#34;9db7d457fd11f8c7c4256a1f4b2e00085d537f34e15dd0b0636bc00d4aa6d234\u0026#34;, \u0026#34;Created\u0026#34;: \u0026#34;2023-07-12T09:48:08.273299482-04:00\u0026#34;, \u0026#34;Scope\u0026#34;: \u0026#34;local\u0026#34;, \u0026#34;Driver\u0026#34;: \u0026#34;bridge\u0026#34;, \u0026#34;EnableIPv6\u0026#34;: true, \u0026#34;IPAM\u0026#34;: { \u0026#34;Driver\u0026#34;: \u0026#34;default\u0026#34;, \u0026#34;Options\u0026#34;: {}, \u0026#34;Config\u0026#34;: [ { \u0026#34;Subnet\u0026#34;: \u0026#34;192.168.0.0/24\u0026#34; }, { \u0026#34;Subnet\u0026#34;: \u0026#34;2001:db8:1::/64\u0026#34; } ] }, \u0026#34;Internal\u0026#34;: false, \u0026#34;Attachable\u0026#34;: false, \u0026#34;Ingress\u0026#34;: false, \u0026#34;ConfigFrom\u0026#34;: { \u0026#34;Network\u0026#34;: \u0026#34;\u0026#34; }, \u0026#34;ConfigOnly\u0026#34;: false, \u0026#34;Containers\u0026#34;: {}, \u0026#34;Options\u0026#34;: {}, \u0026#34;Labels\u0026#34;: {} } ] 多了一个ipv6的子网。\n容器支持ipv6 docker run 使用docker run命令运行容器的时候只需要加上\u0026ndash;net 就可以使用我们创建的网络了：\n1 2 3 4 5 root@U1RTF:~# docker run --rm -it --net mynet busybox ping -6 -c4 ipv6-test.com PING ipv6-test.com (2001:41d0:701:1100::29c8): 56 data bytes 64 bytes from 2001:41d0:701:1100::29c8: seq=0 ttl=45 time=249.606 ms 64 bytes from 2001:41d0:701:1100::29c8: seq=1 ttl=45 time=249.622 ms 64 bytes from 2001:41d0:701:1100::29c8: seq=2 ttl=45 time=249.691 ms 通过上边命令可以发现已经支持了ipv6了。\ndocker compose 编写docker-compose.yaml文件 ，使用刚才创建的网络。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 version: \u0026#39;3\u0026#39; networks: mynet: external: true services: xray: image: teddysun/xray restart: unless-stopped container_name: xray environment: # 自定义host - XRAY_HOST=${XRAY_HOST} ports: - 13100:13100 networks: - mynet volumes: - ./log:/var/log/xray - ./conf/config.json:/etc/xray/config.json 运行上边的xray后再执行ping v6，也是可以正常ping通的。\n至次，我们已经可以给docker容器分配ipv6地址了，以上就是折腾过程，记录一下。\n","date":"2023-07-15T21:34:56Z","permalink":"https://konghanghang.github.io/iminling-pages/2023/docker-container-configuration-ipv6/","title":"docker容器配置ipv6"},{"content":"极光面板是一个多服务器端口租用管理面板，你可以添加多台服务器及端口，并将其分配给任意注册用户，租户则可以很方便地使用被分配的端口来完成各种操作。支持IPv4以及IPv6。github地址：极光面板。\n准备工作 在正式安装极光面板之前需要在要安装的机器上准备以下工作：\n安装docker和docker-compose, 参考：docker安装 生成ssh密钥。如果使用密码连接就不用生成 ssh密钥生成：\n1 2 3 4 # 如果面板服务器并没有已经生成好的 ssh 密钥 ssh-keygen -t rsa -b 4096 -C \u0026#34;your_email@example.com\u0026#34; # 后面一直回车，跳过设置 passphase 即可 # 然后还需要将面板服务器 ~/.ssh/id_rsa.pub 里面的内容复制到每一台被控机的 ~/.ssh/authorized_keys 文件中去。 准备工作好了以后就可以安装了。\n安装 使用官方的安装命令：\n1 2 3 mkdir -p ~/aurora \u0026amp;\u0026amp; cd ~/aurora \u0026amp;\u0026amp; wget https://raw.githubusercontent.com/Aurora-Admin-Panel/deploy/main/docker-compose.yml -O docker-compose.yml \u0026amp;\u0026amp; docker compose up -d # 创建管理员用户（密码必须设置8位以上，否则无法登陆） docker-compose exec backend python app/initial_data.py 首先创建aurara目录，然后把官方的docker-compose.yaml文件下载下来，直接启动就可以了。\n之后可以访问 http://你的IP:8000 进入面板。\n之后就是添加机器以及添加端口转发。\n迁移 使用了一段时间后，想把面板迁移到另一台机器，已经配置好的端口转发不想再配置一遍，所以就需要使用到迁移功能。迁移的步骤也比较简单，首先是要把原面板中的数据导出来，执行命令要在aurora目录下进行：\n1 2 # docker-compose exec -T postgres pg_dump -d aurora -U [数据库用户名，默认aurora] -c \u0026gt; data.sql docker compose exec -T postgres pg_dump -d aurora -U aurora -c \u0026gt; data.sql 然后把导出的data.sql传到新的要安装面板的机器上，在那边用同样的方法先安装面板(把上边的安装步骤完整的走一遍)，然后根据官方的迁移指引，在新安装面板的机器上的aurora目录执行以下命令：\n1 2 3 4 5 6 7 8 # 首先先把所有服务停下 docker compose down # 只启动数据库服务 docker compose up -d postgres # 执行数据恢复 docker compose exec -T postgres psql -d aurora -U [数据库用户名，默认aurora] \u0026lt; data.sql # 然后正常启动所有服务 docker compose up -d 等到所有容器都起来的时候，可以继续访问 http://你的IP:8000 进入面板。查看相关的数据是否也迁移过来了。安照步骤来我是已经可以正常迁移的。\n","date":"2023-06-09T22:08:05Z","image":"https://images.iminling.com/app/hide.php?key=VE8yR2psZGRDY05xQlZsRmlJUzB5cTVjcERqTGZnTVNjNHFiU2g5SjJvazNMbUxNRjcrTFd3Si9PdDhTd3ViTGJBRHErTzg9","permalink":"https://konghanghang.github.io/iminling-pages/2023/jiguang-pannel-install-and-migrate/","title":"极光面板安装及迁移"},{"content":"记录一下安装docker的过程，具体的安装步骤都是参考docker的官方网站进行的安装。\nubuntu安装 卸载旧版 执行下边的命令\n1 2 3 4 5 ubuntu@VM-20-3-ubuntu:~$ sudo apt-get remove docker docker-engine docker.io containerd runc Reading package lists... Done Building dependency tree Reading state information... Done E: Unable to locate package docker-engine 执行上边的命令清除以前的安装。\n设置源 执行以下命令：\n1 2 3 4 5 6 7 8 ubuntu@VM-20-3-ubuntu:~$ sudo apt-get update ubuntu@VM-20-3-ubuntu:~$ sudo apt-get install \\ ca-certificates \\ curl \\ gnupg \\ lsb-release # 添加docker官方GPG key ubuntu@VM-20-3-ubuntu:~$ curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc 执行 1 2 3 4 ubuntu@VM-20-3-ubuntu:~$ echo \\ \u0026#34;deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \\ $(. /etc/os-release \u0026amp;\u0026amp; echo \u0026#34;$VERSION_CODENAME\u0026#34;) stable\u0026#34; | \\ sudo tee /etc/apt/sources.list.d/docker.list \u0026amp;gt; /dev/null 设置安装源。\n安装 先更新刚才安装的源，然后就可以执行安装了：\n1 2 3 4 # 更新 sudo apt-get update # 安装 sudo apt-get install docker-ce docker-ce-cli containerd.io docker-compose-plugin 上边的安装是安装最新版本，如果想安装特定版本则需要先查看有哪些可以安装的版本：\n1 2 3 4 5 ubuntu@VM-20-3-ubuntu:~$ apt-cache madison docker-ce docker-ce | 5:20.10.16~3-0~ubuntu-focal | https://download.docker.com/linux/ubuntu focal/stable amd64 Packages docker-ce | 5:20.10.15~3-0~ubuntu-focal | https://download.docker.com/linux/ubuntu focal/stable amd64 Packages docker-ce | 5:20.10.14~3-0~ubuntu-focal | https://download.docker.com/linux/ubuntu focal/stable amd64 Packages docker-ce | 5:20.10.13~3-0~ubuntu-focal | https://download.docker.com/linux/ubuntu focal/stable amd64 Packages 找到版本后执行以下命令来进行安装：\n1 2 # 版本是上个命令输出的第个列5:20.10.16~3-0~ubuntu-focal sudo apt-get install docker-ce docker-ce-cli containerd.io docker-compose-plugin 安装后就可以使用了。\n不使用sudo ubuntu的系统如果使用的不是root安装，每次运行命令都是需要使用sudo,相对来说是比较麻烦的，如果不想使用sudo，可以使用下面的命令来解决：\n1 2 3 4 5 6 ubuntu@VM-20-3-ubuntu:~$ sudo groupadd docker [sudo] password for root: groupadd: group \u0026#39;docker\u0026#39; already exists ubuntu@VM-20-3-ubuntu:~$ sudo gpasswd -a ${USER} docker Adding user ubuntu to group docker ubuntu@VM-20-3-ubuntu:~$ newgrp - docker 这样子使用起来就方便了很多。\ndebain安装 前两步和ubuntu基本一样，删除旧版，然后设置源。\n删除旧版以及更新apt 1 2 3 4 # 删除旧版 root@s9707 ~ # apt-get remove docker docker-engine docker.io containerd runc # 更新apt包索引 root@s9707 ~ # apt-get update 添加gpg 执行以下命令添加gpg\n1 2 root@s9707 ~ # mkdir -p /etc/apt/keyrings root@s9707 ~ # curl -fsSL https://download.docker.com/linux/debian/gpg -o /etc/apt/keyrings/docker.asc 如果在添加gpg的时候报错：gpg: command not found\n则可以先安装gpg：\n1 root@s9707:~# apt-get install gnupg gnupg2 设置仓库 通过以下命令添加仓库\n1 2 3 4 root@s9707:~# echo \\ \u0026#34;deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/debian \\ $(. /etc/os-release \u0026amp;\u0026amp; echo \u0026#34;$VERSION_CODENAME\u0026#34;) stable\u0026#34; | \\ tee /etc/apt/sources.list.d/docker.list \u0026amp;gt; /dev/null 然后再次更新apt包索引：\n1 root@s9707 ~ # apt-get update 安装docker 接下来就是安装：\n1 apt-get install docker-ce docker-ce-cli containerd.io docker-compose-plugin 整个安装过程也不是很麻烦，跟着官方的步骤走就可以了，这里记录一下自己的安装过程，方便以后快速安装。\n","date":"2023-06-09T21:49:42Z","image":"https://images.iminling.com/app/hide.php?key=dnp6YVlCOXUzcXZ3NHRyMlZGVEZDYUY3c3h6eW9ET21TY3YrWWwrZTZBcllvQU1ZQkIxWXlaQnRpRVR5cml3VDVIRUJUTFk9","permalink":"https://konghanghang.github.io/iminling-pages/2023/linux-install-docker/","title":"linux服务器快速安装docker和docker-compose"},{"content":"起因 最近工作中需要使用到ftp工具，就在网上找了一个java编写的ftp工具类，功能也是挺齐全的，我在本地测试的时候对文件的下载和上传都是没有问题，正常使用。等到功能开发完成后，部署到k8s就出现了无法读取ftp服务器的文件的情况，起初以为是ftp服务器的问题，就又重新搭建了新的ftp服务器还是同样的问题。中间也想过是不是工具类的功能，就在网上查询了好久，大家基本都是用的commons-net这个包，具体的maven依赖如下：\n1 2 3 4 5 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;commons-net\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-net\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.6\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 以为网上找的工具有问题，后来就引用了hutool工具类中的方法，还是同样的问题，百思不得其解的时候，看到hutool工具类那里有一个标题：主动模式和被动模式。起初我也没注意这个，毕竟是一堆的理论。实在是被这个问题虐的体无完肤的时候，我看了一下这个概念，恍然大悟，不就是因为这个原因吗？下面我们来解释一下这两个模式\nPORT和PASV 在解释具体的概念前，我们先来说明一下主动和被动它针对的对象是谁，其实主动和被动都是针对ftp服务器来说的。下面我们来说明一下两个模式\n和\nPORT（主动模式） FTP客户端连接到FTP服务器的21端口，发送用户名和密码登录，登录成功后要list列表或者读取数据时\n_客户端_随机开放一个端口（1024以上），发送 PORT命令到FTP服务器，告诉服务器客户端采用主动模式并开放端口；\nFTP服务器收到PORT主动模式命令和端口号后，通过服务器的20端口和客户端开放的端口连接，发送数据。\n此模式是ftp服务器主动连接客户端的一个端口，并提供文件上传和下载服务，所以客户端需要开发端口的权限出来，防火墙进行放行，这样子ftp服务器才能连接到_客户端_进行文件处理。\nPASV（被动模式） FTP客户端连接到FTP服务器的21端口，发送用户名和密码登录，登录成功后要list列表或者读取数据时，\n客户端发送PASV命令到FTP服务器， 服务器在本地随机开放一个端口（1024以上），然后把开放的端口告诉客户端，\n客户端再连接到服务器开放的端口进行数据传输。\n此模式是客户端主动去连ftp服务端的端口，然后再进行文件的上传和下载，和我们正常思维逻辑是一样的，此时就需要ftp服务端开放具体的端口出来，并在防火墙中进行放行，客户端才能连接上去进行文件处理。\n问题原因 这里来说明一下我遇到的问题的原因，因为我是网上找的客户端，我起初也并不清楚它使用的是主动模式还是被动模式，就直接发布到k8s中进行使用，从遇到的情况来看，应该默认使用的是主动模式:由ftp服务器主动连接客户端的高位端口，来实现文件的上传和下载。但是因为我的服务是放在k8s中，容器的端口都是需要写命令暴露出来的，而我们系统的容器都是默认只暴露了8080端口来进行服务的访问。\n所以在使用主动模式的时候，ftp服务器想通过高位端口来连接到客户端是没有办法成功的，所以在获取文件的时候就什么也拿不到。\n解决办法 我们知道了具体什么问题那就好解决了，解决办法也就是指定当前ftp客户端是使用主动模式还是被动模式。\n因为我们的服务都是部署在k8s中的，所以我选择使用被动模式来进行文件处理，这样子k8s中的容器就不需要做什么处理。而ftp服务器则需要对高位端口进行放行，以便客户端可以连接上来进行服务的上传和下载。\n代码如下：\n1 2 3 4 5 6 7 8 FTPClient ftpClient = new FTPClient(); ftpClient.connect(url, port); ftpClient.enterLocalActiveMode(); //主动模式 // ftpClient.enterLocalPassiveMode(); 被动模式 ftpClient.setControlEncoding(\u0026#34;UTF-8\u0026#34;); ftpClient.changeWorkingDirectory(path); ","date":"2023-06-01T17:21:12Z","image":"https://images.iminling.com/app/hide.php?key=cStKcGRtRXppeGVqL01GdXRLaVRCbDlEN2JJSjZTaHBoL210b1ZaUW1xdDRSVU9ObzdzSGM4c3BqVHh1ZTNKc25nbEdvVk09","permalink":"https://konghanghang.github.io/iminling-pages/2023/java-ftp-cannot-read-file-in-k8s/","title":"java连接ftp部署在k8s中无法读取文件"},{"content":"开发需要使用idea，以前使用的是破解版，使用起来没什么区别，后边觉得破解实在是麻烦，就转正购买了正式版，随意升级的感觉还是很美好的，哈哈。等到第二年快要续费的时候才了解到可以使用开源项目来申请idea全家桶的License，于是就开始了折腾之路。\n申请准备 想要申请免费的License还是需要准备一些事情的：\n满足以下条件的开源项目： 了解开源定义。 正在积极开发，例如，在过去 3 个月内定期提交新代码。 不提供开源软件的付费版本，也不提供与开源项目相关的任何商业服务（例如付费支持、咨询等）。 未获得商业公司或组织（NGO、教育、研究或政府组织）的资助。 不为他们的核心项目开发者支付工资。 支持条款： 许可证仅提供给项目负责人和核心项目提交者。 许可证有效期为一年，之后如果您的项目仍符合支持计划要求，也可以续订。 您只能将免费许可证用于开发非商业开源项目。 您不能与任何第三方共享免费许可证。 github的邮箱要设置成公开的，keep my email addresses private去掉勾选：\n然后就可以开始申请了。\n申请 申请地址：Request for Open Source Development License，里边共有三大项需要填写\n新用户还是老用户 如果是第一次申请，那么肯定是新用户，选择 **No, we are a new customer.**如果是后续通道到期续的话，那就是第二个选项了\n项目信息 填写自己项目的一些信息：项目名称，项目网站地址(如果没有项目网站地址可以和仓库地址填写同一个地址)，仓库地址，License地址(仓库中的开源协议文件)，以及一些项目的信息，如实填写就可以了。\n关于我们自己 主要就是邮箱，github个人主页，以及姓名，填写完成后再勾选一些协议信息就可以提交了。整个过程还是很快的。提交后就会收到邮件：\n1 2 3 4 5 6 7 8 9 10 11 12 13 Hello xxx, Thank you for your OSS development license request. We will evaluate your project, and we’ll notify you of our decision by email. Please note that it could take up to one week to have your project reviewed. If you have any questions, please contact us atJetBrains Community Support. Kind regards, JetBrains Community Support Team www.jetbrains.com The Drive to Develop 提示已经收到了我们的申请，需要一个星期来审核我们的申请。接下来就是耐心等待了。\n审核结果 大概四五天就会出审核结果，审核不通过就是下边的邮件：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 Hello xxx, Thank you for contacting us. I’ve checked if your open source project is still actively and regularly developed - it is one of the main requirements ofJetBrains Open Source Support Program. According to the project\u0026#39;s repository, it has not been actively developed, so I’m afraid that we cannot provide free licenses for your project at this point. Please feel free to contact us again atopensource@jetbrains.comonce you resume active work on your project. If you have any additional questions, I will be glad to help. Regards, Paige Rothmaller JetBrains Americas Phone: 609-714-7883 Fax: 866-838-6784 https://www.jetbrains.com The Drive to Develop 如果审核通过则是下边的邮件：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 Dear xxx, Congratulations, your request to JetBrains for Open Source development license(s) has been approved! The license certificate is attached to this message. Main facts about your license(s): They are valid for one year. You will receive an automatic email reminder shortly before the license expiration date. They should be used for developing your non-commercial open source projects only. If you’ve received more than one license, please share them only with active contributors to your project. To redeem your license(s), please click the link below: Take me to my license(s) If you find that JetBrains software has been useful for your project, please consider mentioning JetBrains support on your project’s homepage. Feel free to use theJetBrains logoand a link to our website such ashttps://jb.gg/OpenSourceSupport. If you have any questions, please get in touch with us atopensource@jetbrains.com. We’ll be glad to help. Kind regards, JetBrains Community Support Team https://www.jetbrains.com The Drive to Develop 续期 免费的license需要一年一续的，在到期前会有邮件通知我们来进行续期：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 Hi xxx, Your JetBrains All Products Pack license(s) will expire in two weeks, on June 3, 2023. We hope that our products have been useful in the development of your open source project. If your project is still in active development, please consider applying for renewal. Don’t hesitate to contact us if you have any questions or issues regarding our support program – we\u0026#39;ll be glad to help. We would also appreciate any feedback on your experience with JetBrains products. Thank you! Kind regards, JetBrains Community Support Team https://www.jetbrains.com The Drive to Develop 我们可以直接点击邮件里的applying for renewal来续期我们的license。\n填写的信息和第一次申请基本一样，只是在第一项新老用户选择的时候选择老用户，然后填写第一次申请通过的license ID就可以了。\n提交申请后还是会有邮件通知：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 Hello xx, We\u0026#39;re writing to you in regards to your OSS development license request. We\u0026#39;ve run an automated check of your GitHub repository to see if your open source project meets the requirements of our Open Source Support Program. Unfortunately, the check failed because the project has not been actively developed recently. We need to see regular code commits submitted for the past 3 months or more. Readme.md and other non-code commits do not count. If you continue working on your project for a few more months, you\u0026#39;re welcome to re-apply for support. If you believe that your application has been evaluated incorrectly, please email us back at opensource@jetbrains.com. We’ll be glad to look into your case and see how we can help you. Thank you! The Community Support team JetBrains https://www.jetbrains.com The Drive to Develop 由于我的项目最近三个月没有提交过记录，很快就收到了拒绝的邮件，所以如果想续期，续期前的三个月最好提交一下commit：\n1 2 3 4 5 6 7 8 9 10 11 12 Hello xxx, Thank you for your OSS development license request. We will evaluate your project, and we’ll notify you of our decision by email. Please allow up to 2 weeks for your application to be processed, as we\u0026#39;re currently experiencing a high volume of requests. We appreciate your patience. If you need assistance with an urgent license renewal request, please contact us at opensource@jetbrains.com. Kind regards, JetBrains Community Support Team www.jetbrains.com The Drive to Develop 后续 终于等到了3个月，2023-07-01日马上又提交了申请，这次终于过了检查，有开始了漫长的等待。07-07凌晨收到了一封邮件：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 Dear xx, Thanks for your interest in our Open Source Program! Could you please provide more details about your OS project and its functionality? What tools are you interested in and how are you going to use them? Thanks, I look forward to your response! Kind Regards, xx Community Support Team JetBrains www.jetbrains.com The Drive to Develop 早上就赶紧回复邮件，介绍了一下项目情况，以及对哪些工具感兴趣，当天晚上就收到了通过的邮件，比初次申请的时候稍微麻烦了一点：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 Hi xx, Thank you for providing such detailed information. We’ve extended your free All Products Pack license for another year. Please check your inbox for the new license certificate. If you have any questions, please feel free to contact me. Have a nice day! Kind Regards, xx Community Support Team JetBrains www.jetbrains.com The Drive to Develop 最后祝大家都可以成功的申请下来。\n","date":"2023-05-20T04:18:39Z","image":"https://images.iminling.com/app/hide.php?key=a3ZmSmVFVjBZbzZDQkpDKzNPQ0hCQ1p3VFpIYVVWU0tUSk54LzZVbjY3R0t1VXVzRThlcDdGOGFXYmtzREE3NW1rY3duQzg9","permalink":"https://konghanghang.github.io/iminling-pages/2023/apply-jetbrains-open-source-development-license/","title":"开源项目申请JetBrains Open Source Development License"},{"content":"在ios端虽然有很多可以用来代理的软件，但是大多知名的软件都没法完整的支持reality, 小火箭(shadowrocket)是支持最好的一个软件了，支持到了xray1.7.5的版本，可以来配置rprx-vision,截止写这篇文章的时候还没有支持reality。其他的圈X(Quantumult X)、Loon以及Stash都还没有完整的支持vision,所以在ios上使用代理软件还是有一些尴尬的。好在还有两个软件是支持reality的。而且还都是免费软件，一个是sing-box for ios(SFI)，另一个就mate for iso(MFI)。现在都还在内测的阶段，今天我们就主要介绍SFI在ios上的安装和使用。\n安装 先安装TestFlight才可以安装使用。直接在苹果应用商店搜索搜索就可以了。安装完TestFlight后就可以使用官方的邀请连接加入内测了：SFI官方安装地址。\nTestFlight安装后的界面：\n软件：\n使用 界面 下面我们先看一下软件打开后的界面：\n初次打开的时候，Dashboard界面会有所不同，会提示安装一个配置文件，根据提示安装就可以了。\n新建配置 配置文件是在Profiles菜单下新建的，点击New Profile就可以了，有三个参数需要填写：Name,Type和(File,Path或URL)。\nName随便起一个名字就可以了，Type可以选择local(本地),icloud以及Remote。\n我们可以先在本地创建一个新的配置文件。\n具体的配置文件如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 { \u0026#34;log\u0026#34;: { \u0026#34;level\u0026#34;: \u0026#34;info\u0026#34;, \u0026#34;timestamp\u0026#34;: true }, \u0026#34;dns\u0026#34;: { \u0026#34;servers\u0026#34;: [ { \u0026#34;tag\u0026#34;: \u0026#34;cloudflare\u0026#34;, \u0026#34;address\u0026#34;: \u0026#34;https://1.1.1.1/dns-query\u0026#34; }, { \u0026#34;tag\u0026#34;: \u0026#34;dnspod\u0026#34;, \u0026#34;address\u0026#34;: \u0026#34;https://1.12.12.12/dns-query\u0026#34;, \u0026#34;detour\u0026#34;: \u0026#34;direct\u0026#34; }, { \u0026#34;tag\u0026#34;: \u0026#34;block\u0026#34;, \u0026#34;address\u0026#34;: \u0026#34;rcode://success\u0026#34; } ], \u0026#34;rules\u0026#34;: [ { \u0026#34;geosite\u0026#34;: \u0026#34;cn\u0026#34;, \u0026#34;server\u0026#34;: \u0026#34;dnspod\u0026#34; }, { \u0026#34;geosite\u0026#34;: \u0026#34;category-ads-all\u0026#34;, \u0026#34;server\u0026#34;: \u0026#34;block\u0026#34;, \u0026#34;disable_cache\u0026#34;: true } ] }, \u0026#34;inbounds\u0026#34;: [ { \u0026#34;type\u0026#34;: \u0026#34;tun\u0026#34;, \u0026#34;tag\u0026#34;: \u0026#34;tun-in\u0026#34;, \u0026#34;interface_name\u0026#34;: \u0026#34;utun\u0026#34;, \u0026#34;inet4_address\u0026#34;: \u0026#34;172.19.0.1/30\u0026#34;, \u0026#34;auto_route\u0026#34;: true, \u0026#34;strict_route\u0026#34;: true, \u0026#34;stack\u0026#34;: \u0026#34;gvisor\u0026#34;, \u0026#34;sniff\u0026#34;: true } ], \u0026#34;outbounds\u0026#34;: [ { \u0026#34;tag\u0026#34;: \u0026#34;bwg\u0026#34;, # tag和下边route中的要一致 \u0026#34;type\u0026#34;: \u0026#34;vless\u0026#34;, \u0026#34;server\u0026#34;: \u0026#34;自己的IP\u0026#34;, \u0026#34;server_port\u0026#34;: 自己的端口, \u0026#34;uuid\u0026#34;: \u0026#34;自己的UUID\u0026#34;, \u0026#34;flow\u0026#34;: \u0026#34;xtls-rprx-vision\u0026#34;, \u0026#34;network\u0026#34;: \u0026#34;tcp\u0026#34;, \u0026#34;packet_encoding\u0026#34;: \u0026#34;xudp\u0026#34;, \u0026#34;tls\u0026#34;: { \u0026#34;enabled\u0026#34;: true, \u0026#34;server_name\u0026#34;: \u0026#34;www.microsoft.com\u0026#34;, # 根据需要改成自己的 \u0026#34;utls\u0026#34;: { \u0026#34;enabled\u0026#34;: true, \u0026#34;fingerprint\u0026#34;: \u0026#34;chrome\u0026#34; }, \u0026#34;reality\u0026#34;: { \u0026#34;enabled\u0026#34;: true, \u0026#34;public_key\u0026#34;: \u0026#34;自己的Public_key\u0026#34;, \u0026#34;short_id\u0026#34;: \u0026#34;自己的short_id\u0026#34; } } }, { \u0026#34;type\u0026#34;: \u0026#34;direct\u0026#34;, \u0026#34;tag\u0026#34;: \u0026#34;direct\u0026#34; }, { \u0026#34;type\u0026#34;: \u0026#34;block\u0026#34;, \u0026#34;tag\u0026#34;: \u0026#34;block\u0026#34; }, { \u0026#34;type\u0026#34;: \u0026#34;dns\u0026#34;, \u0026#34;tag\u0026#34;: \u0026#34;dns\u0026#34; } ], \u0026#34;route\u0026#34;: { \u0026#34;rules\u0026#34;: [ { \u0026#34;protocol\u0026#34;: \u0026#34;dns\u0026#34;, \u0026#34;outbound\u0026#34;: \u0026#34;dns\u0026#34; }, { \u0026#34;geosite\u0026#34;: \u0026#34;cn\u0026#34;, \u0026#34;geoip\u0026#34;: [ \u0026#34;cn\u0026#34;, \u0026#34;private\u0026#34; ], \u0026#34;outbound\u0026#34;: \u0026#34;direct\u0026#34; }, { \u0026#34;geosite\u0026#34;: \u0026#34;category-ads-all\u0026#34;, \u0026#34;outbound\u0026#34;: \u0026#34;block\u0026#34; } ], \u0026#34;auto_detect_interface\u0026#34;: true, \u0026#34;final\u0026#34;: \u0026#34;bwg\u0026#34; } } 将上边的相关配置改成自己的添加成功就可以了。\n使用 通过上边的准备，现在已经可以开始使用了，在DashBoard界面，启动就可以了。也可以在Logs查看当前的连接情况，以及分流情况。\n总结 以上就是reality的简单配置，sing-box支持多种协议，具体的可以参考：官方文档。\n","date":"2023-05-18T16:52:19Z","image":"https://images.iminling.com/app/hide.php?key=MWZYT1hrOWxrOW0xcmZhcEF6WUNnUGo2ZWJEb0E0dFlvZnJtYU9ydnZZRERsRkZGcElubXpMaVUwZ0ZWVDVqdldVL1J4KzQ9","permalink":"https://konghanghang.github.io/iminling-pages/2023/sing-box-for-ios-configuration-xray-reality/","title":"sing-box for ios 配置xray reality"},{"content":"宽带给了公网ip，所以想在自己家搭建一个frp的服务端，这样子就可以当做一台服务器，来进行内网穿透使用了。\nfrps配置 我家里是使用的r2s刷的openwrt系统，所以可以在r2s中进行frps的搭建，找到对应的菜单：\n端口绑定默认7000，直接使用就可以了，我们这里主要是使用http和https服务，所以填写对应的http和https绑定端口就可以了，可以和端口绑定设置成同一个端口。\n子域名设置 在高级选项中我们可以设置一个子域名，这样子我们就可以使用改域名的子域名来进行访问不同的内网穿透服务。对应的子域名下也有一行提示：\n如果subdomain_host不为空，可以在frpc配置文件中设置类型为http(s)的subdomain；subdomain为test，路由将使用test.frps.com\n管理面板设置 我们可以在管理面板查看到当前已经连接的客户端，以及每个客户端的流量使用情况，所以还是有必要进行一下设置。\n面板绑定端口7500，那么我们就可以使用openwrt的管理ip:7500来登录到frps的管理界面。\n端口转发配置 管理界面端口配置 我们在家里的时候可以使用内网ip:7500来访问，但是不在家的时候就没办法了。不慌，因为我有公网ip，那么我就可以通过端口转发，使用的域名+特定端口来访问到内网的7500端口。通过网络防火墙进行端口转发配置。\n配置管理界面的端口转发，通过域名:7500访问到内网openwrt系统的7500端口。\n绑定端口配置 我们的frps绑定的端口是7000，所以需要把7000端口也暴露出去客户端才能正常连接注册上来，同样需要在端口转发中进行配置。\n通过域名:7000访问到内网openwrt系统的7000端口。\n参考上边的管理界面的端口转发配置。\n到这里我们的frps服务端就搭建好了，接下来我们来配置客户端进行连接。\n客户端连接 我们主要先在需要内网穿透的机器上安装frp的客户端，我这里是一个路由器刷的openwrt系统，所以安装frpc就可以了：\n服务器：其实就是我们frps服务端的ip，因为我使用的是宽带的动态ip，所以ip是会变的，我不能直接使用ip，但是我在家里的openwrt中配置了DDNS，那么我就可以使用ddns的域名来作为服务器，填入ddns中的域名。\n端口：7000，和frps的绑定端口一致。\n令牌：和frps中的令牌一致。\nhttp和https穿透服务端口：7000，和服务端一致。\n经过上边的配置我们就可以和服务端连上了，但是我们还没办法通过公网来访问我们其他需要穿透的服务，我们还需要建一条规则。在下方frp setting页面的下方点击添加，新建一个服务：\n开启状态：开启。\nfrp协议类型：选择http就可以了。\n域名类型：我们在frps服务端配置的时候使用的是子域名形式，所以这里也需要填子域名。\n子域名：我们需要使用的访问域名。\n内网主机地址：我们需要访问的是openwrt的管理界面，所以选择openwrt的地址就可以了。\n内网主机端口：我们访问的是管理界面，默认80端口。\n服务备注名：自定义的一个名称。\n其他的默认就可以了。然后点击保存并应用。完成后如下图：\n如上图我添加的子域名是gzax6,那么我还需要去添加一条解析才能使用gzax6.frps.com:7000来访问我的ax6这个路由器的管理界面。\n我们添加一条CNAME的记录，因为ip地址是一直在变化的，我们唯一不变的就是ddns使用的域名，我们解析一条CNAME记录到我们ddns使用的域名，这样子就可以正确的解析到我的openwrt里的frps服务端了。\n总结 经过上述步骤，我们就可以使用域名:7000端口来在外网访问我们内网的路由器管理界面了。\n","date":"2023-04-09T06:23:58Z","image":"https://images.iminling.com/app/hide.php?key=Z1BQTnU0azJ3OUdjSkc0Sm9FS0JsaWgwTmU3MTNabHFNUDBVV2YyalBiWlcyNEV2NGljaSt0cTFteWZjWDhEVTl5R0xreW89","permalink":"https://konghanghang.github.io/iminling-pages/2023/openwrt-frps-configuration/","title":"openwrt系统frps配置使用"},{"content":"想要在外边访问家里的网络，可以使用运营商分配的ip，但是ip可能会经常变动，所以需要进行ddns配置，配置DDNS的前提条件是家里的宽带需要有公网ip。下面我们开始使用cloudflare来进行DDNS的配置。\n添加ddns配置 选择openwrt里的动态DNS功能，然后在里边添加一个自己的配置，名称随便，如我添加的MYDDNS`。\n添加后就跳转到了配置界面，首先我们要选择ddns的提供商，这里我们选择cloudflare:\n切换后如下图：\n查询主机名 这个就是我们的域名，通过这个域名访问到我们的openwrt管理后台，配置一个自己的三级域名，比如购买的域名的openwrt.com`。这里则填写admin.openwrt.com`。\n域名 域名这个选项其实就上将查询主机名修改为admin@openwrt.com。\n用户名和密码 用户名是cloudflare的登录邮箱，密码是cloudflare的global api key。如下图，点击后边的view就可以查看自己的key了。\n截止上边openwrt里的配置就已经完成了。点击保存并应用就可以了。\n域名解析 我们在上边使用到了admin.openwrt.com。然后我们需要在cloudflare的后台去配置这个域名的解析。添加一条A记录，记录值为`admin`,然后我们就可以通过admin.自己的二级域名来访问我们软路由系统了。IPv4地址可以先随便填一个，等待ddns程序自动进行更新。\n开放openwrt端口 在openwrt后台系统中找到网络-防火墙-端口转发`，进行端口转发配置\n具体配置说明：\n名称：随便填一个标识。\n传输协议：选则TCP+UDP。\n外部区域：选wan口\n外部端口：ddns中的域名+外部端口访问到你这个机器。端口一般在1024~65535中选择。\n内部区域：选lan口\n内部ip地址：选openwrt的管理后台ip,例如我这里是192.168.6.1。\n内部端口：openwrt的管理后台一般都是输入ip就可以访问，所以端口是80.\n添加，然后保存并应用，就可以通过ddns里的配置的查询域名:外部端口访问到管理后台，本文中的就是admin.openwrt.com:8080。8080端口是我随便写的，根据自己情况选择一个可以使用的端口，1024~65535之间的都可以。\n","date":"2023-04-08T18:12:20Z","image":"https://images.iminling.com/app/hide.php?key=N3NkMDdwS3dld0x2Q1I2a09HUW9SZU5Fb2g1SEV5Z1FBaU9QcjNwbzE3ZFZLNWlLdVBFZC9Uai9hS0VLdCtDMUFEcVVsZ1E9","permalink":"https://konghanghang.github.io/iminling-pages/2023/openwrt-configuration-cf-ddns/","title":"openwrt配置Cloudflare DDNS"},{"content":"最近在研究国外信用卡，在朋友的帮助下申请了一张美国第一资本的信用卡(C1信用卡)，在次分享一下申请经历。\n要申请信用卡之前，需要先获取到一个美国的地址以及获取美国的ITIN号，这两个会在后续的分享中介绍给大家如何进行申请。今天我们就主要来介绍capital one的信用卡申请过程。\n准备 获取到ITIN号，我们获取到的应该是一个pdf的文件，里边记录了我们的税号，是9位的数字。\n处理ITIN号之外，我们需要了解capital one信用卡的类别，首先我们进入到地址：capition one,在此页面我们会看到几张信用卡，我们要申请的是最后一张，用于重建信用(REBUILDING CREDIT)。\n申请 首先是填写自己的基础信息，如下图，填写自己的姓名，生日，itin以及另外两个no，然后选自己的国籍：\n然后是自己的联系信息，包括地址手机号以及财务信息：\n接下来就是同意一些协议并提交了。\n接下来就会看到以下界面，剩下的就是等待审批了。\n审批 因为我是晚上申请的，处理速度特别的快，提交后不到10分钟就收到了邮件，让补充资料，也就是让补充ITIN信件以及护照。\n然后就是上传继续等通知了。\n通过 把护照和ITIN上传后，不到3分钟，就立马收到了审批通道的邮件，是真的效率高。\n押金 如上图，我只需要最少交49刀就可以了，然后就是通过wise的账户来进行扣除。提交扣费请求后隔天就对费用进行了扣除。接下来就是耐心的等待了。\ncapital one 账号 等了几天后，我尝试了去注册capital one的账号，通过找回用户名和密码来进行操作，写的是Last Name，实际需要输入自己的名+姓的全拼，然后根据提示就可以找回账号并设置密码和手机号，再验证一下手机号就可以注册账号成功并进入系统。\n在系统中就可以看到自己的卡片进度，比如我查看的时候卡在处理中：\n以上就是截图到写这篇文章时信用卡的申请情况，后续如果有变更继续更新。\n整个申请过程还是挺顺利的。\n更新 2023-04-04 收到了卡片邮寄的通知，整个从扣款成功日期(2023-03-23)到4月4日，历时12天。\n2023-04-06 租用的地址收到了信用卡的信件，速度还是很快的。\n2023-04-13 申请转运，anytimemailbox申请转运，并扣款，当天DHL快递就发出了。\n2023-04-18 DHL速度还是可以的，经历了5天终于拿到了实体卡。\n快递查询单：\n实体卡：\n激活 直接下载captialone的app激活是不行的，提示无法激活需要打电话激活，然后就打了电话，这里使用的是google voice,根据提示输入卡号，itin后四位，然后在输入cvv就会提示激活成功，然后就可以正常使用了。\n后续 退押金 在正常使用了几个月后，在9.15日，我收到了一封邮件，里边提示我押金已经退回，并升级了我的卡片，我登录app查看，的确押金早几天就已经退回了，具体的邮件如下：\n额度提升 在收到押金退回的邮件几天后，9.19日我又收到captial one的一份邮件，额度提升了，惊喜，从200到3200，真的是太给力，继续好好使用了。\n产生逾期费用 我一直使用的是wise的账户在还款，2023年10月14日wise通知账户进行了变更，我第一时间在app添加了账户，但是却漏了一个重要的操作：自动扣款替换。我以为添加了扣款账户进去就ok了。直到11月15日wise的app弹出消息说扣款失败，让我用新的账户扣款，我才大事不妙，这时候我进了app才发现需要先取消上一个设置的自动扣款，然后重新设置新的自动扣款账户。设置是设置成功了，但是怎么把这期的账单给还上呢？这时候我就手动的去操作了扣款，15日操作，18日wise通知扣款。18日晚上我登录了C1网页版，查看账单发现多了一笔逾期费用：$25，太狠了。希望大家引以为戒。\n使用经验 拿到卡后，我的使用方式也比较单一，给T-Mobile的手机卡充值了一次大概$10，然后就是绑定了appleId，每个月正常付款Apple One订阅，就这样子使用了几个月后就把押金给退了回来，然后还把额度从200提升到了3200。以上就是我的使用经验，的确是很单调的，希望对大家有所帮助。\n使用了几个月后，我又申请了AE的卡片，有兴趣的小伙伴可以参考：使用ITIN申请American Express(美国运通)信用卡\n","date":"2023-04-03T07:35:05Z","image":"https://images.iminling.com/app/hide.php?key=VW9RWWpMZis0VVQxVVZ3ZWtyTzVNc2JVb05oVWVCWE1kR1dFNXZoQ2R6V3RyaWdlK1JiZkJ3RmhxZ3h4eEJZWE0vc2syNEk9","permalink":"https://konghanghang.github.io/iminling-pages/2023/itin-apply-capital-one-credit-card/","title":"使用ITIN申请capital one信用卡"},{"content":"安装哪吒面板的机器是RN的一台小鸡，本来安装的是ubuntu系统，想换成debian系统，所以需要对哪吒面板的数据进行迁移，所以写此篇文章记录迁移过程。\n迁移准备 参考哪吒面板官方的wiki，所有的数据都存放在/opt/nezha目录下，所以需要备份一下此目录，下载到本地。\n如何进行数据迁移、备份恢复？\n先运行一键脚本，选择停止面板 在旧服务器中打包/opt/nezha文件夹，复制到新环境相同位置解压 在新环境中运行一键脚本，选择启动面板 迁移 将备份数据上传到新的服务器，解压到/opt/nezha目录下。通过nezha.sh启动面板。\n配置通过域名访问面板：\nnginx配置\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 server { listen 80; server_name dashboard.baidu.com,tz.baidu.me; # ws配置 location /ws { proxy_pass http://dashboard-dashboard-1:80; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \u0026#34;Upgrade\u0026#34;; proxy_set_header Host $host; } # 访问配置 location / { proxy_pass http://dashboard-dashboard-1:80; } } 整个迁移过程还是比较简单的，通过备份数据，整体迁移启动。记录一下。\n","date":"2023-03-28T06:48:18Z","image":"https://images.iminling.com/app/hide.php?key=M05ad0RZN21FSGFHQWRWZlBhRjdJejRteTdYV1dUUml0eWRmbTExY1Ntc2lHcXIrSmlLVmF1VHc1NnJqQzVkKytPZFJNWVE9","permalink":"https://konghanghang.github.io/iminling-pages/2023/nezha-pannel-migrate/","title":"哪吒面板迁移"},{"content":"今天我们主要来介绍一下x-ui的安装使用。\nx-ui在原地址是：x-ui\n但是由于原仓库太久没更新，我们今天使用的是改版的FranzKafkaYu/x-ui,支持单个端口多用户，还能分别统计流量，比原版较完善。\n本文使用改版MHSanaei/3x-ui进行配置。\n安装 使用github仓库中的一键安装脚本很容易就可以安装完成安装：\nbash \u003c(curl -Ls https://raw.githubusercontent.com/mhsanaei/3x-ui/master/install.sh) 安装完成如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 Saving to: ‘/usr/local/x-ui-linux-amd64.tar.gz’ /usr/local/x-ui-linux- 100%[=========================\u0026gt;] 27.95M 124MB/s in 0.2s 2023-03-26 08:10:51 (124 MB/s) - ‘/usr/local/x-ui-linux-amd64.tar.gz’ saved [29309974/29309974] x-ui/ x-ui/x-ui.sh x-ui/bin/ x-ui/bin/README.md x-ui/bin/LICENSE x-ui/bin/geosite.dat x-ui/bin/geoip.dat x-ui/bin/xray-linux-amd64 x-ui/x-ui x-ui/x-ui.service --2023-03-26 08:10:52-- https://raw.githubusercontent.com/FranzKafkaYu/x-ui/main/x-ui.sh Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ... Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 25694 (25K) [text/plain] Saving to: ‘/usr/bin/x-ui’ /usr/bin/x-ui 100%[=========================\u0026gt;] 25.09K --.-KB/s in 0.001s 2023-03-26 08:10:52 (34.8 MB/s) - ‘/usr/bin/x-ui’ saved [25694/25694] 出于安全考虑，安装/更新完成后需要强制修改端口与账户密码 确认是否继续,如选择n则跳过本次端口与账户密码设定[y/n]:y 请设置您的账户名:admin 您的账户名将设定为:admin 请设置您的账户密码:admin 您的账户密码将设定为:admin 请设置面板访问端口:8080 您的面板访问端口将设定为:8080 确认设定,设定中 set username and password success 账户密码设定完成 set port 11000 success面板端口设定完成 Created symlink /etc/systemd/system/multi-user.target.wants/x-ui.service → /etc/systemd/system/x-ui.service. x-ui v0.3.4.1 安装完成，面板已启动 安装完成后我们就可以进行登录了，使用我们vps的ip地址加上安装的时候设置的端口就可以正常登录了。\n配置域名访问 使用ip加端口的形式多少有点不怎么方便，我们可以配置nginx来进行反向代理，使用域名来访问我们的x-ui的界面。\nx-ui配置 第一次需要使用ip+端口的形式进行登录，登录x-ui后我们进入面板设置-面板url根路径配置，默认是/,我们将它改为我们想要使用的路径，我这里改为/ui.\nnginx配置 配置nginx的配置文件，添加以下转发配置：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 server { listen 80; server_name _; #access_log /var/log/nginx/host.access.log main; location /ui { proxy_set_header X-Real-IP $remote_addr; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_ignore_client_abort on; proxy_pass http://172.17.0.1:8080; } } 如果不限制域名server_name配置为_就可以了，如果要限制域名，则配置为对应的域名。\n就可以通过域名直接进行访问了。\n节点添加 现在最常用的节点还是vless节点，下边就添加一个vless节点来使用：\n用户就使用xui自己生成的用户信息就可以了。\nflow需要改成xtls-rprx-vision,\n安全选项使用Reality，然后下边的都可以自动生成，\nserverNames可以使用xui自己生成的，也可以使用我们自己找的。\n然后就是保存，去相关的客户端里按照我们的配置进行填写，然后就可以正常上网了。\n这里演示一下openwrt中的配置：\n基本就是对着xui里的进行抄就行了，地址就是自己的vps地址，端口在xui的截图里没有截取到，按自己添加的端口进行填写就行了。然后就可以愉快的上网了。\n","date":"2023-03-26T01:39:01Z","image":"https://images.iminling.com/app/hide.php?key=dmRweU41MERsbjlVeVBxMUJOMzZSN0VyRE15VzhId1FsY3JiWHBtL1FKWXEyUzczTXMzemFCc2twSDMvOWU0dEFyNGpqOFU9","permalink":"https://konghanghang.github.io/iminling-pages/2023/x-ui-configuration-and-use/","title":"x-ui安装配置使用"},{"content":"最近xray新版本1.8发布了，备受期待的reality也随之而来，下面介绍一下我折腾reality的过程。\n首先是去reality的官方仓库查看一下R佬写的模板,git地址：REALITY 模板文件 下面开始配置reality服务器端，配置模板如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 { \u0026#34;inbounds\u0026#34;: [ // 服务端入站配置 { \u0026#34;listen\u0026#34;: \u0026#34;0.0.0.0\u0026#34;, \u0026#34;port\u0026#34;: 443, \u0026#34;protocol\u0026#34;: \u0026#34;vless\u0026#34;, \u0026#34;settings\u0026#34;: { \u0026#34;clients\u0026#34;: [ { \u0026#34;id\u0026#34;: \u0026#34;\u0026#34;, // 必填，执行 ./xray uuid 生成，或 1-30 字节的字符串 \u0026#34;flow\u0026#34;: \u0026#34;xtls-rprx-vision\u0026#34; // 选填，若有，客户端必须启用 XTLS } ], \u0026#34;decryption\u0026#34;: \u0026#34;none\u0026#34; }, \u0026#34;streamSettings\u0026#34;: { \u0026#34;network\u0026#34;: \u0026#34;tcp\u0026#34;, \u0026#34;security\u0026#34;: \u0026#34;reality\u0026#34;, \u0026#34;realitySettings\u0026#34;: { \u0026#34;show\u0026#34;: false, // 选填，若为 true，输出调试信息 \u0026#34;dest\u0026#34;: \u0026#34;example.com:443\u0026#34;, // 必填，格式同 VLESS fallbacks 的 dest \u0026#34;xver\u0026#34;: 0, // 选填，格式同 VLESS fallbacks 的 xver \u0026#34;serverNames\u0026#34;: [ // 必填，客户端可用的 serverName 列表，暂不支持 * 通配符 \u0026#34;example.com\u0026#34;, \u0026#34;www.example.com\u0026#34; ], \u0026#34;privateKey\u0026#34;: \u0026#34;\u0026#34;, // 必填，执行 ./xray x25519 生成 \u0026#34;minClientVer\u0026#34;: \u0026#34;\u0026#34;, // 选填，客户端 Xray 最低版本，格式为 x.y.z \u0026#34;maxClientVer\u0026#34;: \u0026#34;\u0026#34;, // 选填，客户端 Xray 最高版本，格式为 x.y.z \u0026#34;maxTimeDiff\u0026#34;: 0, // 选填，允许的最大时间差，单位为毫秒 \u0026#34;shortIds\u0026#34;: [ // 必填，客户端可用的 shortId 列表，可用于区分不同的客户端 \u0026#34;\u0026#34; // 若有此项，客户端 shortId 可为空 \u0026#34;0123456789abcdef\u0026#34; // 0 到 f，长度为 2 的倍数，长度上限为 16 ] } } } ] } clients参数 clients的配置和以前的vless配置一样，id可以使用xray核心程序来生成：\n1 2 root@r-6c5317:~/xray# ./xray uuid 94281a1a-33bc-445a-ace9-0fdd56a0c14a stramSettings 最重要的配置是streamSettings的配置，security要配置成reality ,dest官方建议如下：\n通常代理用途，目标网站最低标准：**国外网站，支持 TLSv1.3 与 H2，域名非跳转用**（主域名可能被用于跳转到 www）\n加分项：IP 相近（更像，且延迟低），Server Hello 后的握手消息一起加密（如 dl.google.com），有 OCSP Stapling\n配置加分项：**禁回国流量，TCP/80、UDP/443 也转发**（REALITY 对外表现即为端口转发，目标 IP 冷门或许更好） 当我们选择了一个dest 域名后，可以使用xray核心来确定serverNames如何填，我们先来看看xray核心有那些命令可以使用： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 root@r-6c5317:~/xray# ./xray -h Xray is a platform for building proxies. Usage: xray \u0026lt;command\u0026gt; [arguments] The commands are: run Run Xray with config, the default command version Show current version of Xray api Call an API in an Xray process tls TLS tools uuid Generate UUIDv4 or UUIDv5 x25519 Generate key pair for x25519 key exchange Use \u0026#34;xray help \u0026lt;command\u0026gt;\u0026#34; for more information about a command. serverNames 有一个tls tools，可以使用它来确定serverNames，执行 xray tls ping 目标网站网址，填 \u0026ldquo;Allowed domains\u0026rdquo; 的值。我这里使用微软的域名，所以情况如下：\n1 2 3 4 5 6 7 8 9 10 11 12 root@r-6c5317:~/xray# ./xray tls ping www.microsoft.com Tls ping: www.microsoft.com Using IP: 23.3.85.234 ------------------- Pinging without SNI Handshake succeeded Allowed domains: [wwwqa.microsoft.com www.microsoft.com staticview.microsoft.com i.s-microsoft.com microsoft.com c.s-microsoft.com privacy.microsoft.com] ------------------- Pinging with SNI handshake succeeded Allowed domains: [wwwqa.microsoft.com www.microsoft.com staticview.microsoft.com i.s-microsoft.com microsoft.com c.s-microsoft.com privacy.microsoft.com] Tls ping finished 可以把上面的域名填写到serverNames中，客户端在使用的时候找一个域名来填写。\nprivateKey 下边说一下privateKey参数，也是要使用xray核心程序来生成的，在上面我们查看xray -h的时候有一个x25519的命令，生成如下： 1 2 3 root@r-6c5317:~/xray# ./xray x25519 Private key: YIHyZpW1NJLck_XTCG8IYMMqq1JG7w2Vm95HMAbB51g Public key: Xh_hBw4E5SBFjreeAQQjnUMlvLvFPeELy2Xdvur6XwU 服务器端就使用 privateKey，客户端在使用的时候就用publicKey。\n完整服务端配置 所以完整的xray服务端的配置config.json如下： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 { \u0026#34;log\u0026#34;: { \u0026#34;loglevel\u0026#34;: \u0026#34;warning\u0026#34;, \u0026#34;access\u0026#34;: \u0026#34;/var/log/xray/access.log\u0026#34;, \u0026#34;error\u0026#34;: \u0026#34;/var/log/xray/error.log\u0026#34; }, \u0026#34;api\u0026#34;: { \u0026#34;services\u0026#34;: [ \u0026#34;HandlerService\u0026#34;, \u0026#34;LoggerService\u0026#34;, \u0026#34;StatsService\u0026#34; ], \u0026#34;tag\u0026#34;: \u0026#34;api\u0026#34; }, \u0026#34;inbounds\u0026#34;: [ { \u0026#34;listen\u0026#34;: null, \u0026#34;port\u0026#34;: 13100, \u0026#34;protocol\u0026#34;: \u0026#34;vless\u0026#34;, \u0026#34;settings\u0026#34;: { \u0026#34;clients\u0026#34;: [ { \u0026#34;id\u0026#34;: \u0026#34;0c41318a-32b6-4017-9938-4033bf26b111\u0026#34;, \u0026#34;flow\u0026#34;: \u0026#34;xtls-rprx-vision\u0026#34; } ], \u0026#34;decryption\u0026#34;: \u0026#34;none\u0026#34; }, \u0026#34;streamSettings\u0026#34;: { \u0026#34;network\u0026#34;: \u0026#34;tcp\u0026#34;, \u0026#34;security\u0026#34;: \u0026#34;reality\u0026#34;, \u0026#34;realitySettings\u0026#34;: { \u0026#34;show\u0026#34;: false, \u0026#34;dest\u0026#34;: \u0026#34;www.microsoft.com:443\u0026#34;, \u0026#34;xver\u0026#34;: 0, \u0026#34;serverNames\u0026#34;: [ \u0026#34;www.microsoft.com\u0026#34; ], \u0026#34;privateKey\u0026#34;: \u0026#34;YIHyZpW1NJLck_XTCG8IYMMqq1JG7w2Vm95HMAbB51g\u0026#34;, \u0026#34;shortIds\u0026#34;: [ \u0026#34;6ba85179e30d4fc2\u0026#34; ] } }, \u0026#34;sniffing\u0026#34;: { \u0026#34;enabled\u0026#34;: true, \u0026#34;destOverride\u0026#34;: [ \u0026#34;http\u0026#34;, \u0026#34;tls\u0026#34; ] } } ], \u0026#34;outbounds\u0026#34;: [ { \u0026#34;tag\u0026#34;:\u0026#34;common\u0026#34;, \u0026#34;protocol\u0026#34;: \u0026#34;freedom\u0026#34; }, { \u0026#34;protocol\u0026#34;: \u0026#34;blackhole\u0026#34;, \u0026#34;settings\u0026#34;: {}, \u0026#34;tag\u0026#34;: \u0026#34;blocked\u0026#34; } ], \u0026#34;routing\u0026#34;: { \u0026#34;rules\u0026#34;: [ { \u0026#34;type\u0026#34;: \u0026#34;field\u0026#34;, \u0026#34;outboundTag\u0026#34;: \u0026#34;common\u0026#34;, \u0026#34;network\u0026#34;: \u0026#34;udp,tcp\u0026#34; }, { \u0026#34;type\u0026#34;: \u0026#34;field\u0026#34;, \u0026#34;outboundTag\u0026#34;: \u0026#34;blocked\u0026#34;, \u0026#34;ip\u0026#34;: [ \u0026#34;geoip:cn\u0026#34;, \u0026#34;geoip:private\u0026#34; ] } ] }, \u0026#34;policy\u0026#34;: { \u0026#34;statsInboundUplink\u0026#34;: true, \u0026#34;statsInboundDownlink\u0026#34;: true, \u0026#34;statsOutboundUplink\u0026#34;: true, \u0026#34;statsOutboundDownlink\u0026#34;: true }, \u0026#34;dns\u0026#34;: null, \u0026#34;transport\u0026#34;: null, \u0026#34;stats\u0026#34;: null, \u0026#34;reverse\u0026#34;: null, \u0026#34;fakeDns\u0026#34;: null } 客户端配置 客户端我使用的是v2rayN，配置如下：\n以上就是折腾的整个过程，完美上网。\n","date":"2023-03-11T18:30:56Z","image":"https://images.iminling.com/app/hide.php?key=TUVLUjRhOHdSS21VVjh4dDdmbElGUVhHZHRFRlR3c3h1R2F2Qi8wOEg0V3V6cGZReGx5NUs1Z3FQYjRhVXdCdm14WWVma2c9","permalink":"https://konghanghang.github.io/iminling-pages/2023/xray-configutaion-reality/","title":"xray配置使用reality"},{"content":"最近在尝试搭建springboot+dubbo+shiro基于注解的一个项目,突发奇想想把消息转换器从jackson换成fastjson,于是就开始了折腾之路.\n轻车熟路的去自定了一个SpringMvcConfigure去继承WebMvcConfigurerAdapter,然后就发现这个WebMvcConfigurerAdapter竟然过时了?what?点进去看源码:\n1 2 3 4 5 6 7 8 9 10 11 12 /** * An implementation of {@link WebMvcConfigurer} with empty methods allowing * subclasses to override only the methods they\u0026#39;re interested in. * * @author Rossen Stoyanchev * @since 3.1 * @deprecated as of 5.0 {@link WebMvcConfigurer} has default methods (made * possible by a Java 8 baseline) and can be implemented directly without the * need for this adapter */ @Deprecated public abstract class WebMvcConfigurerAdapter implements WebMvcConfigurer {} 可以看到从spring5.0开始就被@Deprecated,原来是java8中支持接口中有默认方法,所以我们现在可以直接实现WebMvcConfigurer,然后选择性的去重写某个方法,而不用实现它的所有方法.\n于是就实现了WebMvcConfigurer:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 @Configuration public class SpringMvcConfigure implements WebMvcConfigurer { /** * 配置消息转换器 * @param converters */ @Override public void configureMessageConverters(List\u0026lt;HttpMessageConverter\u0026lt;?\u0026gt;\u0026gt; converters) { FastJsonHttpMessageConverter fastJsonHttpMessageConverter = new FastJsonHttpMessageConverter(); //自定义配置... FastJsonConfig config = new FastJsonConfig(); config.setSerializerFeatures(SerializerFeature.QuoteFieldNames, SerializerFeature.WriteEnumUsingToString, /*SerializerFeature.WriteMapNullValue,*/ SerializerFeature.WriteDateUseDateFormat, SerializerFeature.DisableCircularReferenceDetect); fastJsonHttpMessageConverter.setFastJsonConfig(config); converters.add(fastJsonHttpMessageConverter); } } 本以为这样子配置就可以完事儿,但是诡异的事情发生了,我明明注释了SerializerFeature.WriteMapNullValue,可是返回的json中仍然有为null的字段,然后我就去com.alibaba.fastjson.support.spring.FastJsonHttpMessageConverter中的write和writeInternal打了断点,再次执行,竟然什么都没有发生,根本没有走这两个方法,于是在自定义的SpringMvcConfigure中configureMessageConverters方法内打了断点,想看看这个方法参数converters里边到底有什么:\n看到这里就想到,肯定是我自己添加的fastjson在后边,所以没有生效,所以就加了以下代码:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 @Override public void configureMessageConverters(List\u0026lt;HttpMessageConverter\u0026lt;?\u0026gt;\u0026gt; converters) { converters = converters.stream() .filter((converter)-\u0026gt; !(converter instanceof MappingJackson2HttpMessageConverter)) .collect(Collectors.toList()); FastJsonHttpMessageConverter fastJsonHttpMessageConverter = new FastJsonHttpMessageConverter(); //自定义配置... FastJsonConfig config = new FastJsonConfig(); config.setSerializerFeatures(SerializerFeature.QuoteFieldNames, SerializerFeature.WriteEnumUsingToString, /*SerializerFeature.WriteMapNullValue,*/ SerializerFeature.WriteDateUseDateFormat, SerializerFeature.DisableCircularReferenceDetect); fastJsonHttpMessageConverter.setFastJsonConfig(config); converters.add(fastJsonHttpMessageConverter); } 竟然还没有生效,后来开始追踪,开始方法是从org.springframework.web.servlet.config.annotation.WebMvcConfigurationSupport类中的一个bean配置:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 @Bean public RequestMappingHandlerAdapter requestMappingHandlerAdapter() { RequestMappingHandlerAdapter adapter = createRequestMappingHandlerAdapter(); adapter.setContentNegotiationManager(mvcContentNegotiationManager()); //就是从这里开始设置converters的,然后从这里一路追踪下去. adapter.setMessageConverters(getMessageConverters()); adapter.setWebBindingInitializer(getConfigurableWebBindingInitializer()); adapter.setCustomArgumentResolvers(getArgumentResolvers()); adapter.setCustomReturnValueHandlers(getReturnValueHandlers()); if (jackson2Present) { adapter.setRequestBodyAdvice(Collections.singletonList(new JsonViewRequestBodyAdvice())); adapter.setResponseBodyAdvice(Collections.singletonList(new JsonViewResponseBodyAdvice())); } AsyncSupportConfigurer configurer = new AsyncSupportConfigurer(); configureAsyncSupport(configurer); if (configurer.getTaskExecutor() != null) { adapter.setTaskExecutor(configurer.getTaskExecutor()); } if (configurer.getTimeout() != null) { adapter.setAsyncRequestTimeout(configurer.getTimeout()); } adapter.setCallableInterceptors(configurer.getCallableInterceptors()); adapter.setDeferredResultInterceptors(configurer.getDeferredResultInterceptors()); return adapter; } getMessageConverters()方法:\n1 2 3 4 5 6 7 8 9 10 11 protected final List\u0026lt;HttpMessageConverter\u0026lt;?\u0026gt;\u0026gt; getMessageConverters() { if (this.messageConverters == null) { this.messageConverters = new ArrayList\u0026lt;\u0026gt;(); configureMessageConverters(this.messageConverters);//进入这一步 if (this.messageConverters.isEmpty()) { addDefaultHttpMessageConverters(this.messageConverters); } extendMessageConverters(this.messageConverters); } return this.messageConverters; } org.springframework.web.servlet.config.annotation.DelegatingWebMvcConfiguration:\n1 2 3 4 5 6 7 8 9 10 @Override protected void configureMessageConverters(List\u0026lt;HttpMessageConverter\u0026lt;?\u0026gt;\u0026gt; converters) { this.configurers.configureMessageConverters(converters); } @Override public void configureMessageConverters(List\u0026lt;HttpMessageConverter\u0026lt;?\u0026gt;\u0026gt; converters) { for (WebMvcConfigurer delegate : this.delegates) { delegate.configureMessageConverters(converters); } } this.delegates包含了springboot的一个默认配置类类:org.springframework.boot.autoconfigure.web.servlet.WebMvcAutoConfiguration里边有一个参数\n1 private final HttpMessageConverters messageConverters; for循环里的delegate.configureMessageConverters(converters)调用了WebMvcAutoConfiguration中的configureMessageConverters方法:\n1 2 3 4 @Override public void configureMessageConverters(List\u0026lt;HttpMessageConverter\u0026lt;?\u0026gt;\u0026gt; converters) { converters.addAll(this.messageConverters.getConverters()); } 执行完这个后,就给converters中添加了10个转换器了,就是上图中的10个. this.delegates中还有一个就是我们自定义的那个,执行完后,在我们自定义的那个SpringMvcConfigure发现我添加的fastjson添加进去了,但是org.springframework.web.servlet.config.annotation.WebMvcConfigurationSupport.getMessageConverters(),发现converters并没有发现我们添加进去的FastJsonHttpMessageConverter,这时突然又想起来:java8的stream api每次都是生成一个新的对象,所以导致converters已经不是传递过来的那个converters的引用了(这里也证明了java是值传递,不是引用传递).\n于是再次改变那个lambda表达式为普通的增强for循环:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 @Override public void configureMessageConverters(List\u0026lt;HttpMessageConverter\u0026lt;?\u0026gt;\u0026gt; converters) { /*converters = converters.stream(). filter((converter)-\u0026gt; !(converter instanceof MappingJackson2HttpMessageConverter)) .collect(Collectors.toList());*/ for (HttpMessageConverter\u0026lt;?\u0026gt; converter : converters) { if (converter instanceof MappingJackson2HttpMessageConverter){ converters.remove(converter); } } FastJsonHttpMessageConverter fastJsonHttpMessageConverter = new FastJsonHttpMessageConverter(); //自定义配置... FastJsonConfig config = new FastJsonConfig(); config.setSerializerFeatures(SerializerFeature.QuoteFieldNames, SerializerFeature.WriteEnumUsingToString, /*SerializerFeature.WriteMapNullValue,*/ SerializerFeature.WriteDateUseDateFormat, SerializerFeature.DisableCircularReferenceDetect); fastJsonHttpMessageConverter.setFastJsonConfig(config); converters.add(fastJsonHttpMessageConverter); } 再次运行,wtf?报错了:ConcurrentModificationException,原来使用for循环遍历过程中不能进行remove操作,于是换成Iterator:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 @Override public void configureMessageConverters(List\u0026lt;HttpMessageConverter\u0026lt;?\u0026gt;\u0026gt; converters) { /*converters = converters.stream() .filter((converter)-\u0026gt; !(converter instanceof MappingJackson2HttpMessageConverter)) .collect(Collectors.toList()); for (HttpMessageConverter\u0026lt;?\u0026gt; converter : converters) { if (converter instanceof MappingJackson2HttpMessageConverter){ converters.remove(converter); } }*/ Iterator\u0026lt;HttpMessageConverter\u0026lt;?\u0026gt;\u0026gt; iterator = converters.iterator(); while(iterator.hasNext()){ HttpMessageConverter\u0026lt;?\u0026gt; converter = iterator.next(); if(converter instanceof MappingJackson2HttpMessageConverter){ iterator.remove(); } } FastJsonHttpMessageConverter fastJsonHttpMessageConverter = new FastJsonHttpMessageConverter(); //自定义配置... FastJsonConfig config = new FastJsonConfig(); config.setSerializerFeatures(SerializerFeature.QuoteFieldNames, SerializerFeature.WriteEnumUsingToString, /*SerializerFeature.WriteMapNullValue,*/ SerializerFeature.WriteDateUseDateFormat, SerializerFeature.DisableCircularReferenceDetect); fastJsonHttpMessageConverter.setFastJsonConfig(config); converters.add(fastJsonHttpMessageConverter); } 再次运行,我去,终于解决了,先是删除MappingJackson2HttpMessageConverter,然后添加FastJsonHttpMessageConverter,但是不是到为什么进过一系列操作后,MappingJackson2HttpMessageConverter还是添加进去了,但是由于FastJsonHttpMessageConverter在MappingJackson2HttpMessageConverter之前添加,所以对结果不影响.至此,解决了这个问题.\n总结 最重要的还是解决了springboot2.0.2配置fastjson不生效的问题 更加明白stream api返回的都是全新的对象 更理解java是值传递而不是引用传递 了解到想要在迭代过程中对集合进行操作要用Iterator,而不是直接简单的for循环或者增强for循环 如有不正确的地方还请指出,谢谢.\n","date":"2023-03-08T06:50:58Z","image":"https://images.iminling.com/app/hide.php?key=SmJabnJsdTlXbDExYlljU3RzemUyTVRlcHFScHFZRUJYSTR1c1BoYkhrZHE3L2RpK05qbkpLQlprcTFPY2QvY3lJaVB3Y3M9","permalink":"https://konghanghang.github.io/iminling-pages/2023/springboot-fastjson-doesnot-work/","title":"记一次踩坑:springboot2.0.2配置fastjson不生效"},{"content":"搭建一个wordpress网站。本文主要介绍使用docker搭建一个完整的wordpress网站。\n安装docker就不做多介绍了.\n准备wordpress的docker-compose.yaml文件：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 version: \u0026#39;3.9\u0026#39; networks: mynet: external: true services: wordpress: # default port 9000 (FastCGI) image: wordpress:6.1.0-fpm container_name: wordpress env_file: - .env restart: unless-stopped networks: - mynet volumes: - ${WORDPRESS_LOCAL_HOME}:/var/www/html - ${WORDPRESS_UPLOADS_CONFIG}:/usr/local/etc/php/conf.d/uploads.ini # - /path/to/repo/myTheme/:/var/www/html/wp-content/themes/myTheme environment: - WORDPRESS_DB_HOST=${WORDPRESS_DB_HOST} - WORDPRESS_DB_NAME=${WORDPRESS_DB_NAME} - WORDPRESS_DB_USER=${WORDPRESS_DB_USER} - WORDPRESS_DB_PASSWORD=${WORDPRESS_DB_PASSWORD} nginx: image: nginx:1.22.0 container_name: nginx env_file: - .env restart: unless-stopped networks: - mynet depends_on: - wordpress ports: - \u0026#34;80:80\u0026#34; # http volumes: - ${WORDPRESS_LOCAL_HOME}:/var/www/html - ./nginx/default.conf:/etc/nginx/conf.d/default.conf - ./logs:/var/log/nginx 使用官方的6.1.0版本的镜像，把文件中的数据库的信息改成自己的就可以正常启动了。 端口这里没有暴露出来，因为我想使用nginx来处理所有请求，所以还需要配置一下nginx的代理规则：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 server { listen 80; listen [::]:80; server_name ${HOST}; index index.php index.html index.htm; root /var/www/html; server_tokens off; client_max_body_size 75M; # update ssl files as required by your deployment #ssl_certificate /etc/ssl/fullchain.pem; #ssl_certificate_key /etc/ssl/privkey.pem; # logging access_log /var/log/nginx/wordpress.access.log; error_log /var/log/nginx/wordpress.error.log; # some security headers ( optional ) add_header X-Frame-Options \u0026#34;SAMEORIGIN\u0026#34; always; add_header X-XSS-Protection \u0026#34;1; mode=block\u0026#34; always; add_header X-Content-Type-Options \u0026#34;nosniff\u0026#34; always; add_header Referrer-Policy \u0026#34;no-referrer-when-downgrade\u0026#34; always; add_header Content-Security-Policy \u0026#34;default-src * data: \u0026#39;unsafe-eval\u0026#39; \u0026#39;unsafe-inline\u0026#39;\u0026#34; always; location / { try_files $uri $uri/ /index.php$is_args$args; } location ~ \\.php$ { try_files $uri = 404; fastcgi_split_path_info ^(.+\\.php)(/.+)$; fastcgi_pass wordpress:9000; fastcgi_index index.php; include fastcgi_params; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; fastcgi_param PATH_INFO $fastcgi_path_info; } location ~ /\\.ht { deny all; } location = /favicon.ico { log_not_found off; access_log off; } location = /favicon.svg { log_not_found off; access_log off; } location = /robots.txt { log_not_found off; access_log off; allow all; } location ~* \\.(css|gif|ico|jpeg|jpg|js|png)$ { expires max; log_not_found off; } } 完成后就可以使用域名来访问了。\n也可以参考我的github仓库中的docker-compose.yaml文件：wordpress\n","date":"2023-03-07T06:59:39Z","image":"https://images.iminling.com/app/hide.php?key=U3grOTJQSUZnQ1N0T2hlU0gydlRwbGdXalNiNmdMSGl4Rk1XNTF2dE0ydlpydmFkZXA0WFhsUEZ5d0o5MnZ4c2tHTkEzSm89","permalink":"https://konghanghang.github.io/iminling-pages/2023/docker-install-wordpress/","title":"docker搭建wordpress教程"}]